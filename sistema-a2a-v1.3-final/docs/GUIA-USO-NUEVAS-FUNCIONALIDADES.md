# üöÄ Gu√≠a de Uso - Nuevas Funcionalidades v1.3

## Sistema A2A para Tesis Doctoral

---

## üìã √çndice

1. [Reproducibilidad con Semillas](#1-reproducibilidad-con-semillas)
2. [Captura y An√°lisis de Trazas PCAP](#2-captura-y-an√°lisis-de-trazas-pcap)
3. [Overhead de Enrutamiento](#3-overhead-de-enrutamiento)
4. [Tests Estad√≠sticos](#4-tests-estad√≠sticos)
5. [Intervalos de Confianza](#5-intervalos-de-confianza)
6. [Reportes Autom√°ticos](#6-reportes-autom√°ticos)
7. [Ejemplos Pr√°cticos](#7-ejemplos-pr√°cticos)

---

## 1. Reproducibilidad con Semillas

### ¬øQu√© es?
Control total sobre la aleatoriedad de las simulaciones para garantizar resultados reproducibles.

### ¬øC√≥mo funciona?
El sistema configura autom√°ticamente la semilla aleatoria en NS-3 antes de crear nodos.

### Uso B√°sico

```python
# El sistema genera autom√°ticamente c√≥digo con semilla
# No necesitas hacer nada especial

# Ejemplo de c√≥digo generado:
ns.core.RngSeedManager.SetSeed(12345)
ns.core.RngSeedManager.SetRun(1)
```

### Uso Avanzado: M√∫ltiples Semillas

Para validaci√≥n estad√≠stica robusta, ejecuta la misma simulaci√≥n con diferentes semillas:

```python
# Crear script personalizado
seeds = [12345, 23456, 34567, 45678, 56789]

for seed in seeds:
    print(f"Ejecutando con semilla: {seed}")
    # Modificar el c√≥digo generado para usar esta semilla
    # O pasar como par√°metro al sistema
```

### Verificar Reproducibilidad

```bash
# Ejecutar simulaci√≥n 1
python main.py

# Guardar resultados
copy simulations\results\sim_*.xml resultados_run1.xml

# Ejecutar simulaci√≥n 2 (con misma semilla)
python main.py

# Comparar resultados (deben ser id√©nticos)
fc resultados_run1.xml simulations\results\sim_*.xml
```

### Beneficios
- ‚úÖ Resultados 100% reproducibles
- ‚úÖ Validaci√≥n por pares
- ‚úÖ Debugging m√°s f√°cil
- ‚úÖ Cumple est√°ndares cient√≠ficos

---

## 2. Captura y An√°lisis de Trazas PCAP

### ¬øQu√© es?
Captura de todos los paquetes transmitidos durante la simulaci√≥n para an√°lisis detallado.

### ¬øC√≥mo funciona?
El sistema habilita autom√°ticamente la captura PCAP en el c√≥digo generado.

### Archivos Generados

```
simulations/results/
‚îú‚îÄ‚îÄ simulacion-0-0_20251124_143022.pcap  # Nodo 0, interfaz 0
‚îú‚îÄ‚îÄ simulacion-0-1_20251124_143022.pcap  # Nodo 0, interfaz 1
‚îú‚îÄ‚îÄ simulacion-1-0_20251124_143022.pcap  # Nodo 1, interfaz 0
‚îî‚îÄ‚îÄ ...
```

### An√°lisis Autom√°tico

El agente **Trace Analyzer** analiza autom√°ticamente los archivos PCAP y genera:

- Estad√≠sticas b√°sicas (paquetes, bytes, duraci√≥n)
- Distribuci√≥n por protocolo (IP, UDP, TCP, ICMP, etc.)
- Detecci√≥n de protocolos de enrutamiento (AODV, OLSR, DSDV, DSR)
- C√°lculo de overhead de enrutamiento
- An√°lisis de latencias

### An√°lisis Manual con Wireshark

```bash
# Abrir archivo PCAP en Wireshark
wireshark simulations\results\simulacion-0-0_*.pcap

# Filtros √∫tiles:
# - Paquetes AODV: aodv
# - Paquetes UDP: udp
# - Paquetes de un nodo espec√≠fico: ip.src == 10.1.1.1
```

### An√°lisis Manual con Scapy

```python
from scapy.all import rdpcap, IP, UDP

# Leer archivo PCAP
packets = rdpcap('simulations/results/simulacion-0-0_*.pcap')

# Analizar paquetes
for pkt in packets:
    if IP in pkt:
        print(f"IP: {pkt[IP].src} ‚Üí {pkt[IP].dst}")
        if UDP in pkt:
            print(f"  UDP: {pkt[UDP].sport} ‚Üí {pkt[UDP].dport}")
```

### Beneficios
- ‚úÖ An√°lisis a nivel de paquetes
- ‚úÖ Detecci√≥n de problemas de red
- ‚úÖ Validaci√≥n de protocolos
- ‚úÖ An√°lisis forense de tr√°fico

---

## 3. Overhead de Enrutamiento

### ¬øQu√© es?
Ratio entre bytes de control (enrutamiento) y bytes de datos.

```
Overhead = Bytes_Control / Bytes_Datos
```

### ¬øC√≥mo se calcula?

#### M√©todo 1: Desde PCAP (Preciso)
El Trace Analyzer analiza los archivos PCAP y cuenta:
- Bytes de paquetes de enrutamiento (AODV, OLSR, etc.)
- Bytes de paquetes de datos (UDP, TCP)

#### M√©todo 2: Estimaci√≥n (Fallback)
Si no hay PCAP, se estima bas√°ndose en literatura:
- AODV: ~15%
- OLSR: ~35%
- DSDV: ~45%
- DSR: ~20%

### Interpretaci√≥n

```
Overhead < 20%  ‚Üí Excelente (protocolo eficiente)
Overhead 20-30% ‚Üí Bueno (aceptable)
Overhead 30-40% ‚Üí Regular (protocolo proactivo)
Overhead > 40%  ‚Üí Alto (considerar optimizaci√≥n)
```

### Ejemplo de Salida

```
üì° Calculando overhead de enrutamiento...
  üìä Overhead calculado desde PCAP: 0.152 (15.2%)
  ‚úì Overhead: 0.152 (15.2%)
```

### Uso en Tesis

```markdown
## Resultados

El protocolo AODV present√≥ un overhead de enrutamiento de 15.2%,
calculado a partir del an√°lisis de trazas PCAP. Este valor es
consistente con la literatura [1], que reporta overheads entre
10-20% para AODV en redes MANET.

[1] Perkins et al., "Ad hoc On-Demand Distance Vector Routing", 2003
```

---

## 4. Tests Estad√≠sticos

### ¬øQu√© son?
Pruebas para determinar si las diferencias observadas son estad√≠sticamente significativas.

### Tests Disponibles

#### T-Test (Dos Muestras)
Compara dos grupos para ver si sus medias son diferentes.

**Ejemplo**: Comparar PDR de flujos exitosos vs fallidos

```python
# El sistema ejecuta autom√°ticamente:
t_test_result = t_test_two_samples(
    successful_flows['pdr'].values,
    failed_flows['pdr'].values
)

# Resultado:
{
    't_statistic': 5.234,
    'p_value': 0.0001,
    'significant': True,
    'interpretation': 'Diferencia estad√≠sticamente significativa (p < 0.05)'
}
```

#### ANOVA (M√∫ltiples Grupos)
Compara tres o m√°s grupos.

**Ejemplo**: Comparar PDR entre diferentes protocolos

### Interpretaci√≥n de p-value

```
p < 0.001  ‚Üí Altamente significativo (***)
p < 0.01   ‚Üí Muy significativo (**)
p < 0.05   ‚Üí Significativo (*)
p ‚â• 0.05   ‚Üí No significativo (ns)
```

### Uso en Tesis

```markdown
## An√°lisis Estad√≠stico

Se realiz√≥ un t-test para comparar el PDR entre flujos exitosos
y fallidos. Los resultados muestran una diferencia estad√≠sticamente
significativa (t = 5.234, p < 0.001), indicando que los flujos
exitosos tienen un PDR significativamente mayor.
```

---

## 5. Intervalos de Confianza

### ¬øQu√© son?
Rango de valores donde se espera que est√© el valor real con cierta probabilidad (95%).

### Formato

```
M√©trica: [L√≠mite Inferior, L√≠mite Superior]
```

### Ejemplo de Salida

```
üìä Calculando intervalos de confianza (95% CI)...
  ‚úì Intervalos calculados para 3 m√©tricas
     pdr: [94.234, 96.876]
     avg_delay_ms: [45.321, 52.789]
     throughput_mbps: [2.123, 2.567]
```

### Interpretaci√≥n

```
PDR: [94.2%, 96.9%]
‚Üí Estamos 95% seguros de que el PDR real est√° entre 94.2% y 96.9%
‚Üí Rango estrecho = alta precisi√≥n
‚Üí Rango amplio = baja precisi√≥n (necesita m√°s datos)
```

### Uso en Tesis

```markdown
## Resultados

El PDR promedio fue de 95.5% (95% CI: [94.2%, 96.9%]), indicando
un rendimiento consistente y confiable del protocolo AODV en las
condiciones evaluadas.
```

---

## 6. Reportes Autom√°ticos

### Reporte Estad√≠stico

El sistema genera autom√°ticamente un reporte en Markdown:

```
simulations/analysis/statistical_report_20251124_143022.md
```

### Contenido del Reporte

```markdown
# Reporte Estad√≠stico - Simulaci√≥n NS-3

## Fecha: 2025-11-24 14:30:22

## Tests Estad√≠sticos

### T-Test: Flujos Exitosos vs Fallidos
- **Estad√≠stico t**: 5.234
- **p-value**: 0.0001
- **Significativo**: S√≠ (p < 0.05)
- **Interpretaci√≥n**: Diferencia estad√≠sticamente significativa

## Intervalos de Confianza (95%)

| M√©trica | L√≠mite Inferior | L√≠mite Superior | Rango |
|---------|----------------|-----------------|-------|
| PDR | 94.234% | 96.876% | 2.642% |
| Delay | 45.321 ms | 52.789 ms | 7.468 ms |
| Throughput | 2.123 Mbps | 2.567 Mbps | 0.444 Mbps |

## Conclusiones

Los resultados muestran un rendimiento consistente con intervalos
de confianza estrechos, indicando alta precisi√≥n en las mediciones.
```

### Uso del Reporte

1. **Copiar a tesis**: Incluir tablas y gr√°ficos directamente
2. **Validaci√≥n**: Verificar significancia estad√≠stica
3. **Comparaci√≥n**: Comparar con otros experimentos

---

## 7. Ejemplos Pr√°cticos

### Ejemplo 1: Simulaci√≥n B√°sica con Todas las Funcionalidades

```bash
# 1. Ejecutar simulaci√≥n
python main.py

# 2. Verificar archivos generados
dir simulations\results

# Deber√≠as ver:
# - sim_*.xml (FlowMonitor)
# - simulacion-*.pcap (Capturas PCAP)
# - sim_*_stdout.txt (Logs)

# 3. Verificar an√°lisis
dir simulations\analysis

# Deber√≠as ver:
# - statistical_report_*.md (Reporte estad√≠stico)

# 4. Abrir dashboard
start simulations\visualizations\dashboard.html
```

### Ejemplo 2: Comparar Dos Protocolos

```python
# Ejecutar simulaci√≥n con AODV
# Modificar tarea: "Simular MANET con AODV, 20 nodos"
python main.py

# Guardar resultados
copy simulations\results\sim_*.xml resultados_aodv.xml
copy simulations\analysis\statistical_report_*.md reporte_aodv.md

# Ejecutar simulaci√≥n con OLSR
# Modificar tarea: "Simular MANET con OLSR, 20 nodos"
python main.py

# Guardar resultados
copy simulations\results\sim_*.xml resultados_olsr.xml
copy simulations\analysis\statistical_report_*.md reporte_olsr.md

# Comparar reportes
fc reporte_aodv.md reporte_olsr.md
```

### Ejemplo 3: Validaci√≥n Estad√≠stica con M√∫ltiples Semillas

```python
# Script personalizado: run_multiple_seeds.py

seeds = [12345, 23456, 34567, 45678, 56789]
results = []

for seed in seeds:
    print(f"\n{'='*80}")
    print(f"Ejecutando con semilla: {seed}")
    print(f"{'='*80}\n")
    
    # Ejecutar simulaci√≥n con esta semilla
    # (modificar c√≥digo generado o pasar como par√°metro)
    
    # Guardar resultados
    results.append({
        'seed': seed,
        'pdr': ...,  # Extraer de resultados
        'delay': ...,
        'throughput': ...
    })

# Calcular estad√≠sticas agregadas
import pandas as pd
df = pd.DataFrame(results)

print("\n" + "="*80)
print("RESULTADOS AGREGADOS")
print("="*80)
print(f"PDR: {df['pdr'].mean():.2f}% ¬± {df['pdr'].std():.2f}%")
print(f"Delay: {df['delay'].mean():.2f} ms ¬± {df['delay'].std():.2f} ms")
print(f"Throughput: {df['throughput'].mean():.3f} Mbps ¬± {df['throughput'].std():.3f} Mbps")
```

### Ejemplo 4: An√°lisis Profundo de PCAP

```python
from scapy.all import rdpcap, IP, UDP
import pandas as pd

# Leer todos los archivos PCAP
pcap_files = list(Path('simulations/results').glob('simulacion-*.pcap'))

all_packets = []
for pcap_file in pcap_files:
    packets = rdpcap(str(pcap_file))
    
    for pkt in packets:
        if IP in pkt:
            all_packets.append({
                'time': float(pkt.time),
                'src': pkt[IP].src,
                'dst': pkt[IP].dst,
                'protocol': pkt[IP].proto,
                'size': len(pkt)
            })

# Crear DataFrame
df = pd.DataFrame(all_packets)

# An√°lisis
print(f"Total paquetes: {len(df)}")
print(f"Bytes totales: {df['size'].sum():,}")
print(f"\nDistribuci√≥n por protocolo:")
print(df['protocol'].value_counts())

# An√°lisis temporal
df['time_relative'] = df['time'] - df['time'].min()
print(f"\nDuraci√≥n: {df['time_relative'].max():.2f} segundos")
print(f"Tasa promedio: {len(df) / df['time_relative'].max():.2f} paquetes/segundo")
```

---

## üéì Checklist para Tesis Doctoral

### Antes de Ejecutar Simulaciones

- [ ] Verificar que NS-3 est√© instalado correctamente
- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Definir semillas para reproducibilidad
- [ ] Planificar n√∫mero de repeticiones (m√≠nimo 5)

### Durante las Simulaciones

- [ ] Verificar generaci√≥n de archivos PCAP
- [ ] Monitorear logs de simulaci√≥n
- [ ] Guardar resultados de cada ejecuci√≥n

### Despu√©s de las Simulaciones

- [ ] Revisar reportes estad√≠sticos generados
- [ ] Verificar intervalos de confianza (rangos estrechos = bueno)
- [ ] Validar significancia estad√≠stica (p < 0.05)
- [ ] Calcular overhead de enrutamiento
- [ ] Generar gr√°ficos para tesis

### Para la Tesis

- [ ] Incluir tabla de resultados con intervalos de confianza
- [ ] Reportar tests estad√≠sticos (t-test, ANOVA)
- [ ] Incluir gr√°ficos de m√©tricas clave
- [ ] Documentar overhead de enrutamiento
- [ ] Mencionar reproducibilidad (semillas usadas)

---

## üìö Referencias

### Papers Relevantes

1. **AODV**: Perkins et al., "Ad hoc On-Demand Distance Vector Routing", RFC 3561, 2003
2. **OLSR**: Clausen et al., "Optimized Link State Routing Protocol", RFC 3626, 2003
3. **Statistical Analysis**: Montgomery, "Design and Analysis of Experiments", 2017

### Herramientas

- **NS-3**: https://www.nsnam.org/
- **Scapy**: https://scapy.net/
- **Wireshark**: https://www.wireshark.org/
- **SciPy**: https://scipy.org/

---

## üí° Tips y Mejores Pr√°cticas

### Reproducibilidad
- Siempre usar semillas fijas para experimentos finales
- Documentar todas las semillas usadas
- Ejecutar m√≠nimo 5 repeticiones con diferentes semillas

### An√°lisis Estad√≠stico
- Verificar normalidad de datos antes de t-test
- Usar ANOVA para comparar m√°s de 2 grupos
- Reportar siempre intervalos de confianza

### PCAP
- Los archivos PCAP pueden ser grandes (>100MB)
- Comprimir antes de archivar: `gzip *.pcap`
- Analizar solo cuando sea necesario

### Overhead
- Comparar con valores de literatura
- Considerar tipo de red (MANET, VANET, WSN)
- Overhead alto no siempre es malo (depende del contexto)

---

**Versi√≥n**: 1.3  
**Fecha**: 24 de Noviembre de 2025  
**Autor**: Sistema A2A
