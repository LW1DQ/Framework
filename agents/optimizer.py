"""
Agente Optimizador

Responsable de proponer y generar c√≥digo optimizado basado en los resultados
de simulaciones previas. Usa t√©cnicas de Deep Learning para mejorar protocolos.
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from typing import Dict, List
from langchain_ollama import ChatOllama

from config.settings import OLLAMA_BASE_URL, MODEL_REASONING, MODEL_CODING
from utils.state import AgentState, add_audit_entry
from agents.ns3_ai_integration import (
    generate_ns3_ai_code,
    generate_drl_training_code,
    should_use_drl
)


def analyze_performance_bottlenecks(kpis: Dict) -> Dict:
    """
    Analiza KPIs para identificar cuellos de botella espec√≠ficos
    
    Args:
        kpis: Diccionario de KPIs
        
    Returns:
        Diccionario con an√°lisis de problemas
    """
    bottlenecks = {
        'critical': [],
        'moderate': [],
        'minor': []
    }
    
    # Analizar PDR
    pdr = kpis.get('avg_pdr', 100)
    if pdr < 70:
        bottlenecks['critical'].append({
            'metric': 'PDR',
            'value': pdr,
            'issue': 'PDR muy bajo - p√©rdida excesiva de paquetes',
            'causes': [
                'Congesti√≥n de red',
                'Colisiones frecuentes',
                'Rutas inestables',
                'Overhead del protocolo'
            ],
            'priority': 1
        })
    elif pdr < 85:
        bottlenecks['moderate'].append({
            'metric': 'PDR',
            'value': pdr,
            'issue': 'PDR sub√≥ptimo',
            'causes': ['Rutas no √≥ptimas', 'Movilidad alta'],
            'priority': 2
        })
    
    # Analizar Delay
    delay = kpis.get('avg_delay', 0)
    if delay > 200:
        bottlenecks['critical'].append({
            'metric': 'Delay',
            'value': delay,
            'issue': 'Latencia excesiva',
            'causes': [
                'Rutas largas',
                'Congesti√≥n',
                'Retransmisiones',
                'Procesamiento lento'
            ],
            'priority': 1
        })
    elif delay > 100:
        bottlenecks['moderate'].append({
            'metric': 'Delay',
            'value': delay,
            'issue': 'Latencia alta',
            'causes': ['Rutas no √≥ptimas', 'Colas largas'],
            'priority': 2
        })
    
    # Analizar Throughput
    throughput = kpis.get('avg_throughput', 0)
    if throughput < 0.5:
        bottlenecks['critical'].append({
            'metric': 'Throughput',
            'value': throughput,
            'issue': 'Throughput muy bajo',
            'causes': [
                'Ancho de banda limitado',
                'P√©rdida de paquetes',
                'Congesti√≥n severa'
            ],
            'priority': 1
        })
    elif throughput < 1.0:
        bottlenecks['moderate'].append({
            'metric': 'Throughput',
            'value': throughput,
            'issue': 'Throughput sub√≥ptimo',
            'causes': ['Uso ineficiente del canal', 'Overhead'],
            'priority': 2
        })
    
    # Analizar variabilidad
    std_pdr = kpis.get('std_pdr', 0)
    if std_pdr > 20:
        bottlenecks['moderate'].append({
            'metric': 'Variabilidad PDR',
            'value': std_pdr,
            'issue': 'Alta variabilidad en PDR',
            'causes': ['Inestabilidad de rutas', 'Movilidad'],
            'priority': 2
        })
    
    # Analizar tasa de √©xito
    success_rate = kpis.get('success_rate', 100)
    if success_rate < 80:
        bottlenecks['critical'].append({
            'metric': 'Success Rate',
            'value': success_rate,
            'issue': 'Muchos flujos fallidos',
            'causes': ['Desconexiones', 'Rutas no encontradas'],
            'priority': 1
        })
    
    return bottlenecks


def propose_dl_architecture(bottlenecks: Dict, task: str) -> str:
    """
    Propone arquitectura de Deep Learning espec√≠fica para los problemas detectados
    
    Args:
        bottlenecks: An√°lisis de cuellos de botella
        task: Tarea original
        
    Returns:
        Propuesta de arquitectura
    """
    try:
        llm = ChatOllama(
            model=MODEL_REASONING,
            temperature=0.2,
            base_url=OLLAMA_BASE_URL
        )
        
        # Preparar resumen de problemas
        problems_summary = []
        
        if bottlenecks['critical']:
            problems_summary.append("**PROBLEMAS CR√çTICOS:**")
            for b in bottlenecks['critical']:
                problems_summary.append(f"- {b['metric']}: {b['issue']} (valor: {b['value']:.2f})")
                problems_summary.append(f"  Causas: {', '.join(b['causes'])}")
        
        if bottlenecks['moderate']:
            problems_summary.append("\n**PROBLEMAS MODERADOS:**")
            for b in bottlenecks['moderate']:
                problems_summary.append(f"- {b['metric']}: {b['issue']} (valor: {b['value']:.2f})")
        
        problems_text = "\n".join(problems_summary)
        
        prompt = f"""
Eres un experto en Deep Reinforcement Learning aplicado a redes de telecomunicaciones.

**TAREA ORIGINAL:**
{task}

**AN√ÅLISIS DE PROBLEMAS DETECTADOS:**
{problems_text}

**OBJETIVO:**
Dise√±a una arquitectura de Deep Learning ESPEC√çFICA para resolver estos problemas.

**PROPUESTA REQUERIDA:**

1. **Tipo de Arquitectura Recomendada**:
   - DQN (Deep Q-Network) - para decisiones discretas de enrutamiento
   - DDPG (Deep Deterministic Policy Gradient) - para control continuo
   - A3C (Asynchronous Advantage Actor-Critic) - para entornos distribuidos
   - GNN (Graph Neural Network) - para topolog√≠as din√°micas
   - Transformer - para secuencias temporales
   
   Justifica tu elecci√≥n bas√°ndote en los problemas espec√≠ficos detectados.

2. **Dise√±o del Espacio de Estados** (qu√© observa el agente):
   ```
   Estado = [
       # Informaci√≥n local del nodo
       buffer_occupancy,      # 0-1
       num_neighbors,         # entero
       energy_level,          # 0-1 (si aplica)
       
       # Informaci√≥n de vecinos
       neighbor_distances,    # array de distancias
       neighbor_loads,        # array de cargas
       
       # M√©tricas hist√≥ricas
       recent_pdr,           # √∫ltimos N paquetes
       recent_delay,         # promedio reciente
       
       # Informaci√≥n de destino
       distance_to_dest,     # distancia euclidiana
       hops_to_dest,         # n√∫mero de saltos
   ]
   ```
   Dimensionalidad total: X valores

3. **Dise√±o del Espacio de Acciones** (qu√© puede decidir):
   ```
   Acciones = {{
       'select_next_hop': [0, 1, 2, ..., N-1],  # ID del vecino
       'adjust_tx_power': [0.1, 0.5, 1.0],      # niveles de potencia
       'set_priority': [0, 1, 2],                # prioridad del paquete
   }}
   ```

4. **Funci√≥n de Recompensa** (ecuaci√≥n matem√°tica):
   ```
   R(t) = w1 * PDR_improvement 
        - w2 * normalized_delay 
        - w3 * energy_consumption
        + w4 * throughput_gain
        - w5 * routing_overhead
   
   Donde:
   - w1 = 0.4 (peso para PDR)
   - w2 = 0.3 (peso para delay)
   - w3 = 0.1 (peso para energ√≠a)
   - w4 = 0.15 (peso para throughput)
   - w5 = 0.05 (peso para overhead)
   ```
   
   Ajusta los pesos seg√∫n los problemas detectados.

5. **Arquitectura de Red Neuronal**:
   ```
   Input Layer: [estado_dim]
   Hidden Layer 1: [256 neurons, ReLU]
   Hidden Layer 2: [128 neurons, ReLU]
   Hidden Layer 3: [64 neurons, ReLU]
   Output Layer: [accion_dim, Softmax/Linear]
   ```

6. **Hiperpar√°metros de Entrenamiento**:
   - Learning rate: 0.001
   - Batch size: 64
   - Replay buffer: 10000
   - Epsilon decay: 0.995
   - Gamma (discount): 0.99
   - Target network update: cada 100 steps

7. **Estrategia de Entrenamiento**:
   - Episodios: 2000-5000
   - Duraci√≥n por episodio: 100-200s simulados
   - Exploraci√≥n: Œµ-greedy con decay
   - Criterio de convergencia: recompensa promedio estable por 100 episodios

8. **Integraci√≥n con NS-3**:
   - Usar ns3-ai para comunicaci√≥n Python-C++
   - Frecuencia de decisiones: cada paquete / cada N paquetes
   - Sincronizaci√≥n: s√≠ncrona vs as√≠ncrona

**FORMATO:**
S√© extremadamente espec√≠fico. Incluye valores num√©ricos concretos.
Prioriza soluciones para los problemas cr√≠ticos detectados.
"""
        
        response = llm.invoke(prompt)
        return response.content
        
    except Exception as e:
        return f"Error generando propuesta: {str(e)}"


def generate_optimization_code(architecture_proposal: str, baseline_code: str, task: str) -> str:
    """
    Genera c√≥digo optimizado basado en la propuesta de arquitectura
    
    Args:
        architecture_proposal: Propuesta de arquitectura DL
        baseline_code: C√≥digo baseline original
        task: Tarea original
        
    Returns:
        C√≥digo optimizado
    """
    try:
        llm = ChatOllama(
            model=MODEL_CODING,
            temperature=0.1,
            base_url=OLLAMA_BASE_URL
        )
        
        prompt = f"""
Eres un experto en NS-3 y Deep Learning. Genera c√≥digo OPTIMIZADO basado en la propuesta.

**TAREA:**
{task}

**PROPUESTA DE ARQUITECTURA DL:**
{architecture_proposal[:1500]}

**C√ìDIGO BASELINE (referencia):**
```python
{baseline_code[:1000]}
```

**OBJETIVO:**
Genera un script NS-3 MEJORADO que implemente optimizaciones basadas en la propuesta.

**OPTIMIZACIONES A IMPLEMENTAR:**

1. **Ajustes de Par√°metros del Protocolo**:
   - Ajustar intervalos de HELLO/TC
   - Optimizar tama√±os de buffer
   - Ajustar potencia de transmisi√≥n

2. **Mejoras en Configuraci√≥n**:
   - Usar protocolo m√°s adecuado si es necesario
   - Optimizar modelo de movilidad
   - Ajustar par√°metros WiFi

3. **Preparaci√≥n para DL** (comentado, para futura implementaci√≥n):
   - Puntos de instrumentaci√≥n para observar estado
   - Puntos de decisi√≥n para acciones del agente
   - Logging de m√©tricas para entrenamiento

**ESTRUCTURA DEL C√ìDIGO:**
```python
#!/usr/bin/env python3
import sys
sys.path.insert(0, 'build/lib/python3')

import ns.core
import ns.network
import ns.internet
import ns.wifi
import ns.mobility
import ns.applications
import ns.flow_monitor
# import ns.aodv / ns.olsr seg√∫n corresponda

def main():
    # Configuraci√≥n OPTIMIZADA
    # ... par√°metros ajustados seg√∫n an√°lisis
    
    # TODO: Integraci√≥n futura con DL
    # - Observar: buffer, vecinos, m√©tricas
    # - Decidir: next hop, potencia, prioridad
    # - Recompensar: seg√∫n funci√≥n propuesta
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
```

**IMPORTANTE:**
- Mant√©n compatibilidad con NS-3 Python bindings
- Incluye comentarios explicando las optimizaciones
- El c√≥digo debe ser EJECUTABLE inmediatamente
- Las mejoras de DL son preparatorias (comentadas)

Devuelve SOLO el c√≥digo Python completo.
"""
        
        response = llm.invoke(prompt)
        
        # Extraer c√≥digo
        import re
        code_pattern = r'```python\n(.*?)\n```'
        matches = re.findall(code_pattern, response.content, re.DOTALL)
        
        if matches:
            return matches[0].strip()
        
        # Si no hay bloques markdown, buscar solo ```
        code_pattern = r'```\n(.*?)\n```'
        matches = re.findall(code_pattern, response.content, re.DOTALL)
        
        if matches:
            return matches[0].strip()
        
        return response.content.strip()
        
    except Exception as e:
        return f"# Error generando c√≥digo optimizado: {str(e)}"


def extract_drl_parameters(optimization_proposal: str) -> Dict:
    """
    Extrae par√°metros de DRL de la propuesta del optimizer
    
    Args:
        optimization_proposal: Texto de la propuesta
        
    Returns:
        Diccionario con par√°metros PPO
    """
    params = {
        'algorithm': 'PPO',
        'learning_rate': 0.0003,
        'gamma': 0.99,
        'eps_clip': 0.2,
        'k_epochs': 4,
        'batch_size': 32,
        'state_dim': 10,
        'action_dim': 5
    }
    
    return params


def optimizer_node(state: AgentState) -> Dict:
    """
    Nodo del agente optimizador para LangGraph
    
    Args:
        state: Estado actual del sistema
        
    Returns:
        Diccionario con actualizaciones al estado
    """
    print("\n" + "="*80)
    print("üöÄ AGENTE OPTIMIZADOR ACTIVADO")
    print("="*80)
    
    # Verificar que haya m√©tricas para analizar
    kpis = state.get('metrics', {})
    
    if not kpis:
        print("‚ö†Ô∏è  No hay m√©tricas para optimizar")
        return {
            'messages': ['No hay m√©tricas disponibles para optimizaci√≥n'],
            **add_audit_entry(state, "optimizer", "no_metrics", {})
        }
    
    task = state.get('task', '')
    baseline_code = state.get('code_snippet', '')
    
    print(f"üìã Tarea: {task}")
    print(f"üìä Analizando rendimiento actual...")
    print(f"   PDR: {kpis.get('avg_pdr', 0):.2f}%")
    print(f"   Delay: {kpis.get('avg_delay', 0):.2f} ms")
    print(f"   Throughput: {kpis.get('avg_throughput', 0):.3f} Mbps")
    print(f"   Clasificaci√≥n: {kpis.get('performance_grade', 'N/A')}")
    print()
    
    # Paso 1: Analizar cuellos de botella
    print("üîç Identificando cuellos de botella...")
    bottlenecks = analyze_performance_bottlenecks(kpis)
    
    critical_count = len(bottlenecks['critical'])
    moderate_count = len(bottlenecks['moderate'])
    
    print(f"   Problemas cr√≠ticos: {critical_count}")
    print(f"   Problemas moderados: {moderate_count}")
    
    if critical_count > 0:
        print(f"\n   ‚ö†Ô∏è  PROBLEMAS CR√çTICOS DETECTADOS:")
        for b in bottlenecks['critical']:
            print(f"      - {b['metric']}: {b['issue']}")
    
    if moderate_count > 0:
        print(f"\n   ‚ÑπÔ∏è  Problemas moderados:")
        for b in bottlenecks['moderate']:
            print(f"      - {b['metric']}: {b['issue']}")
    
    # Si no hay problemas significativos, no optimizar
    if critical_count == 0 and moderate_count == 0:
        print("\n‚úÖ Rendimiento √≥ptimo. No se requieren optimizaciones.")
        return {
            'optimization_proposal': 'Rendimiento √≥ptimo - no se requieren cambios',
            'optimized_code': baseline_code,
            'messages': ['Rendimiento √≥ptimo alcanzado'],
            **add_audit_entry(state, "optimizer", "optimal_performance", {
                'kpis': kpis
            })
        }
    
    # Paso 2: Proponer arquitectura DL
    print(f"\nüß† Dise√±ando arquitectura de Deep Learning...")
    architecture_proposal = propose_dl_architecture(bottlenecks, task)
    print(f"   ‚úì Propuesta generada ({len(architecture_proposal)} caracteres)")
    
    # Paso 3: Determinar si usar DRL
    print(f"\nü§ñ Evaluando necesidad de Deep Reinforcement Learning...")
    use_drl = should_use_drl(kpis)
    
    if use_drl:
        print(f"   ‚úÖ DRL recomendado para estos problemas")
        print(f"   üìö Generando c√≥digo con integraci√≥n ns3-ai...")
        
        # Extraer par√°metros de la propuesta
        drl_params = extract_drl_parameters(architecture_proposal)
        
        # Generar c√≥digo con ns3-ai
        # Extraer par√°metros de la tarea
        import re
        nodes_match = re.search(r'(\d+)\s*nodos', task, re.IGNORECASE)
        area_match = re.search(r'(\d+)x(\d+)', task, re.IGNORECASE)
        protocol_match = re.search(r'(AODV|OLSR|DSDV|DSR)', task, re.IGNORECASE)
        
        nodes = int(nodes_match.group(1)) if nodes_match else 20
        area_size = int(area_match.group(1)) if area_match else 1000
        protocol = protocol_match.group(1) if protocol_match else 'AODV'
        
        optimized_code = generate_ns3_ai_code(protocol, nodes, area_size)
        
        # Tambi√©n generar c√≥digo de entrenamiento
        training_code = generate_drl_training_code(protocol)
        
        # Guardar c√≥digo de entrenamiento
        from pathlib import Path
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        training_file = Path("sistema-a2a-tesis/simulations/scripts") / f"train_drl_{timestamp}.py"
        training_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(training_file, 'w', encoding='utf-8') as f:
            f.write(training_code)
        
        print(f"   ‚úì C√≥digo DRL generado")
        print(f"   ‚úì Script de entrenamiento: {training_file.name}")
    else:
        print(f"   ‚ÑπÔ∏è  DRL no necesario - optimizaci√≥n param√©trica suficiente")
        print(f"\nüíª Generando c√≥digo optimizado...")
        optimized_code = generate_optimization_code(
            architecture_proposal,
            baseline_code,
            task
        )
        print(f"   ‚úì C√≥digo optimizado generado ({len(optimized_code)} caracteres)")
    
    # Guardar propuesta y c√≥digo
    from pathlib import Path
    import datetime
    
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Guardar propuesta de arquitectura
    proposal_file = Path("sistema-a2a-tesis/simulations/optimizations") / f"proposal_{timestamp}.md"
    proposal_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(proposal_file, 'w', encoding='utf-8') as f:
        f.write(f"# Propuesta de Optimizaci√≥n\n\n")
        f.write(f"**Fecha:** {timestamp}\n")
        f.write(f"**Tarea:** {task}\n\n")
        f.write(f"## M√©tricas Baseline\n\n")
        f.write(f"- PDR: {kpis.get('avg_pdr', 0):.2f}%\n")
        f.write(f"- Delay: {kpis.get('avg_delay', 0):.2f} ms\n")
        f.write(f"- Throughput: {kpis.get('avg_throughput', 0):.3f} Mbps\n")
        f.write(f"- Clasificaci√≥n: {kpis.get('performance_grade', 'N/A')}\n\n")
        f.write(f"## Problemas Detectados\n\n")
        
        if bottlenecks['critical']:
            f.write(f"### Cr√≠ticos\n\n")
            for b in bottlenecks['critical']:
                f.write(f"- **{b['metric']}**: {b['issue']}\n")
                f.write(f"  - Valor: {b['value']:.2f}\n")
                f.write(f"  - Causas: {', '.join(b['causes'])}\n\n")
        
        if bottlenecks['moderate']:
            f.write(f"### Moderados\n\n")
            for b in bottlenecks['moderate']:
                f.write(f"- **{b['metric']}**: {b['issue']}\n\n")
        
        f.write(f"\n## Propuesta de Arquitectura DL\n\n")
        f.write(architecture_proposal)
    
    print(f"   üìÑ Propuesta guardada en: {proposal_file.name}")
    
    # Guardar c√≥digo optimizado
    code_file = Path("sistema-a2a-tesis/simulations/scripts") / f"optimized_{timestamp}.py"
    code_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(code_file, 'w', encoding='utf-8') as f:
        f.write(optimized_code)
    
    print(f"   üíæ C√≥digo guardado en: {code_file.name}")
    
    print(f"\n{'='*80}")
    print(f"‚úÖ OPTIMIZACI√ìN COMPLETADA")
    print(f"{'='*80}")
    print(f"Problemas detectados: {critical_count + moderate_count}")
    print(f"Propuesta: {proposal_file.name}")
    print(f"C√≥digo optimizado: {code_file.name}")
    print(f"üîÑ El c√≥digo optimizado ser√° regenerado por el Agente Programador")
    print(f"{'='*80}")
    
    # Importar funci√≥n para incrementar contador
    from utils.state import increment_optimization_count
    
    # Forzar regeneraci√≥n de c√≥digo: resetear validaci√≥n y actualizar notas
    return {
        'optimization_proposal': architecture_proposal,
        'code_snippet': '',  # Resetear para forzar regeneraci√≥n
        'code_validated': False,  # Forzar nueva validaci√≥n
        'research_notes': [f"OPTIMIZACI√ìN REQUERIDA:\n{architecture_proposal[:500]}..."],  # A√±adir contexto
        'bottlenecks': bottlenecks,
        'optimization_files': {
            'proposal': str(proposal_file),
            'code': str(code_file)
        },
        'messages': [
            f'Optimizaci√≥n propuesta: {critical_count} problemas cr√≠ticos, {moderate_count} moderados',
            'C√≥digo ser√° regenerado con optimizaciones aplicadas'
        ],
        **increment_optimization_count(state),
        **add_audit_entry(state, "optimizer", "optimization_completed", {
            'critical_issues': critical_count,
            'moderate_issues': moderate_count,
            'proposal_file': str(proposal_file),
            'code_file': str(code_file),
            'optimization_cycle': state.get('optimization_count', 0) + 1
        })
    }


if __name__ == "__main__":
    # Prueba del agente
    from utils.state import create_initial_state
    
    test_state = create_initial_state("Optimizar AODV con 20 nodos")
    
    # Simular m√©tricas pobres
    test_state['metrics'] = {
        'avg_pdr': 65.5,
        'std_pdr': 15.2,
        'avg_delay': 150.3,
        'avg_throughput': 0.45,
        'success_rate': 70.0,
        'performance_grade': 'Pobre'
    }
    
    test_state['code_snippet'] = "# C√≥digo baseline de prueba"
    
    result = optimizer_node(test_state)
    
    print("\n" + "="*80)
    print("RESULTADO DE PRUEBA")
    print("="*80)
    print(f"Propuesta generada: {len(result.get('optimization_proposal', ''))> 0}")
    print(f"C√≥digo optimizado: {len(result.get('optimized_code', '')) > 0}")
    print(f"Archivos: {result.get('optimization_files', {})}")
