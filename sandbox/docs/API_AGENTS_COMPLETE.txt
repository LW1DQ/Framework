COMPLETE API DOCUMENTATION FOR ALL AGENTS

This file contains the complete documentation that should be added to docs/API.md

=== RESEARCHER AGENT (COMPLETE) ===

Main Functions:
- research_node(state) -> Dict
- search_semantic_scholar(query, max_results=10) -> List[Dict]
- calculate_relevance_score(paper) -> float
- store_in_chromadb(papers, collection_name)
- synthesize_research(task, papers) -> str
- query_vectordb(query, collection_name, n_results=5) -> List
- search_arxiv(query, max_results=5) -> List[Dict]

=== CODER AGENT (COMPLETE) ===

Main Functions:
- coder_node(state) -> Dict
- generate_code(task, research_notes, previous_error, error_type, iteration) -> str
- extract_code_from_response(response) -> str
- validate_code(code) -> Tuple[bool, str]
- ensure_basic_imports(code) -> str
- generate_fallback_code(task) -> str
- save_code(code, filename) -> str

=== SIMULATOR AGENT (COMPLETE) ===

Main Functions:
- simulator_node(state) -> Dict
- validate_code_before_execution(code) -> Tuple[bool, str]
- extract_simulation_info(stdout) -> Dict

=== TRACE ANALYZER AGENT (COMPLETE) ===

Main Functions:
- trace_analyzer_node(state) -> Dict
- check_tshark_available() -> bool
- analyze_pcap_basic_stats(pcap_file) -> Dict
- analyze_pcap_protocols(pcap_file) -> Dict
- analyze_pcap_conversations(pcap_file) -> List[Dict]
- analyze_pcap_routing_packets(pcap_file, protocol) -> Dict
- analyze_pcap_retransmissions(pcap_file) -> Dict
- generate_trace_analysis_report(pcap_file, protocol) -> str

=== ANALYST AGENT (COMPLETE) ===

Main Functions:
- analyst_node(state) -> Dict
- parse_flowmonitor_xml(xml_path) -> pd.DataFrame
- calculate_kpis(df) -> Dict
- calculate_routing_overhead(df, trace_analysis) -> float
- classify_performance(kpis) -> str
- propose_optimization(kpis, task) -> str

=== VISUALIZER AGENT (COMPLETE) ===

Main Functions:
- visualizer_node(state) -> Dict
- create_plots(df, kpis) -> List[str]
- get_pdr_grade(pdr) -> str
- get_delay_grade(delay) -> str

=== OPTIMIZER AGENT (COMPLETE) ===

Main Functions:
- optimizer_node(state) -> Dict
- analyze_performance_bottlenecks(kpis) -> Dict
- propose_dl_architecture(bottlenecks, task) -> str
- generate_optimization_code(architecture_proposal, baseline_code, task) -> str
- extract_drl_parameters(optimization_proposal) -> Dict

=== CRITIC AGENT (COMPLETE) ===

Main Functions:
- critic_node(state) -> Dict

=== GITHUB MANAGER AGENT (COMPLETE) ===

Class: GitHubManager
Methods:
- __init__(repo_path)
- is_git_repo() -> bool
- init_repo() -> bool
- get_current_branch() -> Optional[str]
- create_branch(branch_name, from_branch) -> bool
- switch_branch(branch_name) -> bool
- get_status() -> Dict
- add_files(files) -> bool
- commit(message, description) -> bool
- push(branch, force) -> bool
- pull(branch) -> bool
- merge_branch(source_branch, target_branch) -> bool
- delete_branch(branch_name, force) -> bool
- create_tag(tag_name, message) -> bool
- get_commit_history(limit) -> List[Dict]

Functions:
- create_experiment_report(state) -> str
- github_manager_node(state) -> Dict

=== NS3-AI INTEGRATION AGENT (COMPLETE) ===

Classes:
- ActorCritic(nn.Module)
- NS3AIAgent

Functions:
- generate_ns3_ai_code(protocol, nodes, area_size) -> str
- generate_drl_training_code(protocol) -> str
- should_use_drl(metrics) -> bool
- extract_drl_parameters(proposal) -> Dict
- get_ns3_ai_installation_instructions() -> str

=== UTILITIES (COMPLETE) ===

State Management (utils/state.py):
- create_initial_state(task, max_iterations) -> AgentState
- add_audit_entry(state, agent, action, details) -> Dict
- increment_iteration(state) -> Dict
- increment_optimization_count(state) -> Dict

Logging (utils/logging_utils.py):
- setup_logging(log_dir)
- log_message(agent, message, level)
- update_agent_status(agent, status, details)
- set_system_status(status, **kwargs)
- log_metric(metric_name, value, step)

Memory (utils/memory.py):
- EpisodicMemory class with methods:
  - add_experience(task, code, error, solution)
  - retrieve_experience(task, error, top_k) -> List[Dict]
  - get_all_experiences() -> List[Dict]
  - clear_memory()

Statistical Tests (utils/statistical_tests.py):
- t_test_two_samples(sample1, sample2, alpha) -> Dict
- anova_test(samples, alpha) -> Dict
- calculate_confidence_interval(data, confidence) -> Tuple
- calculate_all_confidence_intervals(df, metrics, confidence) -> Dict
- generate_statistical_report(results) -> str

Error Classes (utils/errors.py):
- A2AError(Exception)
- CompilationError(A2AError)
- SimulationError(A2AError)
- TimeoutError(A2AError)
- ValidationError(A2AError)

=== CONFIGURATION (COMPLETE) ===

Module: config/settings.py

Paths:
- PROJECT_ROOT, DATA_DIR, SIMULATIONS_DIR, LOGS_DIR, CHROMA_PATH, NS3_ROOT

Ollama Settings:
- OLLAMA_BASE_URL, MODEL_REASONING, MODEL_CODING, MODEL_EMBEDDING
- MODEL_TEMPERATURE_REASONING, MODEL_TEMPERATURE_CODING

Simulation Settings:
- SIMULATION_TIMEOUT, MAX_RETRIES

API Settings:
- SEMANTIC_SCHOLAR_MAX_RESULTS

Plotting Settings:
- PLOT_DPI, PLOT_FIGSIZE

=== USAGE EXAMPLES ===

Basic Experiment:
```python
from supervisor import SupervisorOrchestrator
supervisor = SupervisorOrchestrator()
result = supervisor.run_experiment(
    task="Compare AODV and OLSR with 20 nodes",
    max_iterations=3
)
print(f"PDR: {result['metrics']['avg_pdr']:.2f}%")
```

Custom State:
```python
from utils.state import create_initial_state
from agents import research_node, coder_node
state = create_initial_state("Analyze AODV scalability")
state = research_node(state)
state = coder_node(state)
print(state['code_snippet'][:200])
```

Memory Usage:
```python
from utils.memory import memory
memory.add_experience(
    task="AODV simulation",
    code="...",
    error="ImportError: ns.aodv",
    solution="import ns.aodv"
)
experiences = memory.retrieve_experience(
    task="OLSR simulation",
    error="ImportError",
    top_k=3
)
```

END OF COMPLETE API DOCUMENTATION
