

=== Chapter_4_MultiAgent ===


--- Page 8 ---
brief contents
1 ■ Introduction to agents and their world 1
2 ■ Harnessing the power of large language models 14
3 ■ Engaging GPT assistants 39
4 ■ Exploring multi-agent systems 68
5 ■ Empowering agents with actions 98
6 ■ Building autonomous assistants 129
7 ■ Assembling and using an agent platform 160
8 ■ Understanding agent memory and knowledge 180
9 ■ Mastering agent prompts with prompt flow 212
10 ■ Agent reasoning and evaluation 244
11 ■ Agent planning and feedback 272
vvii

--- Page 9 ---
contents
preface xiii
acknowledgments xv
about this book xvii
about the author xxi
about the cover illustration xxii
1 Introduction to agents and their world 1
1.1 Defining agents 1
1.2 Understanding the component systems of an agent 4
1.3 Examining the rise of the agent era: Why agents? 9
1.4 Peeling back the AI interface 11
1.5 Navigating the agent landscape 12
2 Harnessing the power of large language models 14
2.1 Mastering the OpenAI API 16
Connecting to the chat completions model 16 ■ Understanding the
request and response 18
2.2 Exploring open source LLMs with LM Studio 20
Installing and running LM Studio 20 ■ Serving an LLM locally
with LM Studio 23
vii

--- Page 10 ---
viii CONTENTS
2.3 Prompting LLMs with prompt engineering 25
Creating detailed queries 28 ■ Adopting personas 29
Using delimiters 30 ■ Specifying steps 31 ■ Providing
examples 32 ■ Specifying output length 33
2.4 Choosing the optimal LLM for your specific needs 34
2.5 Exercises 36
3 Engaging GPT assistants 39
3.1 Exploring GPT assistants through ChatGPT 40
3.2 Building a GPT that can do data science 44
3.3 Customizing a GPT and adding custom actions 49
Creating an assistant to build an assistant 49 ■ Connecting the
custom action to an assistant 53
3.4 Extending an assistant’s knowledge using file uploads 56
Building the Calculus Made Easy GPT 56 ■ Knowledge search
and more with file uploads 58
3.5 Publishing your GPT 61
Expensive GPT assistants 62 ■ Understanding the economics of
GPTs 63 ■ Releasing the GPT 63
3.6 Exercises 65
4 Exploring multi-agent systems 68
4.1 Introducing multi-agent systems with AutoGen Studio 69
Installing and using AutoGen Studio 70 ■ Adding skills in
AutoGen Studio 72
4.2 Exploring AutoGen 77
Installing and consuming AutoGen 77 ■ Enhancing code output
with agent critics 79 ■ Understanding the AutoGen cache 81
4.3 Group chat with agents and AutoGen 82
4.4 Building an agent crew with CrewAI 84
Creating a jokester crew of CrewAI agents 84 ■ Observing agents
working with AgentOps 87
4.5 Revisiting coding agents with CrewAI 90
4.6 Exercises 95

--- Page 11 ---
CONTENTS ix
5 Empowering agents with actions 98
5.1 Defining agent actions 99
5.2 Executing OpenAI functions 101
Adding functions to LLM API calls 101 ■ Actioning function
calls 103
5.3 Introducing Semantic Kernel 107
Getting started with SK semantic functions 108 ■ Semantic
functions and context variables 109
5.4 Synergizing semantic and native functions 111
Creating and registering a semantic skill/plugin 111 ■ Applying
native functions 115 ■ Embedding native functions within
semantic functions 117
5.5 Semantic Kernel as an interactive service agent 118
Building a semantic GPT interface 119 ■ Testing semantic
services 121 ■ Interactive chat with the semantic service
layer 122
5.6 Thinking semantically when writing semantic
services 125
5.7 Exercises 127
6 Building autonomous assistants 129
6.1 Introducing behavior trees 130
Understanding behavior tree execution 131 ■ Deciding on
behavior trees 132 ■ Running behavior trees with Python
and py_trees 134
6.2 Exploring the GPT Assistants Playground 136
Installing and running the Playground 136 ■ Using and
building custom actions 138 ■ Installing the assistants
database 140 ■ Getting an assistant to run code locally 140
Investigating the assistant process through logs 142
6.3 Introducing agentic behavior trees 143
Managing assistants with assistants 143 ■ Building a coding
challenge ABT 145 ■ Conversational AI systems vs. other
methods 149 ■ Posting YouTube videos to X 150
Required X setup 151
6.4 Building conversational autonomous multi-agents 153

--- Page 12 ---
x CONTENTS
6.5 Building ABTs with back chaining 155
6.6 Exercises 156
7 Assembling and using an agent platform 160
7.1 Introducing Nexus, not just another agent platform 161
Running Nexus 162 ■ Developing Nexus 163
7.2 Introducing Streamlit for chat application
development 165
Building a Streamlit chat application 165 ■ Creating a streaming
chat application 168
7.3 Developing profiles and personas for agents 170
7.4 Powering the agent and understanding the agent
engine 172
7.5 Giving an agent actions and tools 174
7.6 Exercises 178
8 Understanding agent memory and knowledge 180
8.1 Understanding retrieval in AI applications 181
8.2 The basics of retrieval augmented generation (RAG) 182
8.3 Delving into semantic search and document
indexing 184
Applying vector similarity search 184 ■ Vector databases and
similarity search 188 ■ Demystifying document embeddings 189
Querying document embeddings from Chroma 190
8.4 Constructing RAG with LangChain 192
Splitting and loading documents with LangChain 192 ■ Splitting
documents by token with LangChain 195
8.5 Applying RAG to building agent knowledge 196
8.6 Implementing memory in agentic systems 200
Consuming memory stores in Nexus 202 ■ Semantic memory and
applications to semantic, episodic, and procedural memory 204
8.7 Understanding memory and knowledge
compression 207
8.8 Exercises 209

--- Page 13 ---
CONTENTS xi
9 Mastering agent prompts with prompt flow 212
9.1 Why we need systematic prompt engineering 213
9.2 Understanding agent profiles and personas 216
9.3 Setting up your first prompt flow 217
Getting started 218 ■ Creating profiles with Jinja2
templates 222 ■ Deploying a prompt flow API 223
9.4 Evaluating profiles: Rubrics and grounding 224
9.5 Understanding rubrics and grounding 228
9.6 Grounding evaluation with an LLM profile 230
9.7 Comparing profiles: Getting the perfect
profile 232
Parsing the LLM evaluation output 232 ■ Running batch
processing in prompt flow 235 ■ Creating an evaluation flow
for grounding 238 ■ Exercises 242
10 Agent reasoning and evaluation 244
10.1 Understanding direct solution prompting 245
Question-and-answer prompting 246 ■ Implementing few-shot
prompting 248 ■ Extracting generalities with zero-shot
prompting 250
10.2 Reasoning in prompt engineering 252
Chain of thought prompting 253 ■ Zero-shot CoT
prompting 257 ■ Step by step with prompt chaining 258
10.3 Employing evaluation for consistent solutions 261
Evaluating self-consistency prompting 262 ■ Evaluating tree of
thought prompting 266
10.4 Exercises 270
11 Agent planning and feedback 272
11.1 Planning: The essential tool for all agents/assistants 273
11.2 Understanding the sequential planning process 277
11.3 Building a sequential planner 278
11.4 Reviewing a stepwise planner: OpenAI Strawberry 285

--- Page 14 ---
xii CONTENTS
11.5 Applying planning, reasoning, evaluation, and feedback to
assistant and agentic systems 288
Application of assistant/agentic planning 288 ■ Application of
assistant/agentic reasoning 290 ■ Application of evaluation to
agentic systems 291 ■ Application of feedback to agentic/assistant
applications 293
11.6 Exercises 296
appendix A Accessing OpenAI large language models 299
appendix B Python development environment 305
index 311

--- Page 15 ---
preface
My journey into the world of intelligent systems began back in the early 1980s. Like
many people then, I believed artificial intelligence (AI) was just around the corner. It
always seemed like one more innovation and technological leap would lead us to the
intelligence we imagined. But that leap never came.
Perhaps the promise of HAL, from Stanley Kubrick’s 2001: A Space Odyssey, capti-
vated me with the idea of a truly intelligent computer companion. After years of effort,
trial, and countless errors, I began to understand that creating AI was far more com-
plex than we humans had imagined. In the early 1990s, I shifted my focus, applying
my skills to more tangible goals in other industries.
Not until the late 1990s, after experiencing a series of challenging and transforma-
tive events, did I realize my passion for building intelligent systems. I knew these sys-
tems might never reach the superintelligence of HAL, but I was okay with that. I
found fulfillment in working with machine learning and data science, creating models
that could learn and adapt. For more than 20 years, I thrived in this space, tackling
problems that required creativity, precision, and a sense of possibility.
During that time, I worked on everything from genetic algorithms for predicting
unknown inputs to developing generative learning models for horizontal drilling in
the oil-and-gas sector. These experiences led me to write, where I shared my knowl-
edge by way of books on various topics—reverse-engineering Pokémon Go, building
augmented and virtual reality experiences, designing audio for games, and applying
reinforcement learning to create intelligent agents. I spent years knuckles-deep in
code, developing agents in Unity ML-Agents and deep reinforcement learning.
xiii

--- Page 16 ---
xiv PREFACE
Even then, I never imagined that one day I could simply describe what I wanted to
an AI model, and it would make it happen. I never imagined that, in my lifetime, I
would be able to collaborate with an AI as naturally as I do today. And I certainly never
imagined how fast—and simultaneously how slow—this journey would feel.
In November 2022, the release of ChatGPT changed everything. It changed the
world’s perception of AI, and it changed the way we build intelligent systems. For me,
it also altered my perspective on the capabilities of these systems. Suddenly, the idea
of agents that could autonomously perform complex tasks wasn’t just a far-off dream
but instead a tangible, achievable reality. In some of my earlier books, I had described
agentic systems that could undertake specific tasks, but now, those once-theoretical
ideas were within reach.
This book is the culmination of my decades of experience in building intelligent
systems, but it’s also a realization of the dreams I once had about what AI could
become. AI agents are here, poised to transform how we interact with technology, how
we work, and, ultimately, how we live.
Yet, even now, I see hesitation from organizations when it comes to adopting agen-
tic systems. I believe this hesitation stems not from fear of AI but rather from a lack
of understanding and expertise in building these systems. I hope that this book
helps to bridge that gap. I want to introduce AI agents as tools that can be accessible
to everyone—tools we shouldn’t fear but instead respect, manage responsibly, and
learn to work with in harmony.

--- Page 17 ---
acknowledgments
I want to extend my deepest gratitude to the machine learning and deep learning
communities for their tireless dedication and incredible work. Just a few short years
ago, many questioned whether the field was headed for another AI winter—a period
of stagnation and doubt. But thanks to the persistence, brilliance, and passion of
countless individuals, the field not only persevered but also flourished. We’re standing
on the threshold of an AI-driven future, and I am endlessly grateful for the contribu-
tions of this talented community.
Writing a book, even with the help of AI, is no small feat. It takes dedication, col-
laboration, and a tremendous amount of support. I am incredibly thankful to the
team of editors and reviewers who made this book possible. I want to express my
heartfelt thanks to everyone who took the time to review and provide feedback. In
particular, I want to thank Becky Whitney, my content editor, and Ross Turner, my
technical editor and chief production and technology officer at OpenSC, for their
dedication, as well as the whole production team at Manning for their insight and
unwavering support throughout this journey.
To my partner, Rhonda—your love, patience, and encouragement mean the world
to me. You’ve been the cornerstone of my support system, not just for this book but
for all the books that have come before. I truly couldn’t have done any of this without
you. Thank you for being my rock, my partner, and my inspiration.
Many of the early ideas for this book grew out of my work at Symend. It was during
my time there that I first began developing the concepts and designs for agentic sys-
tems that laid the foundation for this book. I am deeply grateful to my colleagues at
xv

--- Page 18 ---
xvi ACKNOWLEDGMENTS
Symend for their collaboration and contributions, including Peh Teh, Andrew Wright,
Ziko Rajabali, Chris Garrett, Kouros, Fatemeh Torabi Asr, Sukh Singh, and Hanif
Joshaghani. Your insights and hard work helped bring these ideas to life, and I am
honored to have worked alongside such an incredible group of people.
Finally, I would like to thank all the reviewers: Anandaganesh Balakrishnan, Aryan
Jadon, Chau Giang, Dan Sheikh, David Curran, Dibyendu Roy Chowdhury, Divya
Bhargavi, Felipe Provezano Coutinho, Gary Pass, John Williams, Jose San Leandro,
Laurence Giglio, Manish Jain, Maxim Volgin, Michael Wang, Mike Metzger, Piti
Champeethong, Prashant Dwivedi, Radhika Kanubaddhi, Rajat Kant Goel, Ramaa
Vissa, Richard Vaughan, Satej Kumar Sahu, Sergio Gtz, Siva Dhandapani, Annamaneni
Sriharsha, Sri Ram Macharla, Sumit Bhattacharyya, Tony Holdroyd, Vidal Graupera,
Vidhya Vinay, and Vinoth Nageshwaran. Your suggestions helped make this a better
book.

--- Page 19 ---
about this book
AI Agents in Action is about building and working with intelligent agent systems—not
just creating autonomous entities but also developing agents that can effectively tackle
and solve real-world problems. The book starts with the basics of working with large
language models (LLMs) to build assistants, multi-agent systems, and agentic behav-
ioral agents. From there, it explores the key components of agentic systems: retrieval
systems for knowledge and memory augmentation, action and tool usage, reasoning,
planning, evaluation, and feedback. The book demonstrates how these components
empower agents to perform a wide range of complex tasks through practical examples.
This journey isn’t just about technology; it’s about reimagining how we approach
problem solving. I hope this book inspires you to see intelligent agents as partners in
innovation, capable of transforming ideas into actions in ways that were once thought
impossible. Together, we’ll explore how AI can augment human potential, enabling us
to achieve far more than we could alone.
Who should read this book
This book is for anyone curious about intelligent agents and how to develop agentic
systems—whether you’re building your first helpful assistant or diving deeper into
complex multi-agent systems. No prior experience with agents, agentic systems,
prompt engineering, or working with LLMs is required. All you need is a basic under-
standing of Python and familiarity with GitHub repositories. My goal is to make these
concepts accessible and engaging, empowering anyone who wants to explore the
world of AI agents to do so with confidence.
xvii

--- Page 20 ---
xviii ABOUT THIS BOOK
Whether you’re a developer, researcher, or hobbyist or are simply intrigued by the
possibilities of AI, this book is for you. I hope that in these pages you’ll find inspira-
tion, practical guidance, and a new appreciation for the remarkable potential of intel-
ligent agents. Let this book guide understanding, creating, and unleashing the power
of AI agents in action.
How this book is organized: A road map
This book has 11 chapters. Chapter 1, “Introduction to agents and their world,”
begins by laying a foundation with fundamental definitions of large language models,
chat systems, assistants, and autonomous agents. As the book progresses, the discus-
sion shifts to the key components that make up an agent and how these components
work together to create truly effective systems. Here is a quick summary of chapters 2
through 11:
 Chapter 2, “Harnessing the power of large language models”—We start by exploring
how to use commercial LLMs, such as OpenAI. We then examine tools, such as
LM Studio, that provide the infrastructure and support for running various
open source LLMs, enabling anyone to experiment and innovate.
 Chapter 3, “Engaging GPT assistants”—This chapter dives into the capabilities of
the GPT Assistants platform from OpenAI. Assistants are foundational agent
types, and we explore how to create practical and diverse assistants, from culi-
nary helpers to intern data scientists and even a book learning assistant.
 Chapter 4, “Exploring multi-agent systems”—Agentic tools have advanced signifi-
cantly quickly. Here, we explore two sophisticated multi-agent systems: CrewAI
and AutoGen. We demonstrate AutoGen’s ability to develop code autono-
mously and see how CrewAI can bring together a group of joke researchers to
create humor collaboratively.
 Chapter 5, “Empowering agents with actions”—Actions are fundamental to any
agentic system. This chapter discusses how agents can use tools and functions to
execute actions, ranging from database and application programming interface
(API) queries to generating images. We focus on enabling agents to take mean-
ingful actions autonomously.
 Chapter 6, “Building autonomous assistants”—We explore the behavior tree—a sta-
ple in robotics and game systems—as a mechanism to orchestrate multiple
coordinated agents. We’ll use behavior trees to tackle challenges such as code
competitions and social media content creation.
 Chapter 7, “Assembling and using an agent platform”—This chapter introduces Nexus,
a sophisticated platform for orchestrating multiple agents and LLMs. We discuss
how Nexus facilitates agentic workflows and enables complex interactions between
agents, providing an example of a fully functioning multi-agent environment.
 Chapter 8, “Understanding agent memory and knowledge”—Retrieval-augmented
generation (RAG) has become an essential tool for extending the capabilities

--- Page 21 ---
ABOUT THIS BOOK xix
of LLM agents. This chapter explores how retrieval mechanisms can serve as
both a source of knowledge by processing ingested files, and of memory, allow-
ing agents to recall previous interactions or events.
 Chapter 9, “Mastering agent prompts with prompt flow”—Prompt engineering is cen-
tral to an agent’s success. This chapter introduces prompt flow, a tool from Mic-
rosoft that helps automate the testing and evaluation of prompts, enabling
more robust and effective agentic behavior.
 Chapter 10, “Agent reasoning and evaluation”—Reasoning is crucial to solving
problems intelligently. In this chapter, we explore various reasoning techniques,
such as chain of thought (CoT), and show how agents can evaluate reasoning
strategies even during inference, improving their capacity to solve problems
autonomously.
 Chapter 11, “Agent planning and feedback”—Planning is perhaps an agent’s most crit-
ical skill in achieving its goals. We discuss how agents can incorporate planning to
navigate complex tasks and how feedback loops can be used to refine those plans.
The chapter concludes by integrating all the key components—actions, memory
and knowledge, reasoning, evaluation, planning, and feedback—into practical
examples of agentic systems that solve real-world problems.
About the code
The code for this book is spread across several open source projects, many of which
are hosted by me or by other organizations in GitHub repositories. Throughout this
book, I strive to make the content as accessible as possible, taking a low-code approach
to help you focus on core concepts. Many chapters demonstrate how simple prompts
can generate meaningful code, showcasing the power of AI-assisted development.
Additionally, you’ll find a variety of assistant profiles and multi-agent systems that
demonstrate how to solve real-world problems using generated code. These examples
are meant to inspire, guide, and empower you to explore what is possible with AI
agents. I am deeply grateful to the many contributors and the community members
who have collaborated on these projects, and I encourage you to explore the reposito-
ries, experiment with the code, and adapt it to your own needs. This book is a testa-
ment to the power of collaboration and the incredible things we can achieve together.
This book contains many examples of source code both in numbered listings and in
line with normal text. In both cases, source code is formatted in a fixed-width font
like this to separate it from ordinary text. Sometimes, some of the code is typeset in
bold to highlight code that has changed from previous steps in the chapter, such as
when a feature is added to an existing line of code. In many cases, the original source
code has been reformatted; we’ve added line breaks and reworked indentation to
accommodate the available page space in the book. In some cases, even this wasn’t
enough, and listings include line-continuation markers (➥). Additionally, comments in
the source code have often been removed from the listings when the code is described

--- Page 22 ---
xx ABOUT THIS BOOK
in the text. Code annotations accompany many of the listings, highlighting important
concepts.
You can get executable snippets of code from the liveBook (online) version of this
book at https://livebook.manning.com/book/ai-agents-in-action. The complete code
for the examples in the book is available for download from the Manning website at
www.manning.com/books/ai-agents-in-action. In addition, the code developed for this
book has been placed in three GitHub repositories that are all publicly accessible:
 GPT-Agents (the original book title), at https://github.com/cxbxmxcx/GPT-
Agents, holds the code for several examples demonstrated in the chapters.
 GPT Assistants Playground, at https://github.com/cxbxmxcx/GPTAssistants
Playground, is an entire platform and tool dedicated to building OpenAI GPT
assistants with a helpful web user interface and plenty of tools to develop auton-
omous agent systems.
 Nexus, at https://github.com/cxbxmxcx/Nexus, is an example of a web-based
agentic tool that can help you create agentic systems and demonstrate various
code challenges.
liveBook discussion forum
Purchase of AI Agents in Action includes free access to liveBook, Manning’s online
reading platform. Using liveBook’s exclusive discussion features, you can attach com-
ments to the book globally or to specific sections or paragraphs. It’s a snap to make
notes for yourself, ask and answer technical questions, and receive help from the
author and other users. To access the forum, go to https://livebook.manning.com/
book/ai-agents-in-action/discussion. You can also learn more about Manning’s forums
and the rules of conduct at https://livebook.manning.com/discussion.
Manning’s commitment to our readers is to provide a venue where a meaningful
dialogue between individual readers and between readers and the author can take
place. It isn’t a commitment to any specific amount of participation on the part of the
author, whose contribution to the forum remains voluntary (and unpaid). We suggest
you try asking the him challenging questions lest his interest stray! The forum and the
archives of previous discussions will be accessible from the publisher’s website as long
as the book is in print.

--- Page 94 ---
70 CHAPTER 4 Exploring multi-agent systems
The basic pattern in AutoGen uses a UserProxy and one or more assistant
agents. Figure 4.2 shows the user proxy taking direction from a human and then
directing an assistant agent enabled to write code to perform the tasks. Each time
the assistant completes a task, the proxy agent reviews, evaluates, and provides feed-
back to the assistant. This iteration loop continues until the proxy is satisfied with
the results.
Human communicates
to the user proxy agent,
which communicates
to other agents.
Evaluation and feedback
loop is formed between
the proxy and the assistant.
Assistant agent
undertakes completion
of the direct tasks.
LLM configured to
write Python code
Figure 4.2 The user proxy agent and assistant agent communication (Source: AutoGen)
The benefit of the proxy is that it works to replace the required human feedback and
evaluation, and, in most cases, it does a good job. While it doesn’t eliminate the need
for human feedback and evaluation, it produces much more complete results overall.
And, while the iteration loop is time consuming, it’s time you could be drinking a cof-
fee or working on other tasks.
AutoGen Studio is a tool developed by the AutoGen team that provides a helpful
introduction to conversable agents. In the next exercise, we’ll install Studio and run
some experiments to see how well the platform performs. These tools are still in a
rapid development cycle, so if you encounter any problems, consult the documenta-
tion on the AutoGen GitHub repository.
4.1.1 Installing and using AutoGen Studio
Open the chapter_04 folder in Visual Studio Code (VS Code), create a local Python
virtual environment, and install the requirements.txt file. If you need assistance with
this, consult appendix B to install all of this chapter’s exercise requirements.
Open a terminal in VS Code (Ctrl-`, Cmd-`) pointing to your virtual environment,
and run AutoGen Studio using the command shown in listing 4.1. You’ll first need to

--- Page 95 ---
4.1 Introducing multi-agent systems with AutoGen Studio 71
define an environment variable for your OpenAI key. Because ports 8080 and 8081
are popular, and if you have other services running, change the port to 8082 or some-
thing you choose.
Listing4.1 Launching AutoGen Studio
# set environment variable on Bash (Git Bash)
export OPENAI_API_KEY=”<your API key>”
Use the appropriate
command for your
# sent environment variable with PowerShell
terminal type.
$env:VAR_NAME =”<your API key>"
autogenstudio ui --port 8081
Change the port if you expect or
experience a conflict on your machine.
Navigate your browser to the AutoGen Studio interface shown in figure 4.3 (as of this
writing). While there may be differences, one thing is for sure: the primary interface
will still be chat. Enter a complex task that requires coding. The example used here is
Create a plot showing the popularity of the term GPT Agents in Google search.
The Playground tab is where you interact
with agents. The Build tab is for creating new
agents and skills, and the Gallery tab is for
reviewing previous best output.
The proxy agent and assistant
agent will not work together
to complete the task.
Enter a task for the
agents to work on.
You can create new
sessions or review or
continue previous
sessions.
Figure 4.3 Entering a task for the agents to work on in the AutoGen interface

--- Page 96 ---
72 CHAPTER 4 Exploring multi-agent systems
The agent assistant generates code snippets to perform or complete various subtasks
as the agents work together through the task in the example. The user proxy agent then
attempts to execute those code snippets and assesses the output. In many cases, prov-
ing the code runs and produces the required output is sufficient for the user proxy
agent to approve the task’s completion.
If you encounter any problems with the assistant agent requests, ask the proxy
agent to try a different method or another problem. This highlights a bigger problem
with agentic systems using packages or libraries that have expired and no longer work.
For this reason, it’s generally better to get agents to execute actions rather than build
code to perform actions as tools.
TIP Executing AutoGen and AutoGen Studio using Docker is recommended,
especially when working with code that may affect the operating system. Docker
can isolate and virtualize the agents’ environment, thus isolating potentially
harmful code. Using Docker can help alleviate any secondary windows or
websites that may block the agent process from running.
Figure 4.4 shows the agent’s completion of the task. The proxy agent will collect any
generated code snippet, images, or other documents and append them to the message.
Reply with TERMINATE if you are
finished with this agent session. This
stop word is used to stop the session.
Generated codefiles and In this example, a Matplotlib
other output will be plot was generated in a new
attached to the last message. window outside the browser.
Figure 4.4 The output after the agents complete the task

--- Page 97 ---
4.1 Introducing multi-agent systems with AutoGen Studio 73
You can also review the agent conversation by opening the Agent Messages expander.
In many cases, if you ask the agent to generate plots or applications, secondary win-
dows will open showing those results.
Amazingly, the agents will perform most tasks nicely and complete them well.
Depending on the complexity of the task, you may need to further iterate with the
proxy. Sometimes, an agent may only go so far to complete a task because it lacks the
required skills. In the next section, we’ll look at how to add skills to agents.
4.1.2 Adding skills in AutoGen Studio
Skills and tools, or actions, as we refer to them in this book, are the primary means by
which agents can extend themselves. Actions give agents the ability to execute code,
call APIs, or even further evaluate and inspect generated output. AutoGen Studio cur-
rently begins with just a basic set of tools to fetch web content or generate images.
NOTE Many agentic systems employ the practice of allowing agents to code to
solve goals. However, we discovered that code can be easily broken, needs to be
maintained, and can change quickly. Therefore, as we’ll discuss in later chap-
ters, it’s better to provide agents with skills/actions/tools to solve problems.
In the following exercise scenario, we’ll add a skill/action to inspect an image using
the OpenAI vision model. This will allow the proxy agent to provide feedback if we ask
the assistant to generate an image with particular content.
With AutoGen Studio running, go to the Build tab and click Skills, as shown in
figure 4.5. Then, click the New Skill button to open a code panel where you can
copy–paste code to. From this tab, you can also configure models, agents, and agent
workflows.
Enter the code shown in listing 4.2 and also provided in the book’s source code as
describe_image.py. Copy and paste this code into the editor window, and then click
the Save button at the bottom.

--- Page 98 ---
74 CHAPTER 4 Exploring multi-agent systems
Click to create a new skill.
You can also configure Click existing skills
other models, agents, and to see how they work.
workflows from here.
Figure 4.5 Steps to creating a new skill on the Build tab
Listing4.2 describe_image.py
import base64
import requests
import os
def describe_image(image_path='animals.png') -> str:
"""
Uses GPT-4 Vision to inspect and describe the contents of the image.
:param input_path: str, the name of the PNG file to describe.
"""
api_key = os.environ['OPEN_API_KEY']
Function to load and
encode the image as
# Function to encode the image
a Base64 string
def encode_image(image_path):
with open(image_path, "rb") as image_file:
return base64.b64encode(image_file.read()).decode('utf-8')

--- Page 99 ---
4.1 Introducing multi-agent systems with AutoGen Studio 75
# Getting the base64 string
base64_image = encode_image(image_path)
headers = {
"Content-Type": "application/json",
"Authorization": f"Bearer {api_key}"
}
payload = {
"model": "gpt-4-turbo",
"messages": [
{
"role": "user",
"content": [
{
"type": "text",
"text": "What’s in this image?"
},
{ Including the
"type": "image_url", image string
"image_url": { along with the
JSON payload
"url": f"data:image/jpeg;base64,{base64_image}"
}
}
]
}
],
"max_tokens": 300
}
response = requests.post(
"https://api.openai.com/v1/chat/completions",
headers=headers,
json=payload)
return response.json()["choices"][0]["message"] Unpacking the response and
["content"] returning the content of the reply
The describe_image function uses the OpenAI GPT-4 vision model to describe what
is in the image. This skill can be paired with the existing generate_image skill as a
quality assessment. The agents can confirm that the generated image matches the
user’s requirements.
After the skill is added, it must be added to the specific agent workflow and agent
for use. Figure 4.6 demonstrates adding the new skill to the primary assistant agent in
the general or default agent workflow.
Now that the skill is added to the primary assistant, we can task the agent with cre-
ating a specific image and validating it using the new describe_image skill. Because
image generators notoriously struggle with correct text, we’ll create an exercise task to
do just that.
Enter the text shown in listing 4.3 to prompt the agents to create a book image
cover for this book. We’ll explicitly say that the text needs to be correct and insist that
the agent uses the new describe_image function to verify the image.

--- Page 100 ---
76 CHAPTER 4 Exploring multi-agent systems
Go to the Build tab, and then go to the Workflows tab.
Select to edit the primary_assistant
at the bottom of the workflow panel.
Select the General
Agent Workflow.
Click add to add the new
describe_image skill.
Click OK to exit and return
to the Playground tab.
Figure 4.6 Configuring the primary_assistant agent with the new skill
Listing4.3 Prompting for a book cover
Please create a cover for the book GPT Agents In Action, use the
describe_image skill to make sure the title of the book is spelled
correctly on the cover
After the prompt is entered, wait for a while, and you may get to see some dialogue
exchanged about the image generation and verification process. In the end, though, if
everything works correctly, the agents will return with the results shown in figure 4.7.
Remarkably, the agent coordination completed the task in just a couple of itera-
tions. Along with the images, you can also see the various helper code snippets gener-
ated to assist with task completion. AutoGen Studio is impressive in its ability to
integrate skills that the agents can further adapt to complete some goal. The following
section will show how these powerful agents are implemented in code.

--- Page 101 ---
4.2 Exploring AutoGen 77
The agents generate additional
code to use the skills as needed.
Review the generated outputfiles.
After a couple iterations, the book cover
is generated with the correct text.
Tho agents even enhance existing
skills to better complete the task.
Figure 4.7 The generated file outputs from the agent work on the image generation task
4.2 Exploring AutoGen
While AutoGen Studio is a fantastic tool for understanding multi-agent systems, we
must look into the code. Fortunately, coding multiple agent examples with AutoGen is
simple and easy to run. We’ll cover the basic AutoGen setup in the next section.
4.2.1 Installing and consuming AutoGen
This next exercise will look at coding a basic multi-agent system that uses a user proxy
and conversable agent. Before we do that, though, we want to make sure AutoGen is
installed and configured correctly.
Open a terminal in VS Code, and run the entire chapter 4 install directions per
appendix B, or run the pip command in listing 4.4. If you’ve installed the require-
ments.txt file, you’ll also be ready to run AutoGen.
Listing4.4 Installing AutoGen
pip install pyautogen
Next, copy the chapter_04/OAI_CONFIG_LIST.example to OAI_CONFIG_LIST, remov-
ing .example from the file name. Then, open the new file in VS Code, and enter your

--- Page 102 ---
78 CHAPTER 4 Exploring multi-agent systems
OpenAI or Azure configuration in the OAI_CONFIG_LIST file in listing 4.5. Fill in your
API key, model, and other details per your API service requirements. AutoGen will
work with any model that adheres to the OpenAI client. That means you can use local
LLMs via LM Studio or other services such as Groq, Hugging Face, and more.
Listing4.5 OAI_CONFIG_LIST
Select the model; GPT-4
[
is recommended.
{
"model": "gpt-4",
Use the service key you
"api_key": "<your OpenAI API key here>",
would typically use.
"tags": ["gpt-4", "tool"]
},
Select the model; GPT-4
{
is recommended.
"model": "<your Azure OpenAI deployment name>",
"api_key": "<your Azure OpenAI API key here>",
Use the service
"base_url": "<your Azure OpenAI API base here>",
key you would
"api_type": "azure", typically use.
"api_version": "2024-02-15-preview"
}
] Changing the base URL allows you to point to
other services, not just Azure OpenAI.
Now, we can look at the code for a basic multi-agent chat using the out-of-the-box
UserProxy and ConversableAgent agents. Open autogen_start.py in VS Code,
shown in the following listing, and review the parts before running the file.
Listing4.6 autogen_start.py
from autogen import ConversableAgent, UserProxyAgent, config_list_from_json
Loads your LLM
configuration from the
config_list = config_list_from_json(
JSON file OAI_CONFIG_LIST
env_or_file="OAI_CONFIG_LIST")
assistant = ConversableAgent(
This agent talks
"agent",
directly to the LLM.
llm_config={"config_list": config_list})
user_proxy = UserProxyAgent(
This agent proxies
"user",
conversations from the
code_execution_config={ user to the assistant.
"work_dir": "working",
"use_docker": False,
A chat is initiated with the
},
assistant through the user_proxy
human_input_mode="ALWAYS",
to complete a task.
is_termination_msg=lambda x: x.get("content", "")
.rstrip()
Setting the termination message
.endswith("TERMINATE"),
allows the agent to iterate.
)
user_proxy.initiate_chat(assistant, message="write a solution
➥
for fizz buzz in one line?")

--- Page 103 ---
4.2 Exploring AutoGen 79
Run the code by running the file in VS Code in the debugger (F5). The code in list-
ing 4.6 uses a simple task to demonstrate code writing. Listing 4.7 shows a few examples
to choose from. These coding tasks are also some of the author’s regular baselines to
assess an LLMs’ strength in coding.
Listing4.7 Simple coding task examples
write a Python function to check if a number is prime To enjoy iterating
code a classic sname game using Pygame over these tasks, use
Windows Subsystem
code a classic asteroids game in Python using Pygame
for Linux (WSL) on
Windows, or use Docker.
After the code starts in a few seconds, the assistant will respond to the proxy with a
solution. At this time, the proxy will prompt you for feedback. Press Enter, essentially
giving no feedback, and this will prompt the proxy to run the code to verify it operates
as expected.
Impressively, the proxy agent will even take cues to install required packages such
as Pygame. Then it will run the code, and you’ll see the output in the terminal or as a
new window or browser. You can play the game or use the interface if the code shelled
a new window/browser.
Note that the spawned window/browser won’t close on Windows and will require
exiting the entire program. To avoid this problem, run the code through Windows
Subsystem for Linux (WSL) or Docker. AutoGen explicitly recommends using Docker
for code execution agents, and if you’re comfortable with containers, this is a good
option.
Either way, after the proxy generates and runs the code, the working_dir folder
set earlier in listing 4.6 should now have a Python file with the code. This will allow
you to run the code at your leisure, make changes, or even ask for improvements, as
we’ll see. In the next section, we’ll look at how to improve the capabilities of the cod-
ing agents.
4.2.2 Enhancing code output with agent critics
One powerful benefit of multi-agent systems is the multiple roles/personas you can
automatically assign when completing tasks. Generating or helping to write code can be
an excellent advantage to any developer, but what if that code was also reviewed and
tested? In the next exercise, we’ll add another agent critic to our agent system to help
with coding tasks. Open autogen_coding_critic.py, as shown in the following listing.
Listing4.8 autogen_coding_critic.py
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
config_list = config_list_from_json(env_or_file="OAI_CONFIG_LIST")
user_proxy = UserProxyAgent(
"user",

--- Page 104 ---
80 CHAPTER 4 Exploring multi-agent systems
code_execution_config={
"work_dir": "working",
"use_docker": False,
"last_n_messages": 1,
},
human_input_mode="ALWAYS",
is_termination_msg=lambda x:
x.get("content", "").rstrip().endswith("TERMINATE"),
)
engineer = AssistantAgent(
name="Engineer",
llm_config={"config_list": config_list},
system_message="""
You are a profession Python engineer, known for your expertise in
software development.
You use your skills to create software applications, tools, and
games that are both functional and efficient.
Your preference is to write clean, well-structured code that is easy
to read and maintain.
""",
This time, the assistant is
)
given a system/persona
message.
critic = AssistantAgent(
name="Reviewer",
llm_config={"config_list": config_list},
system_message="""
You are a code reviewer, known for your thoroughness and commitment
to standards.
Your task is to scrutinize code content for any harmful or
substandard elements.
You ensure that the code is secure, efficient, and adheres to best
practices.
You will identify any issues or areas for improvement in the code
and output them as a list.
""",
A second assistant critic agent is
)
created with a background.
def review_code(recipient, messages, sender, config):
return f"""
Review and critque the following code.
{recipient.chat_messages_for_summary(sender)[-1]['content']}
"""
user_proxy.register_nested_chats( A custom function
[ helps extract the
{ code for review by
the critic.
"recipient": critic, A nested chat is
"message": review_code, created between
"summary_method": "last_msg", the critic and the
"max_turns": 1, engineer.
}
],
trigger=engineer,
)

--- Page 105 ---
4.2 Exploring AutoGen 81
task = """Write a snake game using Pygame."""
res = user_proxy.initiate_chat(
recipient=engineer,
The proxy agent initiates a
message=task,
chat with a max delay and
max_turns=2,
explicit summary method.
summary_method="last_msg"
)
Run the autogen_coding_critic.py file in VS Code in debug mode, and watch the
dialog between the agents. This time, after the code returns, the critic will also be trig-
gered to respond. Then, the critic will add comments and suggestions to improve the
code.
Nested chats work well for supporting and controlling agent interactions, but we’ll
see a better approach in the following section. Before that though, we’ll review the
importance of the AutoGen cache in the next section.
4.2.3 Understanding the AutoGen cache
AutoGen can consume many tokens over chat iterations as a conversable multi-agent
platform. If you ask AutoGen to work through complex or novel problems, you may
even encounter token limits on your LLM; because of this, AutoGen supports several
methods to reduce token usage.
AutoGen uses caching to store progress and reduce token usage. Caching is
enabled by default, and you may have already encountered it. If you check your cur-
rent working folder, you’ll notice a .cache folder, as shown in figure 4.8. Caching
allows your agents to continue conversations if they get interrupted.
A cache is denoted by the folder
and contains a SQLite database
of message history.
The folder code
is output here.
Output codefiles are named Figure 4.8 AutoGen cache
with temporary names. and working folders
In code, you can control the cache folder for your agent’s run, as shown in listing 4.9.
By wrapping the initiate_chat call with the with statement, you can control the

--- Page 106 ---
82 CHAPTER 4 Exploring multi-agent systems
location and seed for the cache. This will allow you to save and return to long-running
AutoGen tasks in the future by just setting the cache_seed for the previous cache.
Listing4.9 Setting the cache folder
with Cache.disk(cache_seed=42) as cache:
Setting the seed_cache
res = user_proxy.initiate_chat(
denotes the individual
recipient=engineer, location.
message=task,
max_turns=2,
summary_method="last_msg",
Sets the cache as
cache=cache,
a parameter
)
This caching ability allows you to continue operations from the previous cache loca-
tion and captures previous runs. It can also be a great way to demonstrate and inspect
how an agent conversation generated the results. In the next section, we’ll look at
another conversational pattern in which AutoGen supports group chat.
4.3 Group chat with agents and AutoGen
One problem with chat delegation and nested chats or conversations is the convey-
ance of information. If you’ve ever played the telephone game, you’ve witnessed this
firsthand and experienced how quickly information can change over iterations. With
agents, this is certainly no different, and chatting through nested or sequential con-
versations can alter the task or even the desired result.
The telephone game
The telephone game is a fun but educational game that demonstrates information
and coherence loss. Children form a line, and the first child receives a message only
they can hear. Then, in turn, the children verbally pass the message on to the next
child, and so on. At the end, the last child announces the message to the whole
group, which often isn’t even close to the same message.
To counter this, AutoGen provides a group chat, a mechanism by which agents par-
ticipate in a shared conversation. This allows agents to review all past conversations
and better collaborate on long-running and complex tasks.
Figure 4.9 shows the difference between nested and collaborative group chats. We
used the nested chat feature in the previous section to build a nested agent chat. In
this section, we use the group chat to provide a more collaborative experience.
Open autogen_coding_group.py with relevant parts, as shown in listing 4.10. The
code is similar to the previous exercise but now introduces GroupChat and GroupChat-
Manager. The agents and messages are held with the group chat, similar to a messaging
channel in applications such as Slack or Discord. The chat manager coordinates the
message responses to reduce conversation overlap.

--- Page 107 ---
4.3 Group chat with agents and AutoGen 83
ConversableAgents Nested Chat ConversableAgents Group Chat
User Proxy
Messages go through the
User Proxy
group chat manager.
Agentsnowcollaborate
Chat throughthe groupchat
Proxy initiates chat Critic responds with Manager manager.
suggested updates
with engineer.
and changes.
Engineer Message is sent Critic Engineer Critic
to the critic.
Representsthe nested
chatto the critic
Figure 4.9 The difference between nested and group chat for conversable agents
Listing4.10 autoget_coding_group.py (relevant sections)
user_proxy = UserProxyAgent(
"user",
code_execution_config={
"work_dir": "working",
"use_docker": False,
Human input is now
"last_n_messages": 3,
set to never, so no
},
human feedback.
human_input_mode="NEVER",
)
llm_config = {"config_list": config_list}
engineer = AssistantAgent(…
Code omitted, but
consult changes to the
persona in the file
critic = AssistantAgent(…
groupchat = GroupChat(agents=[user_proxy,
engineer, This object holds the
critic], connection to all the
messages=[], agents and stores the
max_round=20) messages.
manager = GroupChatManager(groupchat=groupchat,
llm_config=llm_config)
The manager
coordinates the
task = """Write a snake game using Pygame.""" conversation as a
moderator would.

--- Page 108 ---
84 CHAPTER 4 Exploring multi-agent systems
with Cache.disk(cache_seed=43) as cache:
res = user_proxy.initiate_chat(
recipient=manager,
message=task,
cache=cache,
)
Run this exercise, and you’ll see how the agents collaborate. The engineer will now
take feedback from the critic and undertake operations to address the critic’s sugges-
tions. This also allows the proxy to engage in all of the conversation.
Group conversations are an excellent way to strengthen your agents’ abilities as
they collaborate on tasks. However, they are also substantially more verbose and token
expensive. Of course, as LLMs mature, so do the size of their context token windows
and the price of token processing. As token windows increase, concerns over token
consumption may eventually go away.
AutoGen is a powerful multi-agent platform that can be experienced using a web
interface or code. Whatever your preference, this agent collaboration tool is an excel-
lent platform for building code or other complex tasks. Of course, it isn’t the only plat-
form, as you’ll see in the next section, where we explore a newcomer called CrewAI.
4.4 Building an agent crew with CrewAI
CrewAI is relatively new to the realm of multi-agent systems. Where AutoGen was
initially developed from research and then extended, CrewAI is built with enterprise
systems in mind. As such, the platform is more robust, making it less extensible in
some areas.
With CrewAI, you build a crew of agents to focus on specific areas of a task goal.
Unlike AutoGen, CrewAI doesn’t require the use of the user proxy agent but instead
assumes the agents only work among themselves.
Figure 4.10 shows the main elements of the CrewAI platform, how they connect
together, and their primary function. It shows a sequential-processing agent system
with generic researcher and writer agents. Agents are assigned tasks that may also include
tools or memory to assist them.
CrewAI supports two primary forms of processing: sequential and hierarchical. Fig-
ure 4.10 shows the sequential process by iterating across the given agents and their
associated tasks. In the next section, we dig into some code to set up a crew and
employ it to complete a goal and create a good joke.
4.4.1 Creating a jokester crew of CrewAI agents
CrewAI requires more setup than AutoGen, but this also allows for more control and
additional guides, which provide more specific context to guide the agents in com-
pleting the given task. This isn’t without problems, but it does offer more control than
AutoGen out of the box.
Open crewai_introduction.py in VS Code and look at the top section, as shown
in listing 4.11. Many settings are required to configure an agent, including the role,

--- Page 110 ---
86 CHAPTER 4 Exploring multi-agent systems
"the funny in everyday situations and can turn a dull moment into"
"a laugh riot."
), Supports the use of
allow_delegation=True, Creates the memory for the agents
) agents and
provides them verbose allows the
a goal agent to emit output
joke_writer = Agent(
to the terminal.
role="Joke Writer",
goal="Write a humourous and funny joke on the following {topic}",
verbose=True,
memory=True,
backstory=(
"You are a joke writer with a flair for humor. You can turn a"
"simple idea into a laugh riot. You have a way with words and"
"can make people laugh with just a few lines."
),
allow_delegation=False, The backstory is the
) agent’s background—
its persona.
The agents can either be delegated to or
are allowed to delegate; True means they
can delegate.
Moving down the code, we next see the tasks, as shown in listing 4.12. Tasks denote an
agent’s process to complete the primary system goal. They also link an agent to work
on a specific task, define the output from that task, and may include how it’s executed.
Listing4.12 crewai_introduction.py (task section)
The Task description defines how
research_task = Task(
the agent will complete the task.
description=(
"Identify what makes the following topic:{topic} so funny."
"Be sure to include the key elements that make it humourous."
"Also, provide an analysis of the current social trends,"
"and how it impacts the perception of humor."
),
expected_output="A comprehensive 3 paragraphs long report
➥
on the latest jokes.",
Explicitly defines the expected
agent=joke_researcher,
output from performing the task
)
The Task description defines how
write_task = Task(
the agent will complete the task.
description=(
The
"Compose an insightful, humourous and socially aware joke on
agent
{topic}."
assigned
"Be sure to include the key elements that make it funny and"
to work
"relevant to the current social trends."
on the Explicitly defines the expected
),
task output from performing the task
expected_output="A joke on {topic}.",
agent=joke_writer,
If the agent should execute
async_execution=False,
asynchronously
output_file="the_best_joke.md",
)
Any output the agent will generate

--- Page 111 ---
4.4 Building an agent crew with CrewAI 87
Now, we can see how everything comes together as the Crew at the bottom of the file,
as shown in listing 4.13. Again, many options can be set when building the Crew,
including the agents, tasks, process type, memory, cache, maximum requests per min-
ute (max_rpm), and whether the crew shares.
Listing4.13 crewai_introduction.py (crew section)
The tasks the agents
Defining how the agents
can work on
will interact
The agents assembled
into the crew Whether the system should
crew = Crew( use memory; needs to be set
agents=[joke_researcher, joke_writer], if agents/tasks have it on
tasks=[research_task, write_task],
process=Process.sequential, Whether the system
should use a cache,
memory=True,
similar to AutoGen
cache=True,
max_rpm=100,
Maximum requests per minute
share_crew=True,
the system should limit itself to
)
Whether the crew should share
information, similar to group chat
result = crew.kickoff(inputs={"topic": "AI engineer jokes"})
print(result)
When you’re done reviewing, run the file in VS Code (F5), and watch the terminal for
conversations and messages from the crew. As you can probably tell by now, the goal of
this agent system is to craft jokes related to AI engineering. Here are some of the fun-
nier jokes generated over a few runs of the agent system:
 Why was the computer cold? It left Windows open.
 Why don’t AI engineers play hide and seek with their algorithms? Because no
matter where they hide, the algorithms always find them in the “overfitting”
room!
 What is an AI engineer’s favorite song? “I just called to say I love you . . . and to
collect more data for my voice recognition software.”
 Why was the AI engineer broke? Because he spent all his money on cookies, but
his browser kept eating them.
Before you run more iterations of the joke crew, you should read the next section.
This section shows how to add observability to the multi-agent system.
4.4.2 Observing agents working with AgentOps
Observing a complex assemblage such as a multi-agent system is critical to understand-
ing the myriad of problems that can happen. Observability through application tracing
is a key element of any complex system, especially one engaged in enterprise use.
CrewAI supports connecting to a specialized agent operations platform appropri-
ately called AgentOps. This observability platform is generic and designed to support

--- Page 112 ---
88 CHAPTER 4 Exploring multi-agent systems
observability with any agent platform specific to LLM usage. Currently, no pricing or
commercialization details are available.
Connecting to AgentOps is as simple as installing the package, getting an API key,
and adding a line of code to your crew setup. This next exercise will go through the
steps to connect and run AgentOps.
Listing 4.14 shows installing the agentops package using pip. You can install the
package alone or as an additional component of the crewai package. Remember that
AgentOps can also be connected to other agent platforms for observability.
Listing4.14 Installing AgentOps
pip install agentops
or as an option with CrewAI
pip install crewai[agentops]
Before using AgentOps, you need to sign up for an API key. Following are the general
steps to sign up for a key at the time of writing:
1 Visit https://app.agentops.ai in your browser.
2 Sign up for an account.
3 Create a project, or use the default.
4 Go to Settings > Projects and API Keys.
5 Copy and/or generate a new API key; this will copy the key to your browser.
6 Paste the key to your .env file in your project.
After the API key is copied, it should resemble the example shown in the following
listing.
Listing4.15 env.: Adding an AgentOps key
AGENTOPS_API_KEY="your API key"
Now, we need to add a few lines of code to the CrewAI script. Listing 4.16 shows the
additions as they are added to the crewai_agentops.py file. When creating your own
scripts, all you need to do is add the agentops package and initialize it when using
CrewAI.
Listing4.16 crewai_agentops.py (AgentOps additions)
import agentops
The addition of the
from crewai import Agent, Crew, Process, Task
required package
from dotenv import load_dotenv
load_dotenv() Make sure to initialize the
agentops.init() package after the environment
variables are loaded.

--- Page 113 ---
4.4 Building an agent crew with CrewAI 89
Run the crewai_agentops.py file in VS Code (F5), and watch the agents work as before.
However, you can now go to the AgentOps dashboard and view the agent interactions
at various levels.
Figure 4.11 shows the dashboard for running the joke crew to create the best joke.
Several statistics include total duration, the run environment, prompt and completion
tokens, LLM call timings, and estimated cost. Seeing the cost can be both sobering
and indicative of how verbose agent conversations can become.
Various statistics are captured with
respect to the entire agent conversation
sequence, including costs.
System information
is captured as well.
You can even track individual
LLM calls, actions, and tool use.
Prompts and replies are also
captured for all iterations.
Figure 4.11 The AgentOps dashboard for running the joke crew
The AgentOps platform is an excellent addition to any agent platform. While it’s built
into CrewAI, it’s helpful that the observability could be added to AutoGen or other
frameworks. Another attractive thing about AgentOps is that it’s dedicated to observing
agent interactions and not transforming from a machine learning operations platform.
In the future, we’ll likely see the spawn of more agent observability patterns.
One benefit that can’t be overstated is the cost observation that an observability
platform can provide. Did you notice in figure 4.11 that creating a single joke costs a
little over 50 cents? Agents can be very powerful, but they can also become very costly,
and it’s essential to observe what those costs are in terms of practicality and commer-
cialization.

--- Page 114 ---
90 CHAPTER 4 Exploring multi-agent systems
In the last section of this chapter, we’ll return to CrewAI and revisit building
agents that can code games. This will provide an excellent comparison between the
capabilities of AutoGen and CrewAI.
4.5 Revisiting coding agents with CrewAI
A great way to compare capabilities between multi-agent platforms is to implement
similar tasks in a bot. In this next set of exercises, we’ll employ CrewAI as a game pro-
gramming team. Of course, this could be adapted to other coding tasks as well.
Open crewai_coding_crew.py in VS Code, and we’ll first review the agent section
in listing 4.17. Here, we’re creating a senior engineer, a QA engineer, and a chief QA
engineer with a role, goal, and backstory.
Listing4.17 crewai_coding_crew.py (agent section)
print("## Welcome to the Game Crew")
Allows the user
print("-------------------------------")
to input the
game = input("What is the game you would like to build? instructions for
➥
What will be the mechanics?\n") their game
senior_engineer_agent = Agent(
role="Senior Software Engineer",
goal="Create software as needed",
backstory=dedent(
"""
You are a Senior Software Engineer at a leading tech think tank.
Your expertise in programming in python. and do your best to
produce perfect code
"""
),
allow_delegation=False,
verbose=True,
)
qa_engineer_agent = Agent(
role="Software Quality Control Engineer",
goal="create prefect code, by analizing the code
➥
that is given for errors",
backstory=dedent(
"""
You are a software engineer that specializes in checking code
for errors. You have an eye for detail and a knack for finding
hidden bugs.
You check for missing imports, variable declarations, mismatched
brackets and syntax errors.
You also check for security vulnerabilities, and logic errors
"""
),
allow_delegation=False,
verbose=True,
)

--- Page 115 ---
4.5 Revisiting coding agents with CrewAI 91
chief_qa_engineer_agent = Agent(
role="Chief Software Quality Control Engineer",
goal="Ensure that the code does the job that it is supposed to do",
backstory=dedent(
"""
You are a Chief Software Quality Control Engineer at a leading
tech think tank. You are responsible for ensuring that the code
that is written does the job that it is supposed to do.
You are responsible for checking the code for errors and ensuring
that it is of the highest quality.
"""
),
Only the chief QA engineer
allow_delegation=True,
can delegate tasks.
verbose=True,
)
Scrolling down in the file will display the agent tasks, as shown in listing 4.18. The task
descriptions and expected output should be easy to follow. Again, each agent has a
specific task to provide better context when working to complete the task.
Listing4.18 crewai_coding_crew.py (task section)
code_task = Task(
description=f"""
You will create a game using python, these are the instructions:
Instructions
------------
{game}
You will write the code for the game using python.""",
expected_output="Your Final answer must be the
➥
full python code, only the python code and nothing else.",
agent=senior_engineer_agent,
) The game instructions
are substituted into the
qa_task = Task( prompt using Python
description=f"""You are helping create a game formatting.
➥
using python, these are the instructions:
Instructions
------------
{game}
Using the code you got, check for errors. Check for logic errors,
syntax errors, missing imports, variable declarations,
mismatched brackets,
and security vulnerabilities.""",
expected_output="Output a list of issues you found in the code.",
agent=qa_engineer_agent,
)
evaluate_task = Task(
description=f"""You are helping create a game
➥
using python, these are the instructions:
Instructions
------------
{game}

--- Page 116 ---
92 CHAPTER 4 Exploring multi-agent systems
You will look over the code to insure that it is complete and
does the job that it is supposed to do. """,
expected_output="Your Final answer must be the
➥
corrected a full python code, only the python code and nothing else.",
agent=chief_qa_engineer_agent,
)
Finally, we can see how this comes together by going to the bottom of the file, as
shown in listing 4.19. This crew configuration is much like what we’ve seen before.
Each agent and task are added, as well as the verbose and process attributes. For this
example, we’ll continue to use sequential methods.
Listing4.19 crewai_coding_crew.py (crew section)
crew = Crew(
agents=[senior_engineer_agent,
qa_engineer_agent,
chief_qa_engineer_agent],
tasks=[code_task, qa_task, evaluate_task],
verbose=2,
process=Process.sequential, Process is sequential.
)
# Get your crew to work!
No additional context is
result = crew.kickoff()
provided in the kickoff.
print("######################")
print(result)
When you run the VS Code (F5) file, you’ll be prompted to enter the instructions for
writing a game. Enter some instructions, perhaps the snake game or another game
you choose. Then, let the agents work, and observe what they produce.
With the addition of the chief QA engineer, the results will generally look better
than what was produced with AutoGen, at least out of the box. If you review the code,
you’ll see that it generally follows good patterns and, in some cases, may even include
tests and unit tests.
Before we finish the chapter, we’ll make one last change to the crew’s processing
pattern. Previously, we employed sequential processing, as shown in figure 4.10. Fig-
ure 4.12 shows what hierarchical processing looks like in CrewAI.
Adding this manager is a relatively simple process. Listing 4.20 shows the addi-
tional code changes to a new file that uses the coding crew in a hierarchical method.
Aside from importing a class for connecting to OpenAI from LangChain, the other
addition is adding this class as the crew manger, manager_llm.

--- Page 117 ---
4.5 Revisiting coding agents with CrewAI 93
Crew
crew
manager
Agents Hierarchical processing
is coordinated through
a managing agent.
researcher writer
goal: goal:
backstory: backstory:
Agents have a goal
and backstory as
Tasks their persona.
research on this {topic} write on this topic
Tools can be attached
to agents and tasks.
Tools
Search CallAPIs Access data
Memory
Conversational Task specific Semantic
Various forms of memory and
retrievalaugmentedgeneration (RAG)
patterns are supported.
Figure 4.12 Hierarchical processing of agents coordinated through a crew manager
Listing4.20 crewai_hierarchy.py (crew manager sections)
from langchain_openai import ChatOpenAI
Imports the LLM
connector from
crew = Crew( LangChain
agents=[senior_engineer_agent,
qa_engineer_agent,
chief_qa_engineer_agent],
You must set a crew
tasks=[code_task, qa_task, evaluate_task],
manager when selecting
verbose=2,
hierarchical processing.
process=Process.hierarchical,
manager_llm=ChatOpenAI( Sets the crew manager to
temperature=0, model="gpt-4" be the LLM connector

--- Page 118 ---
94 CHAPTER 4 Exploring multi-agent systems
), You must set a crew manager when
) selecting hierarchical processing.
Run this file in VS Code (F5). When prompted, enter a game you want to create. Try
using the same game you tried with AutoGen; the snake game is also a good baseline
example. Observe the agents work through the code and review it repeatedly for
problems.
After you run the file, you can also jump on AgentOps to review the cost of this
run. Chances are, it will cost over double what it would have without the agent man-
ager. The output will also likely not be significantly better. This is the trap of building
agent systems without understanding how quickly things can spiral.
An example of this spiral that often happens when agents continually iterate over
the same actions is frequently repeating tasks. You can view this problem in AgentOps,
as shown in figure 4.13, by viewing the Repeat Thoughts plot.
Plot indicates the repetition
of the same thoughts in an
agent interaction.
2
1.5
1
0.5
Figure 4.13 The repetition of thoughts as they occurred within an agent run
The Repeat Thoughts plot from AgentOps is an excellent way to measure the repeti-
tion your agent system encounters. Overly repetitive thought patterns typically
mean the agent isn’t being decisive enough and instead keeps trying to generate a
different answer. If you encounter this problem, you want to change the agents’ pro-
cessing patterns, tasks, and goals. You may even want to alter the system’s type and
number of agents.
Multi-agent systems are an excellent way to break up work in terms of work pat-
terns of jobs and tasks. Generally, the job role is allocated to an agent role/persona,

--- Page 119 ---
4.6 Exercises 95
and the tasks it needs to complete may be implicit, as in AutoGen, or more explicit, as
in CrewAI.
In this chapter, we covered many useful tools and platforms that you can use right
away to improve your work, life, and more. That completes our journey through multi-
agent platforms, but it doesn’t conclude our exploration and use of multiple agents,
as we’ll discover in later chapters.
4.6 Exercises
Use the following exercises to improve your knowledge of the material:
 Exercise 1—Basic Agent Communication with AutoGen
Objective—Familiarize yourself with basic agent communications and setup in
AutoGen.
Tasks:
– Set up AutoGen Studio on your local machine, following the instructions
provided in this chapter.
– Create a simple multi-agent system with a user proxy and two assistant agents.
– Implement a basic task where the user proxy coordinates between the assis-
tant agents to generate a simple text output, such as summarizing a short
paragraph.
 Exercise 2—Implementing Advanced Agent Skills in AutoGen Studio
Objective—Enhance agent capabilities by adding advanced skills.
Tasks:
– Develop and integrate a new skill into an AutoGen agent that allows it to
fetch and display real-time data from a public API (e.g., weather information
or stock prices).
– Ensure the agent can ask for user preferences (e.g., city for weather, type of
stocks) and display the fetched data accordingly.
 Exercise 3—Role-Based Task Management with CrewAI
Objective—Explore role-based task management in CrewAI.
Tasks:
– Design a CrewAI setup where multiple agents are assigned specific roles
(e.g., data fetcher, analyzer, presenter).
– Configure a task sequence where the data fetcher collects data, the analyzer
processes the data, and the presenter generates a report.
– Execute the sequence and observe the flow of information and task delega-
tion among agents.
 Exercise 4—Multi-Agent Collaboration in Group Chat Using AutoGen
Objective—Understand and implement a group chat system in AutoGen to facil-
itate agent collaboration.

--- Page 120 ---
96 CHAPTER 4 Exploring multi-agent systems
Tasks:
– Set up a scenario where multiple agents need to collaborate to solve a com-
plex problem (e.g., planning an itinerary for a business trip).
– Use the group chat feature to allow agents to share information, ask ques-
tions, and provide updates to each other.
– Monitor the agents’ interactions and effectiveness in collaborative problem
solving.
 Exercise 5—Adding and Testing Observability with AgentOps in CrewAI
Objective—Implement and evaluate the observability of agents using AgentOps
in a CrewAI environment.
Tasks:
– Integrate AgentOps into a CrewAI multi-agent system.
– Design a task for the agents that involves significant computation or data
processing (e.g., analyzing customer reviews to determine sentiment trends).
– Use AgentOps to monitor the performance, cost, and output accuracy of the
agents. Identify any potential inefficiencies or errors in agent interactions.
Summary
 AutoGen, developed by Microsoft, is a conversational multi-agent platform that
employs a variety of agent types, such as user proxies and assistant agents, to
facilitate task execution through natural language interactions.
 AutoGen Studio acts as a development environment that allows users to create,
test, and manage multi-agent systems, enhancing the usability of AutoGen.
 AutoGen supports multiple communication patterns, including group chats
and hierarchical and proxy communications. Proxy communication involves a
primary agent (proxy) that interfaces between the user and other agents to
streamline task completion.
 CrewAI offers a structured approach to building multi-agent systems with a focus
on enterprise applications. It emphasizes role-based and autonomous agent func-
tionalities, allowing for flexible, sequential, or hierarchical task management.
 Practical exercises in the chapter illustrate how to set up and use AutoGen Stu-
dio, including installing necessary components and running basic multi-agent
systems.
 Agents in AutoGen can be equipped with specific skills to perform tasks such as
code generation, image analysis, and data retrieval, thereby broadening their
application scope.
 CrewAI is distinguished by its ability to structure agent interactions more rigidly
than AutoGen, which can be advantageous in settings that require precise and
controlled agent behavior.
 CrewAI supports integrating memory and tools for agents to consume through
task completion.

--- Page 121 ---
Summary 97
 CrewAI supports integration with observability tools such as AgentOps, which
provides insights into agent performance, interaction efficiency, and cost
management.
 AgentOps is an agent observability platform that can help you easily monitor
extensive agent interactions.

--- Page 122 ---
Empowering agents
with actions
This chapter covers
 How an agent acts outside of itself using actions
 Defining and using OpenAI functions
 The Semantic Kernel and how to use
semantic functions
 Synergizing semantic and native functions
 Instantiating a GPT interface with
Semantic Kernel
In this chapter, we explore actions through the use of functions and how agents
can use them as well. We’ll start by looking at OpenAI function calling and then
quickly move on to another project from Microsoft called Semantic Kernel (SK),
which we’ll use to build and manage skills and functions for agents or as agents.
We’ll finish the chapter using SK to host our first agent system. This will be a
complete chapter with plenty of annotated code examples.
98

--- Page 123 ---
5.1 Defining agent actions 99
5.1 Defining agent actions
ChatGPT plugins were first introduced to provide a session with abilities, skills, or
tools. With a plugin, you can search the web or create spreadsheets or graphs. Plugins
provide ChatGPT with the means to extend the platform.
Figure 5.1 shows how a ChatGPT plugin works. In this example, a new movie rec-
ommender plugin has been installed in ChatGPT. When a user asks ChatGPT to rec-
ommend a new movie, the large language model (LLM) recognizes that it has a
plugin to manage that action. It then breaks down the user request into actionable
parameters, which it passes to the new movie recommender.
Prompt Engineering Strategies
Use External Tools
Enhances model capabilities.
Tactics include embeddings-based search, code execution, and access
Actions
to specific functions.
Memory
A plugin may use the same,
different, or even multiple
The LLM recognizes the
LLMs.
request for a plugin and
then extracts the input
parameters required for GPT-4.5? Plugin calls LLM to get a recommendation
for the list of new movies.
the plugin.
Second, the plugin
uses an LLM to get
Confirmsthe use of
a recommendation.
the recommender plugin
ChatGPTuser
Calls the plugin/function New Movie Recommender
Can you recommend with parameters plugin (agent)
a new movie?
Here are some new movies Plugin replies with
you may like to see... recommended new movie.
Plugin uses a service
ChatGPTwith a new First, the plugin scrapes tofind new movie.
movie recommender a site for a list of new
plugin movies.
The plugin/agent
scrapes websites for
new movies.
Figure 5.1 How a ChatGPT plugin operates and how plugins and other external tools (e.g., APIs) align with the
Use External Tools prompt engineering strategy
The recommender then scrapes a website showcasing new movies and appends that
information to a new prompt request to an LLM. With this information, the LLM

--- Page 124 ---
100 CHAPTER 5 Empowering agents with actions
responds to the recommender, which passes this back to ChatGPT. ChatGPT then
responds to the user with the recommended request.
We can think of plugins as proxies for actions. A plugin generally encapsulates one
or more abilities, such as calling an API or scraping a website. Actions, therefore, are
extensions of plugins—they give a plugin its abilities.
AI agents can be considered plugins and consumers of plugins, tools, skills, and
other agents. Adding skills, functions, and tools to an agent/plugin allows it to exe-
cute well-defined actions—figure 5.2 highlights where agent actions occur and their
interaction with LLMs and other systems.
4. The agent system passes
An agent may use the
the responses to the LLM
same, different, or
to summarize the results.
1. The LLM recognizes the even multiple LLMs.
request for a plugin/agent Plugin calls LLM to get a
GPT-4.5?
and then extracts the input recommendation for the list of new movies.
parameters required to
activate the agent.
2. The agent adds the
Confirmsthe use of information to a prompt
a recommender plugin
used to make a request
ChatGPTuser to an LLM.
Calls the agent/plugin New Movie Recommender
Can you recommend with parameters plugin (agent)
a new movie?
Here are some new movies Agent replies with
you may like to see... recommended new movie.
Agent uses a function or
skill tofind new movie.
Agent System
3. The agent uses an action
tofind new movies.
The plugin/agent scrapes
websites for new movies.
An agent action can be a
Chevron denotes an
agent action. function or skill/tool prompt.
Figure 5.2 How an agent uses actions to perform external tasks
An agent action is an ability that allows it to use a function, skill, or tool. What gets
confusing is that different frameworks use different terminology. We’ll define an
action as anything an agent can do to establish some basic definitions.
ChatGPT plugins and functions represent an actionable ability that ChatGPT or an
agent system can use to perform additional actions. Now let’s examine the basis for
OpenAI plugins and the function definition.

=== Chapter_8_Memory ===


--- Page 8 ---
brief contents
1 ■ Introduction to agents and their world 1
2 ■ Harnessing the power of large language models 14
3 ■ Engaging GPT assistants 39
4 ■ Exploring multi-agent systems 68
5 ■ Empowering agents with actions 98
6 ■ Building autonomous assistants 129
7 ■ Assembling and using an agent platform 160
8 ■ Understanding agent memory and knowledge 180
9 ■ Mastering agent prompts with prompt flow 212
10 ■ Agent reasoning and evaluation 244
11 ■ Agent planning and feedback 272
vvii

--- Page 9 ---
contents
preface xiii
acknowledgments xv
about this book xvii
about the author xxi
about the cover illustration xxii
1 Introduction to agents and their world 1
1.1 Defining agents 1
1.2 Understanding the component systems of an agent 4
1.3 Examining the rise of the agent era: Why agents? 9
1.4 Peeling back the AI interface 11
1.5 Navigating the agent landscape 12
2 Harnessing the power of large language models 14
2.1 Mastering the OpenAI API 16
Connecting to the chat completions model 16 ■ Understanding the
request and response 18
2.2 Exploring open source LLMs with LM Studio 20
Installing and running LM Studio 20 ■ Serving an LLM locally
with LM Studio 23
vii

--- Page 10 ---
viii CONTENTS
2.3 Prompting LLMs with prompt engineering 25
Creating detailed queries 28 ■ Adopting personas 29
Using delimiters 30 ■ Specifying steps 31 ■ Providing
examples 32 ■ Specifying output length 33
2.4 Choosing the optimal LLM for your specific needs 34
2.5 Exercises 36
3 Engaging GPT assistants 39
3.1 Exploring GPT assistants through ChatGPT 40
3.2 Building a GPT that can do data science 44
3.3 Customizing a GPT and adding custom actions 49
Creating an assistant to build an assistant 49 ■ Connecting the
custom action to an assistant 53
3.4 Extending an assistant’s knowledge using file uploads 56
Building the Calculus Made Easy GPT 56 ■ Knowledge search
and more with file uploads 58
3.5 Publishing your GPT 61
Expensive GPT assistants 62 ■ Understanding the economics of
GPTs 63 ■ Releasing the GPT 63
3.6 Exercises 65
4 Exploring multi-agent systems 68
4.1 Introducing multi-agent systems with AutoGen Studio 69
Installing and using AutoGen Studio 70 ■ Adding skills in
AutoGen Studio 72
4.2 Exploring AutoGen 77
Installing and consuming AutoGen 77 ■ Enhancing code output
with agent critics 79 ■ Understanding the AutoGen cache 81
4.3 Group chat with agents and AutoGen 82
4.4 Building an agent crew with CrewAI 84
Creating a jokester crew of CrewAI agents 84 ■ Observing agents
working with AgentOps 87
4.5 Revisiting coding agents with CrewAI 90
4.6 Exercises 95

--- Page 11 ---
CONTENTS ix
5 Empowering agents with actions 98
5.1 Defining agent actions 99
5.2 Executing OpenAI functions 101
Adding functions to LLM API calls 101 ■ Actioning function
calls 103
5.3 Introducing Semantic Kernel 107
Getting started with SK semantic functions 108 ■ Semantic
functions and context variables 109
5.4 Synergizing semantic and native functions 111
Creating and registering a semantic skill/plugin 111 ■ Applying
native functions 115 ■ Embedding native functions within
semantic functions 117
5.5 Semantic Kernel as an interactive service agent 118
Building a semantic GPT interface 119 ■ Testing semantic
services 121 ■ Interactive chat with the semantic service
layer 122
5.6 Thinking semantically when writing semantic
services 125
5.7 Exercises 127
6 Building autonomous assistants 129
6.1 Introducing behavior trees 130
Understanding behavior tree execution 131 ■ Deciding on
behavior trees 132 ■ Running behavior trees with Python
and py_trees 134
6.2 Exploring the GPT Assistants Playground 136
Installing and running the Playground 136 ■ Using and
building custom actions 138 ■ Installing the assistants
database 140 ■ Getting an assistant to run code locally 140
Investigating the assistant process through logs 142
6.3 Introducing agentic behavior trees 143
Managing assistants with assistants 143 ■ Building a coding
challenge ABT 145 ■ Conversational AI systems vs. other
methods 149 ■ Posting YouTube videos to X 150
Required X setup 151
6.4 Building conversational autonomous multi-agents 153

--- Page 12 ---
x CONTENTS
6.5 Building ABTs with back chaining 155
6.6 Exercises 156
7 Assembling and using an agent platform 160
7.1 Introducing Nexus, not just another agent platform 161
Running Nexus 162 ■ Developing Nexus 163
7.2 Introducing Streamlit for chat application
development 165
Building a Streamlit chat application 165 ■ Creating a streaming
chat application 168
7.3 Developing profiles and personas for agents 170
7.4 Powering the agent and understanding the agent
engine 172
7.5 Giving an agent actions and tools 174
7.6 Exercises 178
8 Understanding agent memory and knowledge 180
8.1 Understanding retrieval in AI applications 181
8.2 The basics of retrieval augmented generation (RAG) 182
8.3 Delving into semantic search and document
indexing 184
Applying vector similarity search 184 ■ Vector databases and
similarity search 188 ■ Demystifying document embeddings 189
Querying document embeddings from Chroma 190
8.4 Constructing RAG with LangChain 192
Splitting and loading documents with LangChain 192 ■ Splitting
documents by token with LangChain 195
8.5 Applying RAG to building agent knowledge 196
8.6 Implementing memory in agentic systems 200
Consuming memory stores in Nexus 202 ■ Semantic memory and
applications to semantic, episodic, and procedural memory 204
8.7 Understanding memory and knowledge
compression 207
8.8 Exercises 209

--- Page 13 ---
CONTENTS xi
9 Mastering agent prompts with prompt flow 212
9.1 Why we need systematic prompt engineering 213
9.2 Understanding agent profiles and personas 216
9.3 Setting up your first prompt flow 217
Getting started 218 ■ Creating profiles with Jinja2
templates 222 ■ Deploying a prompt flow API 223
9.4 Evaluating profiles: Rubrics and grounding 224
9.5 Understanding rubrics and grounding 228
9.6 Grounding evaluation with an LLM profile 230
9.7 Comparing profiles: Getting the perfect
profile 232
Parsing the LLM evaluation output 232 ■ Running batch
processing in prompt flow 235 ■ Creating an evaluation flow
for grounding 238 ■ Exercises 242
10 Agent reasoning and evaluation 244
10.1 Understanding direct solution prompting 245
Question-and-answer prompting 246 ■ Implementing few-shot
prompting 248 ■ Extracting generalities with zero-shot
prompting 250
10.2 Reasoning in prompt engineering 252
Chain of thought prompting 253 ■ Zero-shot CoT
prompting 257 ■ Step by step with prompt chaining 258
10.3 Employing evaluation for consistent solutions 261
Evaluating self-consistency prompting 262 ■ Evaluating tree of
thought prompting 266
10.4 Exercises 270
11 Agent planning and feedback 272
11.1 Planning: The essential tool for all agents/assistants 273
11.2 Understanding the sequential planning process 277
11.3 Building a sequential planner 278
11.4 Reviewing a stepwise planner: OpenAI Strawberry 285

--- Page 14 ---
xii CONTENTS
11.5 Applying planning, reasoning, evaluation, and feedback to
assistant and agentic systems 288
Application of assistant/agentic planning 288 ■ Application of
assistant/agentic reasoning 290 ■ Application of evaluation to
agentic systems 291 ■ Application of feedback to agentic/assistant
applications 293
11.6 Exercises 296
appendix A Accessing OpenAI large language models 299
appendix B Python development environment 305
index 311

--- Page 15 ---
preface
My journey into the world of intelligent systems began back in the early 1980s. Like
many people then, I believed artificial intelligence (AI) was just around the corner. It
always seemed like one more innovation and technological leap would lead us to the
intelligence we imagined. But that leap never came.
Perhaps the promise of HAL, from Stanley Kubrick’s 2001: A Space Odyssey, capti-
vated me with the idea of a truly intelligent computer companion. After years of effort,
trial, and countless errors, I began to understand that creating AI was far more com-
plex than we humans had imagined. In the early 1990s, I shifted my focus, applying
my skills to more tangible goals in other industries.
Not until the late 1990s, after experiencing a series of challenging and transforma-
tive events, did I realize my passion for building intelligent systems. I knew these sys-
tems might never reach the superintelligence of HAL, but I was okay with that. I
found fulfillment in working with machine learning and data science, creating models
that could learn and adapt. For more than 20 years, I thrived in this space, tackling
problems that required creativity, precision, and a sense of possibility.
During that time, I worked on everything from genetic algorithms for predicting
unknown inputs to developing generative learning models for horizontal drilling in
the oil-and-gas sector. These experiences led me to write, where I shared my knowl-
edge by way of books on various topics—reverse-engineering Pokémon Go, building
augmented and virtual reality experiences, designing audio for games, and applying
reinforcement learning to create intelligent agents. I spent years knuckles-deep in
code, developing agents in Unity ML-Agents and deep reinforcement learning.
xiii

--- Page 16 ---
xiv PREFACE
Even then, I never imagined that one day I could simply describe what I wanted to
an AI model, and it would make it happen. I never imagined that, in my lifetime, I
would be able to collaborate with an AI as naturally as I do today. And I certainly never
imagined how fast—and simultaneously how slow—this journey would feel.
In November 2022, the release of ChatGPT changed everything. It changed the
world’s perception of AI, and it changed the way we build intelligent systems. For me,
it also altered my perspective on the capabilities of these systems. Suddenly, the idea
of agents that could autonomously perform complex tasks wasn’t just a far-off dream
but instead a tangible, achievable reality. In some of my earlier books, I had described
agentic systems that could undertake specific tasks, but now, those once-theoretical
ideas were within reach.
This book is the culmination of my decades of experience in building intelligent
systems, but it’s also a realization of the dreams I once had about what AI could
become. AI agents are here, poised to transform how we interact with technology, how
we work, and, ultimately, how we live.
Yet, even now, I see hesitation from organizations when it comes to adopting agen-
tic systems. I believe this hesitation stems not from fear of AI but rather from a lack
of understanding and expertise in building these systems. I hope that this book
helps to bridge that gap. I want to introduce AI agents as tools that can be accessible
to everyone—tools we shouldn’t fear but instead respect, manage responsibly, and
learn to work with in harmony.

--- Page 17 ---
acknowledgments
I want to extend my deepest gratitude to the machine learning and deep learning
communities for their tireless dedication and incredible work. Just a few short years
ago, many questioned whether the field was headed for another AI winter—a period
of stagnation and doubt. But thanks to the persistence, brilliance, and passion of
countless individuals, the field not only persevered but also flourished. We’re standing
on the threshold of an AI-driven future, and I am endlessly grateful for the contribu-
tions of this talented community.
Writing a book, even with the help of AI, is no small feat. It takes dedication, col-
laboration, and a tremendous amount of support. I am incredibly thankful to the
team of editors and reviewers who made this book possible. I want to express my
heartfelt thanks to everyone who took the time to review and provide feedback. In
particular, I want to thank Becky Whitney, my content editor, and Ross Turner, my
technical editor and chief production and technology officer at OpenSC, for their
dedication, as well as the whole production team at Manning for their insight and
unwavering support throughout this journey.
To my partner, Rhonda—your love, patience, and encouragement mean the world
to me. You’ve been the cornerstone of my support system, not just for this book but
for all the books that have come before. I truly couldn’t have done any of this without
you. Thank you for being my rock, my partner, and my inspiration.
Many of the early ideas for this book grew out of my work at Symend. It was during
my time there that I first began developing the concepts and designs for agentic sys-
tems that laid the foundation for this book. I am deeply grateful to my colleagues at
xv

--- Page 18 ---
xvi ACKNOWLEDGMENTS
Symend for their collaboration and contributions, including Peh Teh, Andrew Wright,
Ziko Rajabali, Chris Garrett, Kouros, Fatemeh Torabi Asr, Sukh Singh, and Hanif
Joshaghani. Your insights and hard work helped bring these ideas to life, and I am
honored to have worked alongside such an incredible group of people.
Finally, I would like to thank all the reviewers: Anandaganesh Balakrishnan, Aryan
Jadon, Chau Giang, Dan Sheikh, David Curran, Dibyendu Roy Chowdhury, Divya
Bhargavi, Felipe Provezano Coutinho, Gary Pass, John Williams, Jose San Leandro,
Laurence Giglio, Manish Jain, Maxim Volgin, Michael Wang, Mike Metzger, Piti
Champeethong, Prashant Dwivedi, Radhika Kanubaddhi, Rajat Kant Goel, Ramaa
Vissa, Richard Vaughan, Satej Kumar Sahu, Sergio Gtz, Siva Dhandapani, Annamaneni
Sriharsha, Sri Ram Macharla, Sumit Bhattacharyya, Tony Holdroyd, Vidal Graupera,
Vidhya Vinay, and Vinoth Nageshwaran. Your suggestions helped make this a better
book.

--- Page 19 ---
about this book
AI Agents in Action is about building and working with intelligent agent systems—not
just creating autonomous entities but also developing agents that can effectively tackle
and solve real-world problems. The book starts with the basics of working with large
language models (LLMs) to build assistants, multi-agent systems, and agentic behav-
ioral agents. From there, it explores the key components of agentic systems: retrieval
systems for knowledge and memory augmentation, action and tool usage, reasoning,
planning, evaluation, and feedback. The book demonstrates how these components
empower agents to perform a wide range of complex tasks through practical examples.
This journey isn’t just about technology; it’s about reimagining how we approach
problem solving. I hope this book inspires you to see intelligent agents as partners in
innovation, capable of transforming ideas into actions in ways that were once thought
impossible. Together, we’ll explore how AI can augment human potential, enabling us
to achieve far more than we could alone.
Who should read this book
This book is for anyone curious about intelligent agents and how to develop agentic
systems—whether you’re building your first helpful assistant or diving deeper into
complex multi-agent systems. No prior experience with agents, agentic systems,
prompt engineering, or working with LLMs is required. All you need is a basic under-
standing of Python and familiarity with GitHub repositories. My goal is to make these
concepts accessible and engaging, empowering anyone who wants to explore the
world of AI agents to do so with confidence.
xvii

--- Page 20 ---
xviii ABOUT THIS BOOK
Whether you’re a developer, researcher, or hobbyist or are simply intrigued by the
possibilities of AI, this book is for you. I hope that in these pages you’ll find inspira-
tion, practical guidance, and a new appreciation for the remarkable potential of intel-
ligent agents. Let this book guide understanding, creating, and unleashing the power
of AI agents in action.
How this book is organized: A road map
This book has 11 chapters. Chapter 1, “Introduction to agents and their world,”
begins by laying a foundation with fundamental definitions of large language models,
chat systems, assistants, and autonomous agents. As the book progresses, the discus-
sion shifts to the key components that make up an agent and how these components
work together to create truly effective systems. Here is a quick summary of chapters 2
through 11:
 Chapter 2, “Harnessing the power of large language models”—We start by exploring
how to use commercial LLMs, such as OpenAI. We then examine tools, such as
LM Studio, that provide the infrastructure and support for running various
open source LLMs, enabling anyone to experiment and innovate.
 Chapter 3, “Engaging GPT assistants”—This chapter dives into the capabilities of
the GPT Assistants platform from OpenAI. Assistants are foundational agent
types, and we explore how to create practical and diverse assistants, from culi-
nary helpers to intern data scientists and even a book learning assistant.
 Chapter 4, “Exploring multi-agent systems”—Agentic tools have advanced signifi-
cantly quickly. Here, we explore two sophisticated multi-agent systems: CrewAI
and AutoGen. We demonstrate AutoGen’s ability to develop code autono-
mously and see how CrewAI can bring together a group of joke researchers to
create humor collaboratively.
 Chapter 5, “Empowering agents with actions”—Actions are fundamental to any
agentic system. This chapter discusses how agents can use tools and functions to
execute actions, ranging from database and application programming interface
(API) queries to generating images. We focus on enabling agents to take mean-
ingful actions autonomously.
 Chapter 6, “Building autonomous assistants”—We explore the behavior tree—a sta-
ple in robotics and game systems—as a mechanism to orchestrate multiple
coordinated agents. We’ll use behavior trees to tackle challenges such as code
competitions and social media content creation.
 Chapter 7, “Assembling and using an agent platform”—This chapter introduces Nexus,
a sophisticated platform for orchestrating multiple agents and LLMs. We discuss
how Nexus facilitates agentic workflows and enables complex interactions between
agents, providing an example of a fully functioning multi-agent environment.
 Chapter 8, “Understanding agent memory and knowledge”—Retrieval-augmented
generation (RAG) has become an essential tool for extending the capabilities

--- Page 21 ---
ABOUT THIS BOOK xix
of LLM agents. This chapter explores how retrieval mechanisms can serve as
both a source of knowledge by processing ingested files, and of memory, allow-
ing agents to recall previous interactions or events.
 Chapter 9, “Mastering agent prompts with prompt flow”—Prompt engineering is cen-
tral to an agent’s success. This chapter introduces prompt flow, a tool from Mic-
rosoft that helps automate the testing and evaluation of prompts, enabling
more robust and effective agentic behavior.
 Chapter 10, “Agent reasoning and evaluation”—Reasoning is crucial to solving
problems intelligently. In this chapter, we explore various reasoning techniques,
such as chain of thought (CoT), and show how agents can evaluate reasoning
strategies even during inference, improving their capacity to solve problems
autonomously.
 Chapter 11, “Agent planning and feedback”—Planning is perhaps an agent’s most crit-
ical skill in achieving its goals. We discuss how agents can incorporate planning to
navigate complex tasks and how feedback loops can be used to refine those plans.
The chapter concludes by integrating all the key components—actions, memory
and knowledge, reasoning, evaluation, planning, and feedback—into practical
examples of agentic systems that solve real-world problems.
About the code
The code for this book is spread across several open source projects, many of which
are hosted by me or by other organizations in GitHub repositories. Throughout this
book, I strive to make the content as accessible as possible, taking a low-code approach
to help you focus on core concepts. Many chapters demonstrate how simple prompts
can generate meaningful code, showcasing the power of AI-assisted development.
Additionally, you’ll find a variety of assistant profiles and multi-agent systems that
demonstrate how to solve real-world problems using generated code. These examples
are meant to inspire, guide, and empower you to explore what is possible with AI
agents. I am deeply grateful to the many contributors and the community members
who have collaborated on these projects, and I encourage you to explore the reposito-
ries, experiment with the code, and adapt it to your own needs. This book is a testa-
ment to the power of collaboration and the incredible things we can achieve together.
This book contains many examples of source code both in numbered listings and in
line with normal text. In both cases, source code is formatted in a fixed-width font
like this to separate it from ordinary text. Sometimes, some of the code is typeset in
bold to highlight code that has changed from previous steps in the chapter, such as
when a feature is added to an existing line of code. In many cases, the original source
code has been reformatted; we’ve added line breaks and reworked indentation to
accommodate the available page space in the book. In some cases, even this wasn’t
enough, and listings include line-continuation markers (➥). Additionally, comments in
the source code have often been removed from the listings when the code is described

--- Page 22 ---
xx ABOUT THIS BOOK
in the text. Code annotations accompany many of the listings, highlighting important
concepts.
You can get executable snippets of code from the liveBook (online) version of this
book at https://livebook.manning.com/book/ai-agents-in-action. The complete code
for the examples in the book is available for download from the Manning website at
www.manning.com/books/ai-agents-in-action. In addition, the code developed for this
book has been placed in three GitHub repositories that are all publicly accessible:
 GPT-Agents (the original book title), at https://github.com/cxbxmxcx/GPT-
Agents, holds the code for several examples demonstrated in the chapters.
 GPT Assistants Playground, at https://github.com/cxbxmxcx/GPTAssistants
Playground, is an entire platform and tool dedicated to building OpenAI GPT
assistants with a helpful web user interface and plenty of tools to develop auton-
omous agent systems.
 Nexus, at https://github.com/cxbxmxcx/Nexus, is an example of a web-based
agentic tool that can help you create agentic systems and demonstrate various
code challenges.
liveBook discussion forum
Purchase of AI Agents in Action includes free access to liveBook, Manning’s online
reading platform. Using liveBook’s exclusive discussion features, you can attach com-
ments to the book globally or to specific sections or paragraphs. It’s a snap to make
notes for yourself, ask and answer technical questions, and receive help from the
author and other users. To access the forum, go to https://livebook.manning.com/
book/ai-agents-in-action/discussion. You can also learn more about Manning’s forums
and the rules of conduct at https://livebook.manning.com/discussion.
Manning’s commitment to our readers is to provide a venue where a meaningful
dialogue between individual readers and between readers and the author can take
place. It isn’t a commitment to any specific amount of participation on the part of the
author, whose contribution to the forum remains voluntary (and unpaid). We suggest
you try asking the him challenging questions lest his interest stray! The forum and the
archives of previous discussions will be accessible from the publisher’s website as long
as the book is in print.

--- Page 206 ---
182 CHAPTER 8 Understanding agent memory and knowledge
The retrieval mechanism, called retrieval augmented generation (RAG), has
become a standard for providing relevant context to a prompt. The exact mechanism
that powers RAG also powers memory/knowledge, and it’s essential to understand
how it works. In the next section, we’ll examine what RAG is.
8.2 The basics of retrieval augmented generation (RAG)
RAG has become a popular mechanism for supporting document chat or question-
and-answer chat. The system typically works by a user supplying a relevant document,
such as a PDF, and then using RAG and a large language model (LLM) to query the
document.
Figure 8.2 shows how RAG can allow a document to be queried using an LLM.
Before any document can be queried, it must first be loaded, transformed into con-
text chunks, embedded into vectors, and stored in a vector database.
Retrieval Augmented Generation (RAG)
Document is loaded, Chunks of text
transformed, and are converted
split into chunks. to vectors.
Submit document
to query Transform Embedding Vector DB Vectors
Documents are representing
first indexed to a chunks of text
vector database. are stored.
LLM Chat
(2)Augment
Indexed documents Query is Prompt
can be queried/ embedded Retrieval works
questioned by the to represent (1) Retrieve by using vector system: you are a ...
user. a vector. similarity search.
Query
Embedding Vector DB
Query Context Context
Retrieved context
Response
semantically matches
the query.
LLM
LLM generates a response
(3) Generate based on the contextualized
prompt.
Figure 8.2 The two phases of RAG: first, documents must be loaded, transformed, embedded, and stored, and,
second, they can be queried using augmented generation.
A user can query previously indexed documents by submitting a query. That query is
then embedded into a vector representation to search for similar chunks in the vector

--- Page 207 ---
8.2 The basics of retrieval augmented generation (RAG) 183
database. Content similar to the query is then used as context and populated into the
prompt as augmentation. The prompt is pushed to an LLM, which can use the con-
text information to help answer the query.
Unstructured memory/knowledge concepts rely on some format of text-similarity
search following the retrieval pattern shown in figure 8.2. Figure 8.3 shows how mem-
ory uses the same embedding and vector database components. Rather than preload
documents, conversations or parts of a conversation are embedded and saved to a vec-
tor database.
Memory Retrieval Augmented Generation
LLM Chat
(2)Augment
Query is Prompt
embedded Retrieval works
to represent (1) Retrieve by using vector system: you are a ...
a vector. Memory similarity search.
Query
Embedding Vector DB
Query Memory Memory
Retrieved memory
Response
semantically matches
the query.
All or parts of the
Embedding LLM
conversation are
Chat with memory embedded and Generated
added to the Response
vector database.
(4) Remember (3) Generate
LLM generates a
response based on the
contextualized prompt.
Figure 8.3 Memory retrieval for augmented generation uses the same embedding patterns to index items to a
vector database.
The retrieval pattern and document indexing are nuanced and require careful con-
sideration to be employed successfully. This requires understanding how data is stored
and retrieved, which we’ll start to unfold in the next section.

--- Page 208 ---
184 CHAPTER 8 Understanding agent memory and knowledge
8.3 Delving into semantic search and document indexing
Document indexing transforms a document’s information to be more easily recov-
ered. How the index will be queried or searched also plays a factor, whether searching
for a particular set of words or wanting to match phrase for phrase.
A semantic search is a search for content that matches the searched phrase by words
and meaning. The ability to search by meaning, semantically, is potent and worth
investigating in some detail. In the next section, we look at how vector similarity
search can lay the framework for semantic search.
8.3.1 Applying vector similarity search
Let’s look now at how a document can be transformed into a semantic vector, or a repre-
sentation of text that can then be used to perform distance or similarity matching.
There are numerous ways to convert text into a semantic vector, so we’ll look at a sim-
ple one.
Open the chapter_08 folder in a new Visual Studio Code (VS Code) workspace.
Create a new environment and pip install the requirements.txt file for all the
chapter dependencies. If you need help setting up a new Python environment, con-
sult appendix B.
Now open the document_vector_similarity.py file in VS Code, and review the
top section in listing 8.1. This example uses Term Frequency–Inverse Document Fre-
quency (TF–IDF). This numerical statistic reflects how important a word is to a docu-
ment in a collection or set of documents by increasing proportionally to the number
of times a word appears in the document and offset by the frequency of the word in
the document set. TF–IDF is a classic measure of understanding one document’s
importance within a set of documents.
Listing8.1 document_vector_similarity (transform to vector)
import plotly.graph_objects as go
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
documents = [ Samples of documents
"The sky is blue and beautiful.",
"Love this blue and beautiful sky!",
"The quick brown fox jumps over the lazy dog.",
"A king's breakfast has sausages, ham, bacon, eggs, toast, and beans",
"I love green eggs, ham, sausages and bacon!",
"The brown fox is quick and the blue dog is lazy!",
"The sky is very blue and the sky is very beautiful today",
"The dog is lazy but the brown fox is quick!"
]
Vectorization
using TF–IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(documents)
Vectorize the
documents.

--- Page 209 ---
8.3 Delving into semantic search and document indexing 185
Let’s break down TF–IDF into its two components using the sample sentence, “The
sky is blue and beautiful,” and focusing on the word blue.
TERM FREQUENCY (TF)
Term Frequency measures how frequently a term occurs in a document. Because we’re
considering only a single document (our sample sentence), the simplest form of the
TF for blue can be calculated as the number of times blue appears in the document
divided by the total number of words in the document. Let’s calculate it:
Number of times blue appears in the document: 1
Total number of words in the document: 6
TF = 1 ÷ 6TF = .16
INVERSE DOCUMENT FREQUENCY (IDF)
Inverse Document Frequency measures how important a term is within the entire corpus.
It’s calculated by dividing the total number of documents by the number of docu-
ments containing the term and then taking the logarithm of that quotient:
IDF = log(Total number of documents ÷ Number of documents containing the word)
In this example, the corpus is a small collection of eight documents, and blue appears
in four of these documents.
IDF = log(8 ÷ 4)
TF–IDF CALCULATION
Finally, the TF–IDF score for blue in our sample sentence is calculated by multiplying
the TF and the IDF scores:
TF–IDF = TF × IDF
Let’s compute the actual values for TF–IDF for the word blue using the example pro-
vided; first, the term frequency (how often the word occurs in the document) is com-
puted as follows:
TF = 1 ÷ 6
Assuming the base of the logarithm is 10 (commonly used), the inverse document fre-
quency is computed as follows:
IDF = log10 (8 ÷ 4)
Now let’s calculate the exact TF–IDF value for the word blue in the sentence, “The sky
is blue and beautiful”:

--- Page 210 ---
186 CHAPTER 8 Understanding agent memory and knowledge
The Term Frequency (TF) is approximately 0.1670.
The Inverse Document Frequency (IDF) is approximately 0.301.
Thus, the TF–IDF (TF × IDF) score for blue is approximately 0.050.
This TF–IDF score indicates the relative importance of the word blue in the given doc-
ument (the sample sentence) within the context of the specified corpus (eight docu-
ments, with blue appearing in four of them). Higher TF–IDF scores imply greater
importance.
We use TF–IDF here because it’s simple to apply and understand. Now that we
have the elements represented as vectors, we can measure document similarity using
cosine similarity. Cosine similarity is a measure used to calculate the cosine of the
angle between two nonzero vectors in a multidimensional space, indicating how simi-
lar they are, irrespective of their size.
Figure 8.4 shows how cosine distance compares the vector representations of two
pieces or documents of text. Cosine similarity returns a value from –1 (not similar) to
1 (identical). Cosine distance is a normalized value ranging from 0 to 2, derived by tak-
ing 1 minus the cosine similarity. A cosine distance of 0 means identical items, and 2
indicates complete opposites.
Cosine Similarity
The sky is blue and beautiful.
Vector representations of the text rendered in 2D
and in reality vectors can be highly dimensional.
Love this blue and beautiful sky!
θ The angle or distance is a measure of how
close the vectors are in space. It also
Cosine Distance represents their similarity to each other.
Figure 8.4 How cosine
similarity is measured
Listing 8.2 shows how the cosine similarities are computed using the cosine_similarity
function from scikit-learn. Similarities are calculated for each document against all
other documents in the set. The computed matrix of similarities for documents is
stored in the cosine_similarities variable. Then, in the input loop, the user can
select the document to view its similarities to the other documents.

--- Page 211 ---
8.3 Delving into semantic search and document indexing 187
Listing8.2 document_vector_similarity (cosine similarity)
Computes the document
cosine_similarities = cosine_similarity(X)
similarities for all vector pairs
while True:
The main
selected_document_index = input(f"Enter a document number
input loop
➥
(0-{len(documents)-1}) or 'exit' to quit: ").strip()
if selected_document_index.lower() == 'exit':
break
if not selected_document_index.isdigit() or
➥
not 0 <= int(selected_document_index) < len(documents):
print("Invalid input. Please enter a valid document number.")
continue
Gets the selected
selected_document_index = int(selected_document_index) document index
to compare with
selected_document_similarities =
cosine_similarities[selected_document_index]
Extracts the
computed similarities
# code to plot document similarities omitted against all documents
Figure 8.5 shows the output of running the sample in VS Code (F5 for debugging
mode). After you select a document, you’ll see the similarities between the various
documents in the set. A document will have a cosine similarity of 1 with itself. Note
that you won’t see a negative similarity because of the TF–IDF vectorization. We’ll look
later at other, more sophisticated means of measuring semantic similarity.
Cosine Similarities of“The sky is blue and beautiful.”with Others
The select document is compared against all
other documents to show similarity
measure between document vectors.
Figure 8.5 The cosine similarity between selected documents and the document set

--- Page 212 ---
188 CHAPTER 8 Understanding agent memory and knowledge
The method of vectorization will dictate the measure of semantic similarity between
documents. Before we move on to better methods of vectorizing documents, we’ll
examine storing vectors to perform vector similarity searches.
8.3.2 Vector databases and similarity search
After vectorizing documents, they can be stored in a vector database for later similar-
ity searches. To demonstrate how this works, we can efficiently replicate a simple vec-
tor database in Python code.
Open document_vector_database.py in VS Code, as shown in listing 8.3. This
code demonstrates creating a vector database in memory and then allowing users to
enter text to search the database and return results. The results returned show the
document text and the similarity score.
Listing8.3 document_vector_database.py
# code above omitted
Stores the
vectorizer = TfidfVectorizer()
document vectors
X = vectorizer.fit_transform(documents)
into an array
vector_database = X.toarray()
def cosine_similarity_search(query, The function to perform
database, similarity matching on
query returns, matches,
vectorizer,
and similarity scores
top_n=5):
query_vec = vectorizer.transform([query]).toarray()
similarities = cosine_similarity(query_vec, database)[0]
top_indices = np.argsort(-similarities)[:top_n] # Top n indices
return [(idx, similarities[idx]) for idx in top_indices]
while True:
The main
query = input("Enter a search query (or 'exit' to stop): ")
input loop
if query.lower() == 'exit':
break
top_n = int(input("How many top matches do you want to see? "))
search_results = cosine_similarity_search(query,
vector_database,
vectorizer,
top_n)
print("Top Matched Documents:")
for idx, score in search_results:
print(f"- {documents[idx]} (Score: {score:.4f})")
Loops through
results and
print("\n") outputs text and
###Output similarity score
Enter a search query (or 'exit' to stop): blue
How many top matches do you want to see? 3
Top Matched Documents:
- The sky is blue and beautiful. (Score: 0.4080)
- Love this blue and beautiful sky! (Score: 0.3439)
- The brown fox is quick and the blue dog is lazy! (Score: 0.2560)

--- Page 213 ---
8.3 Delving into semantic search and document indexing 189
Run this exercise to see the output (F5 in VS Code). Enter any text you like, and see
the results of documents being returned. This search form works well for matching
words and phrases with similar words and phrases. This form of search misses the
word context and meaning from the document. In the next section, we’ll look at a way
of transforming documents into vectors that better preserves their semantic meaning.
8.3.3 Demystifying document embeddings
TF–IDF is a simple form that tries to capture semantic meaning in documents. How-
ever, it’s unreliable because it only counts word frequency and doesn’t understand the
relationships between words. A better and more modern method uses document
embedding, a form of document vectorizing that better preserves the semantic mean-
ing of the document.
Embedding networks are constructed by training neural networks on large data-
sets to map words, sentences, or documents to high-dimensional vectors, capturing
semantic and syntactic relationships based on context and relationships in the data.
You typically use a pretrained model trained on massive datasets to embed documents
and perform embeddings. Models are available from many sources, including Hug-
ging Face and, of course, OpenAI.
In our next scenario, we’ll use an OpenAI embedding model. These models are
typically perfect for capturing the semantic context of embedded documents. Listing
8.4 shows the relevant code that uses OpenAI to embed the documents into vectors
that are then reduced to three dimensions and rendered into a plot.
Listing8.4 document_visualizing_embeddings.py (relevant sections)
load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')
Join all the items on the string ', '.
if not api_key:
raise ValueError("No API key found. Please check your .env file.")
client = OpenAI(api_key=api_key)
def get_embedding(text, model="text-embedding-ada-002"):
Uses the OpenAI
text = text.replace("\n", " ")
client to create
return client.embeddings.create(input=[text],
the embedding
model=model).data[0].embedding
# Sample documents (omitted) Generates embeddings
for each document of
size 1536 dimensions
embeddings = [get_embedding(doc) for doc in documents]
print(embeddings_array.shape)
Converts embeddings to
a NumPy array for PCA
embeddings_array = np.array(embeddings)
pca = PCA(n_components=3)
Applies PCA to
reduced_embeddings = pca.fit_transform(embeddings_array)
reduce dimensions
to 3 for plotting

--- Page 214 ---
190 CHAPTER 8 Understanding agent memory and knowledge
When a document is embedded using an OpenAI model, it transforms the text into a
vector with dimensions of 1536. We can’t visualize this number of dimensions, so we
use a dimensionality reduction technique via principal component analysis (PCA) to
convert the vector of size 1536 to 3 dimensions.
Figure 8.6 shows the output generated from running the file in VS Code. By reduc-
ing the embeddings to 3D, we can plot the output to show how semantically similar
documents are now grouped.
Similar documents are now similar in
meaning and are shown grouped together.
Documents are projected to 3D
based on their semantic meaning.
Figure 8.6 Embeddings in 3D, showing how similar semantic documents are grouped
The choice of which embedding model or service you use is up to you. The OpenAI
embedding models are considered the best for general semantic similarity. This has
made these models the standard for most memory and retrieval applications. With
our understanding of how text can be vectorized with embeddings and stored in a vec-
tor database, we can move on to a more realistic example in the next section.
8.3.4 Querying document embeddings from Chroma
We can combine all the pieces and look at a complete example using a local vector
database called Chroma DB. Many vector database options exist, but Chroma DB is an
excellent local vector store for development or small-scale projects. There are also
plenty of more robust options that you can consider later.

--- Page 215 ---
8.3 Delving into semantic search and document indexing 191
Listing 8.5 shows the new and relevant code sections from the document_query_
chromadb.py file. Note that the results are scored by distance and not by similarity.
Cosine distance is determined by this equation:
Cosine Distance(A,B) = 1 – Cosine Similarity(A,B)
This means that cosine distance will range from 0 for most similar to 2 for semanti-
cally opposite in meaning.
Listing8.5 document_query_chromadb.py (relevant code sections)
embeddings = [get_embedding(doc) for doc in documents] Generates embeddings
for each document and
ids = [f"id{i}" for i in range(len(documents))]
assigns an ID
chroma_client = chromadb.Client()
Creates a Chroma DB
collection = chroma_client.create_collection(
client and a collection
name="documents")
collection.add(
Adds document
embeddings=embeddings,
embeddings to
documents=documents, the collection
ids=ids
)
def query_chromadb(query, top_n=2):
Queries the datastore
query_embedding = get_embedding(query)
and returns the top n
results = collection.query( relevant documents
query_embeddings=[query_embedding],
n_results=top_n
)
return [(id, score, text) for id, score, text in
zip(results['ids'][0],
results['distances'][0],
results['documents'][0])]
while True:
query = input("Enter a search query (or 'exit' to stop): ")
if query.lower() == 'exit':
break
top_n = int(input("How many top matches do you want to see? "))
search_results = query_chromadb(query, top_n)
The input loop for
print("Top Matched Documents:") user input and output of
for id, score, text in search_results: relevant documents/scores
print(f"""
ID:{id} TEXT: {text} SCORE: {round(score, 2)}
""")
print("\n")
###Output
Enter a search query (or 'exit' to stop): dogs are lazy
How many top matches do you want to see? 3
Top Matched Documents:
ID:id7 TEXT: The dog is lazy but the brown fox is quick! SCORE: 0.24

--- Page 216 ---
192 CHAPTER 8 Understanding agent memory and knowledge
ID:id5 TEXT: The brown fox is quick and the blue dog is lazy! SCORE: 0.28
ID:id2 TEXT: The quick brown fox jumps over the lazy dog. SCORE: 0.29
As the earlier scenario demonstrated, you can now query the documents using seman-
tic meaning rather than just key terms or phrases. These scenarios should now pro-
vide the background to see how the retrieval pattern works at a low level. In the next
section, we’ll see how the retrieval pattern can be employed using LangChain.
8.4 Constructing RAG with LangChain
LangChain began as an open source project specializing in abstracting the retrieval
pattern across multiple data sources and vector stores. It has since morphed into
much more, but foundationally, it still provides excellent options for implementing
retrieval.
Figure 8.7 shows a diagram from LangChain that identifies the process of storing
documents for retrieval. These same steps may be replicated in whole or in part to
implement memory retrieval. The critical difference between document and memory
retrieval is the source and how content is transformed.
LangChain supports
multiple options for
LangChain provides a
vector stores.
plugin architecture that
Transform breaks Embed or
supports document import
the document embeddings
from many sources.
down into relevant break the chunks
sections or chunks. into vectors.
Figure 8.7 Load, transform, embed, and store steps in storing documents for later retrieval
We’ll examine how to implement each of these steps using LangChain and under-
stand the nuances and details accompanying this implementation. In the next section,
we’ll start by splitting and loading documents with LangChain.
8.4.1 Splitting and loading documents with LangChain
Retrieval mechanisms augment the context of a given prompt with specific informa-
tion relevant to the request. For example, you may request detailed information about

--- Page 217 ---
8.4 Constructing RAG with LangChain 193
a local document. With earlier language models, submitting the whole document as
part of the prompt wasn’t an option due to token limitations.
Today, we could submit a whole document for many commercial LLMs, such as
GPT-4 Turbo, as part of a prompt request. However, the results may not be better and
would likely cost more because of the increased number of tokens. Therefore, a better
option is to split the document and use the relevant parts to request context—pre-
cisely what RAG and memory do.
Splitting a document is essential in breaking down content into semantically and
specifically relevant sections. Figure 8.8 shows how to break down an HTML docu-
ment containing the Mother Goose nursery rhymes. Often, splitting a document into
contextual semantic chunks requires careful consideration.
Load the document(s). Split the documents into chunks.
Create
embeddings Store
Ideally, the chunks are
semantically relevant
and specific.
Figure 8.8 How the document would ideally be split into chunks for better semantic and contextual meaning
Ideally, when we split documents into chunks, they are broken down by relevance and
semantic meaning. While an LLM or agent could help us with this, we’ll look at cur-
rent toolkit options within LangChain for splitting documents. Later in this chapter,
we’ll look at a semantic function that can assist us in semantically dividing content for
embeddings.
For the next exercise, open langchain_load_splitting.py in VS Code, as shown
in listing 8.6. This code shows where we left off from listing 8.5, in the previous sec-
tion. Instead of using the sample documents, we’re loading the Mother Goose nursery
rhymes this time.

--- Page 218 ---
194 CHAPTER 8 Understanding agent memory and knowledge
Listing8.6 langchain_load_splitting.py (sections and output)
New LangChain
From langchain_community.document_loaders
➥ imports
import UnstructuredHTMLLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
#previous code
Loads the
document
loader = UnstructuredHTMLLoader(
as HTML
"sample_documents/mother_goose.html")
data = loader.load
Loads the
document
text_splitter = RecursiveCharacterTextSplitter(
chunk_size=100,
Splits the document into blocks of
chunk_overlap=25,
text 100 characters long with a
length_function=len,
25-character overlap
add_start_index=True,
)
documents = text_splitter.split_documents(data) Embeds only 250
chunks, which is
documents = [doc.page_content cheaper and faster
➥
for doc in documents] [100:350]
Returns the
embeddings = [get_embedding(doc) for doc in documents] embedding for
ids = [f"id{i}" for i in range(len(documents))] each document
###Output
Enter a search query (or 'exit' to stop): who kissed the girls and made
them cry?
How many top matches do you want to see? 3
Top Matched Documents:
ID:id233 TEXT: And chid her daughter,
And kissed my sister instead of me. SCORE: 0.4…
Note in listing 8.6 that the HTML document gets split into 100-character chunks with
a 25-character overlap. The overlap allows the document’s parts not to cut off specific
thoughts. We selected the splitter for this exercise because it was easy to use, set up,
and understand.
Go ahead and run the langchain_load_splitting.py file in VS Code (F5). Enter
a query, and see what results you get. The output in listing 8.6 shows good results
given a specific example. Remember that we only embedded 250 document chunks to
reduce costs and keep the exercise short. Of course, you can always try to embed the
entire document or use a minor input document example.
Perhaps the most critical element to building proper retrieval is the process of
document splitting. You can use numerous methods to split a document, including
multiple concurrent methods. More than one method passes and splits the docu-
ment for numerous embedding views of the same document. In the next section,
we’ll examine a more general technique for splitting documents, using tokens and
tokenization.

--- Page 219 ---
8.4 Constructing RAG with LangChain 195
8.4.2 Splitting documents by token with LangChain
Tokenization is the process of breaking text into word tokens. Where a word token rep-
resents a succinct element in the text, a token could be a word like hold or even a sym-
bol like the left curly brace ({), depending on what’s relevant.
Splitting documents using tokenization provides a better base for how the text will
be interpreted by language models and for semantic similarity. Tokenization also
allows the removal of irrelevant characters, such as whitespace, making the similarity
matching of documents more relevant and generally providing better results.
For the next code exercise, open the langchain_token_splitting.py file in VS
Code, as shown in listing 8.7. Now we split the document using tokenization, which
breaks the document into sections of unequal size. The unequal size results from the
large sections of whitespace of the original document.
Listing8.7 langchain_token_splitting.py (relevant new code)
loader = UnstructuredHTMLLoader("sample_documents/mother_goose.html")
data = loader.load()
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
chunk_size=50, chunk_overlap=10
Updates to 50 tokens
)
and overlap of 10
tokens
documents = text_splitter.split_documents(data)
documents = [doc for doc in documents][8:94] Selects just the
documents that
db = Chroma.from_documents(documents, OpenAIEmbeddings()) contain rhymes
def query_documents(query, top_n=2):
docs = db.similarity_search(query, top_n) Uses the database’s
return docs similarity search
###Output
Created a chunk of size 68,
Breaks into irregular
which is longer than the specified 50
size chunks because of
Created a chunk of size 67,
the whitespace
which is longer than the specified 50
Enter a search query (or 'exit' to stop):
who kissed the girls and made them cry?
How many top matches do you want to see? 3
Top Matched Documents:
Document 1: GEORGY PORGY
Georgy Porgy, pudding and pie,
Kissed the girls and made them cry.
Run the langchain_token_splitting.py code in VS Code (F5). You can use the
query we used last time or your own. Notice how the results are significantly better
than the previous exercise. However, the results are still suspect because the query
uses several similar words in the same order.
A better test would be to try a semantically similar phrase but one that uses differ-
ent words and check the results. With the code still running, enter a new phrase to

--- Page 220 ---
196 CHAPTER 8 Understanding agent memory and knowledge
query: Why are the girls crying? Listing 8.8 shows the results of executing that
query. If you run this example yourself and scroll down over the output, you’ll see
Georgy Porgy appear in either the second or third returned document.
Listing8.8 Query: Who made the girls cry?
Enter a search query (or 'exit' to stop): Who made the girls cry?
How many top matches do you want to see? 3
Top Matched Documents:
Document 1: WILLY, WILLY
Willy, Willy Wilkin…
This exercise shows how various retrieval methods can be employed to return docu-
ments semantically. With this base established, we can see how RAG can be applied to
knowledge and memory systems. The following section will discuss RAG as it applies
to knowledge of agents and agentic systems.
8.5 Applying RAG to building agent knowledge
Knowledge in agents encompasses employing RAG to search semantically across
unstructured documents. These documents could be anything from PDFs to Micro-
soft Word documents and all text, including code. Agentic knowledge also includes
using unstructured documents for Q&A, reference lookup, information augmenta-
tion, and other future patterns.
Nexus, the agent platform developed in tandem with this book and introduced in
the previous chapter, employs complete knowledge and memory systems for agents.
In this section, we’ll uncover how the knowledge system works.
To install Nexus for just this chapter, see listing 8.9. Open a terminal within the
chapter_08 folder, and execute the commands in the listing to download, install,
and run Nexus in normal or development mode. If you want to refer to the code,
you should install the project in development and configure the debugger to run
the Streamlit app from VS Code. Refer to chapter 7 if you need a refresher on any of
these steps.
Listing8.9 Installing Nexus
# to install and run
pip install git+https://github.com/cxbxmxcx/Nexus.git
nexus run
# install in development mode
git clone https://github.com/cxbxmxcx/Nexus.git
# Install the cloned repository in editable mode
pip install -e Nexus

--- Page 222 ---
198 CHAPTER 8 Understanding agent memory and knowledge
Select to view all the Select to query the
embeddings in the document embeddings
knowledge store. in the knowledge store.
Enter text to query
and see the results of
the topfive chunks
displayed.
Plot of embeddings shown in 3D
Figure 8.10 The embeddings and document query views
Enter a question about
Select an agent engine
the script you would
that supports knowledge.
like to ask.
The agent will reply given Be sure to select the
the chosen persona. knowledge store.
Figure 8.11 Enabling the knowledge store for agent use

--- Page 223 ---
8.5 Applying RAG to building agent knowledge 199
You can also configure the RAG settings within the Configuration tab of the Knowl-
edge Store Manager page, as shown in figure 8.12. As of now, you can select from the
type of splitter (Chunking Option field) to chunk the document, along with the
Chunk Size field and Overlap field.
Select the
Configuration tab.
Allows for some overlap Represents the minimum Represents the type of
of text from one chunk size in characters or tokens document splitter used to extract
to the next to chunk the data chunks from the document
Figure 8.12 Managing the knowledge store splitting and chunking options
The loading, splitting, chunking, and embedding options provided are the only basic
options supported by LangChain for now. In future versions of Nexus, more options
and patterns will be offered. The code to support other options can be added directly
to Nexus.
We won’t cover the code that performs the RAG as it’s very similar to what we
already covered. Feel free to review the Nexus code, particularly the KnowledgeManager
class in the knowledge_manager.py file.

--- Page 224 ---
200 CHAPTER 8 Understanding agent memory and knowledge
While the retrieval patterns for knowledge and memory are quite similar for aug-
mentation, the two patterns differ when it comes to populating the stores. In the next
section, we’ll explore what makes memory in agents unique.
8.6 Implementing memory in agentic systems
Memory in agents and AI applications is often described in the same terms as cogni-
tive memory functions. Cognitive memory describes the type of memory we use to
remember what we did 30 seconds ago or how tall we were 30 years ago. Computer
memory is also an essential element of agent memory, but one we won’t consider in
this section.
Figure 8.13 shows how memory is broken down into sensory, short-term, and long-
term memory. This memory can be applied to AI agents, and this list describes how
each form of memory maps to agent functions:
 Sensory memory in AI—Functions such as RAG but with images/audio/haptic
data forms. Briefly holds input data (e.g., text and images) for immediate pro-
cessing but not long-term storage.
 Short-term/working memory in AI—Acts as an active memory buffer of conversa-
tion history. We’re holding a limited amount of recent input and context for
immediate analysis and response generation. Within Nexus, short- and long-
term conversational memory is also held in the context of the thread.
 Long-term memory in AI—Longer-term memory storage relevant to the agent’s or
user’s life. Semantic memory provides a robust capacity to store and retrieve rel-
evant global or local facts and concepts.
Iconic memory (visual) Visual memory
Sensory memory Echoic memory (auditory)
Haptic memory (touch)
Conversational
Memory Short-term memory (contextual memory)
memory and RAG
Episodic memory
(life events) This is an area of
Explicit/declarative memory memory of most
(conscious) interest to agents.
Semantic memory
Long-term memory
(facts, concepts)
Implicit/procedural memory (unconscious skills)
Implicit memory and skills can also be
conveyed as actions and tools for agents.
Figure 8.13 How memory is broken down into various forms

--- Page 225 ---
8.6 Implementing memory in agentic systems 201
While memory uses the exact same retrieval and augmentation mechanisms as knowl-
edge, it typically differs significantly when updating or appending memories. Figure 8.14
highlights the process of capturing and using memories to augment prompts. Because
memories are often different from the size of complete documents, we can avoid
using any splitting or chunking mechanisms.
Adding memories
New memories
can come from a Embedding Vector DB User likes time
User: conversation or travel movies
I like time travel
[I like time can be populated
travel movies] movies as a set of beginning User likes sci-fi
movies
facts, preferences,
and so on. Stored
embeddings
and text
LLM User likes time
Memory function, travel movies
extracts relevant
memories User likes sci-fi
movies
Conversations are then fed back into the memory function
to create new memories.
Basic memory augmentation
Augmented prompt
user: LLM Assistant:
User: What movie should What movie should You should watch
What movie I watch? I watch? this movie on
should I watch? Remembered facts: time travel.
User likes time
travel movies
Response sent
back to user
Embedding Vector DB
Converted to embedding
and then used to query database
Figure 8.14 Basic memory retrieval and augmentation workflow
Nexus provides a mechanism like the knowledge store, allowing users to create mem-
ory stores that can be configured for various uses and applications. It also supports
some of the more advanced memory forms highlighted in figure 8.13. The following
section will examine how basic memory stores work in Nexus.

--- Page 226 ---
202 CHAPTER 8 Understanding agent memory and knowledge
8.6.1 Consuming memory stores in Nexus
Memory stores operate and are constructed like knowledge stores in Nexus. They
both heavily rely on the retrieval pattern. What differs is the extra steps memory sys-
tems take to build new memories.
Go ahead and start Nexus, and refer to listing 8.9 if you need to install it. After
logging in, select the Memory page, and create a new memory store, as shown in fig-
ure 8.15. Select an agent engine, and then add a few personal facts and preferences
about yourself.
Select the Create a new memory Select the memory
Memory page. store called my_memory. you want to inspect.
Add a few facts or You will need to select an agent
preferences about yourself. engine to process the memory.
Figure 8.15 Adding memories to a newly created memory store
The reason we need an agent (LLM) was shown in figure 8.14 earlier. When informa-
tion is fed into a memory store, it’s generally processed through an LLM using a memory

--- Page 227 ---
8.6 Implementing memory in agentic systems 203
function, whose purpose is to process the statements/conversations into semantically
relevant information related to the type of memory.
Listing 8.10 shows the conversational memory function used to extract information
from a conversation into memories. Yes, this is just the header portion of the prompt
sent to the LLM, instructing it how to extract information from a conversation.
Listing8.10 Conversational memory function
Summarize the conversation and create a set of statements that summarize
the conversation. Return a JSON object with the following keys: 'summary'.
Each key should have a list of statements that are relevant to that
category. Return only the JSON object and nothing else.
After you generate a few relevant memories about yourself, return to the Chat area in
Nexus, enable the my_memory memory store, and see how well the agent knows you.
Figure 8.16 shows a sample conversation using a different agent engine.
Ask the agent something relevant to If possible, select a different agent
the facts you just added to memory. engine that supports memory.
Select the memory store.
Figure 8.16 Conversing with a different agent on the same memory store
This is an example of a basic memory pattern that extracts facts/preferences from
conversations and stores them in a vector database as memories. Numerous other
implementations of memory follow those displayed earlier in figure 8.13. We’ll imple-
ment those in the next section.

--- Page 228 ---
204 CHAPTER 8 Understanding agent memory and knowledge
8.6.2 Semantic memory and applications to semantic, episodic,
and procedural memory
Psychologists categorize memory into multiple forms, depending on what informa-
tion is remembered. Semantic, episodic, and procedural memory all represent differ-
ent types of information. Episodic memories are about events, procedural memories are
about the process or steps, and semantic represents the meaning and could include
feelings or emotions. Other forms of memory (geospatial is another), aren’t described
here but could be.
Because these memories rely on an additional level of categorization, they also rely
on another level of semantic categorization. Some platforms, such as Semantic Kernel
(SK), refer to this as semantic memory. This can be confusing because semantic categori-
zation is also applied to extract episodic and procedural memories.
Figure 8.17 shows the semantic memory categorization process, also sometimes
called semantic memory. The difference between semantic memory and regular mem-
ory is the additional step of processing the input semantically and extracting relevant
questions that can be used to query the memory-relevant vector database.
Conversations are then
fed back into the memory
function to create relevant
Semantic memory augmentation new memories.
Augmented prompt
user:
What movie should I LLM Assistant:
User:
What movie should watch? You should watch
What movie
I watch? Semantics: this movie on time
should I watch?
The user has recently travel.
watched these time
travel movies.
Response sent
SemanticAugmentation back to user
function extracts details
specific to memory form. The user has recently
watched these time
travel movies.
LLM
Vector DB
The semantic
augmentation What type of movies Embedding
converts the input does the user like?
into questions Questions are converted
Give me a summary
relevant to the of movies the user to embedding and then
particular form of has watched. used to query database.
memory.
Figure 8.17 How semantic memory augmentation works

--- Page 229 ---
8.6 Implementing memory in agentic systems 205
The benefit of using semantic augmentation is the increased ability to extract more
relevant memories. We can see this in operation by jumping back into Nexus and cre-
ating a new semantic memory store.
Figure 8.18 shows how to configure a new memory store using semantic memory.
As of yet, you can’t configure the specific function prompts for memory, augmenta-
tion, and summarization. However, it can be useful to read through each of the func-
tion prompts to gain a sense of how they work.
Be sure to create a new Select the
memory storefirst. Configuration tab.
Select SEMANTIC as the type of memory.
Memory function for adding new memories
Augmentation function is called to extract
relevance before querying a memory store.
Summarization function is used in memory
compression.
Figure 8.18 Configuration for changing the memory store type to semantic

--- Page 230 ---
206 CHAPTER 8 Understanding agent memory and knowledge
Now, if you go back and add facts and preferences, they will convert to the semantics
of the relevant memory type. Figure 8.19 shows an example of memories being popu-
lated for the same set of statements into two different forms of memory. Generally, the
statements entered into memory would be more specific to the form of memory.
Figure 8.19 Comparing memories for the same information given two different memory types
Memory and knowledge can significantly assist an agent with various application types.
Indeed, a single memory/knowledge store could feed one or multiple agents, allowing

--- Page 231 ---
8.7 Understanding memory and knowledge compression 207
for further specialized interpretations of both types of stores. We’ll finish out the
chapter by discussing memory/knowledge compression next.
8.7 Understanding memory and knowledge compression
Much like our own memory, memory stores can become cluttered with redundant
information and numerous unrelated details over time. Internally, our minds deal
with memory clutter by compressing or summarizing memories. Our minds remem-
ber more significant details over less important ones, and memories accessed more
frequently.
We can apply similar principles of memory compression to agent memory and
other retrieval systems to extract significant details. The principle of compression is
similar to semantic augmentation but adds another layer to the preclusters groups of
related memories that can collectively be summarized.
Figure 8.20 shows the process of memory/knowledge compression. Memories or
knowledge are first clustered using an algorithm such as k-means. Then, the groups of
memories are passed through a compression function, which summarizes and collects
the items into more succinct representations.
Memory/Knowledge Comparison
The user likes time Compression function
travel movies. Clustering summarizes items Embedding Vector DB The user enjoys
by group and time travel movies
The speaker enjoys function into a new and has seen
time travel movies. list of memories and the followingfilms:
knowledge
likes time travel Items are clustered Compressed items are
stories using reduced dimensional stored as embeddings.
embeddings andk-means.
Memories and
knowledge can be
redundant, repetitive,
and include duplicate
information and
potentially misaligned
information.
Figure 8.20 The process of memory and knowledge compression
Nexus provides for both knowledge and memory store compression using k-means
optimal clustering. Figure 8.21 shows the compression interface for memory. Within
the compression interface, you’ll see the items displayed in 3D and clustered. The size
(number of items) of the clusters is shown in the left table.
Compressing memories and even knowledge is generally recommended if the
number of items in a cluster is large or unbalanced. Each use case for compression
may vary depending on the use and application of memories. Generally, though, if an

--- Page 232 ---
208 CHAPTER 8 Understanding agent memory and knowledge
Compression requires an agent
The optimal number of
engine; GPT-4 or higher LLMs
k-means clusters are shown.
are preferred for compression.
Click the Compress button to Number of items are
start compression. The process of shown per cluster.
compression may take several minutes
depending on the size of the store.
Figure 8.21 The interface for compressing memories
inspection of the items in a store contains repetitive or duplicate information, it’s a
good time for compression. The following is a summary of use cases for applications
that would benefit from compression.
THE CASE FOR KNOWLEDGE COMPRESSION
Knowledge retrieval and augmentation have also been shown to benefit significantly
from compression. Results will vary by use case, but generally, the more verbose the
source of knowledge, the more it will benefit from compression. Documents that
feature literary prose, such as stories and novels, will benefit more than, say, a base
of code. However, if the code is likewise very repetitive, compression could also be
shown to be beneficial.
THE CASE FOR HOW OFTEN YOU APPLY COMPRESSION
Memory will often benefit from the periodic compression application, whereas knowl-
edge stores typically only help on the first load. How frequently you apply compres-
sion will greatly depend on the memory use, frequency, and quantity.
THE CASE FOR APPLYING COMPRESSION MORE THAN ONCE
Multiple passes of compression at the same time has been shown to improve retrieval
performance. Other patterns have also suggested using memory or knowledge at vari-
ous levels of compression. For example, a knowledge store is compressed two times,
resulting in three different levels of knowledge.

--- Page 233 ---
8.8 Exercises 209
THE CASE FOR BLENDING KNOWLEDGE AND MEMORY COMPRESSION
If a system is specialized to a particular source of knowledge and that system also
employs memories, there may be further optimization to consolidate stores. Another
approach is to populate memory with the starting knowledge of a document directly.
THE CASE FOR MULTIPLE MEMORY OR KNOWLEDGE STORES
In more advanced systems, we’ll look at agents employing multiple memory and knowl-
edge stores relevant to their workflow. For example, an agent could employ individual
memory stores as part of its conversations with individual users, perhaps including the
ability to share different groups of memory with different groups of individuals. Mem-
ory and knowledge retrieval are cornerstones of agentic systems, and we can now sum-
marize what we covered and review some learning exercises in the next section.
8.8 Exercises
Use the following exercises to improve your knowledge of the material:
 Exercise 1—Load and Split a Different Document (Intermediate)
Objective—Understand the effect of document splitting on retrieval efficiency by
using LangChain.
Tasks:
– Select a different document (e.g., a news article, a scientific paper, or a short
story).
– Use LangChain to load and split the document into chunks.
– Analyze how the document is split into chunks and how it affects the retrieval
process.
 Exercise 2—Experiment with Semantic Search (Intermediate)
Objective—Compare the effectiveness of various vectorization techniques by per-
forming semantic searches.
Tasks:
– Choose a set of documents for semantic search.
– Use a vectorization method such as Word2Vec or BERT embeddings instead
of TF–IDF.
– Perform the semantic search, and compare the results with those obtained
using TF–IDF to understand the differences and effectiveness.
 Exercise 3—Implement a Custom RAG Workflow (Advanced)
Objective—Apply theoretical knowledge of RAG in a practical context using
LangChain.
Tasks:
– Choose a specific application (e.g., customer service inquiries or academic
research queries).
– Design and implement a custom RAG workflow using LangChain.
– Tailor the workflow to suit the chosen application, and test its effectiveness.

--- Page 234 ---
210 CHAPTER 8 Understanding agent memory and knowledge
 Exercise 4—Build a Knowledge Store and Experiment with Splitting Patterns
(Intermediate)
Objective—Understand how different splitting patterns and compression affect
knowledge retrieval.
Tasks:
– Build a knowledge store, and populate it with a couple of documents.
– Experiment with different forms of splitting/chunking patterns, and analyze
their effect on retrieval.
– Compress the knowledge store, and observe the effects on query performance.
 Exercise 5—Build and Test Various Memory Stores (Advanced)
Objective—Understand the uniqueness and use cases of different memory store
types.
Tasks:
– Build various forms of memory stores (conversational, semantic, episodic,
and procedural).
– Interact with an agent using each type of memory store, and observe the dif-
ferences.
– Compress the memory store, and analyze the effect on memory retrieval.
Summary
 Memory in AI applications differentiates between unstructured and structured
memory, highlighting their use in contextualizing prompts for more relevant
interactions.
 Retrieval augmented generation (RAG) is a mechanism for enhancing prompts
with context from external documents, using vector embeddings and similarity
search to retrieve relevant content.
 Semantic search with document indexing converts documents into semantic
vectors using TF–IDF and cosine similarity, enhancing the capability to perform
semantic searches across indexed documents.
 Vector databases and similarity search stores document vectors in a vector data-
base, facilitating efficient similarity searches and improving retrieval accuracy.
 Document embeddings capture semantic meanings, using models such as
OpenAI’s models to generate embeddings that preserve a document’s context
and facilitate semantic similarity searches.
 LangChain provides several tools for performing RAG, and it abstracts the
retrieval process, allowing for easy implementation of RAG and memory sys-
tems across various data sources and vector stores.
 Short-term and long-term memory in LangChain implements conversational
memory within LangChain, distinguishing between short-term buffering pat-
terns and long-term storage solutions.

--- Page 235 ---
Summary 211
 Storing document vectors in databases for efficient similarity searches is crucial
for implementing scalable retrieval systems in AI applications.
 Agent knowledge directly relates to the general RAG pattern of performing
question and answer on documents or other textual information.
 Agent memory is a pattern related to RAG that captures the agentic interac-
tions with users, itself, and other systems.
 Nexus is a platform that implements agentic knowledge and memory systems,
including setting up knowledge stores for document retrieval and memory
stores for various forms of memory.
 Semantic memory augmentation (semantic memory) differentiates between vari-
ous types of memories (semantic, episodic, procedural). It implements them
through semantic augmentation, enhancing agents’ ability to recall and use
information relevantly specific to the nature of the memories.
 Memory and knowledge compression are techniques for condensing informa-
tion stored in memory and knowledge systems, improving retrieval efficiency
and relevancy through clustering and summarization.

--- Page 236 ---
Mastering agent prompts
with prompt flow
This chapter covers
 Understanding systematic prompt engineering
and setting up your first prompt flow
 Crafting an effective profile/persona prompt
 Evaluating profiles: Rubrics and grounding
 Grounding evaluation of a large language model
profile
 Comparing prompts: Getting the perfect profile
In this chapter, we delve into the Test Changes Systematically prompt engineering
strategy. If you recall, we covered the grand strategies of the OpenAI prompt engi-
neering framework in chapter 2. These strategies are instrumental in helping us
build better prompts and, consequently, better agent profiles and personas. Under-
standing this role is key to our prompt engineering journey.
Test Changes Systematically is such a core facet of prompt engineering that Mic-
rosoft developed a tool around this strategy called prompt flow, described later in
this chapter. Before getting to prompt flow, we need to understand why we need
systemic prompt engineering.
212

=== Chapter_11_Planning ===


--- Page 298 ---
274 CHAPTER 11 Agent planning and feedback
make the model appear more intelligent and capable. Therefore, in the next exercise,
we’ll look at an example to set a baseline and differentiate between an LLM that can’t
plan and an agent that can.
For the next exercise, we’ll use Nexus to demonstrate how raw LLMs can’t plan
independently. If you need assistance installing, setting up, and running Nexus, refer
to chapter 7. After you have Nexus installed and ready, we can begin running it with
the Gradio interface, using the commands shown next.
Listing11.1 Running Nexus with the Gradio interface
nexus run gradio
Gradio is an excellent web interface tool built to demonstrate Python machine learn-
ing projects. Figure 11.2 shows the Gradio Nexus interface and the process for creat-
ing an agent and using an agent engine (OpenAI, Azure, and Groq) of your choice.
You can’t use LM Studio unless the model/server supports tool/action use. Anthropic’s
Claude supports internal planning, so for the purposes of this exercise, avoid using
this model.
1. Select to create a new agent.
When you start conversing
2. Name your agent.
with your agent, you will need
to create a new thread or use
3. Don’t worry about a system an existing thread.
prompt or instructions.
4. Select an engine. Note that each engine needs to
be configured correctly to show in the list.
5. Keep the default engine settings, model,
temperature,top_p, and max tokens.
6. Don’t worry about retrieval or
advanced options for now.
7. Click Add Agent when your agent
configuration is complete.
Figure 11.2 Creating a new agent in Nexus

--- Page 299 ---
11.1 Planning: The essential tool for all agents/assistants 275
After creating the agent, we want to give it specific actions (tools) to undertake or
complete a goal. Generally, providing only the actions an agent needs to complete its
goal is best for a few reasons:
 More actions can confuse an agent into deciding which to use or even how to
solve a goal.
 APIs have limits on the number of tools that can be submitted; at the time of
writing, hitting this limit is relatively easy.
 Agents may use your actions in ways you didn’t intend unless that’s your goal.
Be warned, however, that actions can have consequences.
 Safety and security need to be considered. LLMs aren’t going to take over the
world, but they make mistakes and quickly get off track. Remember, these
agents will operate independently and may perform any action.
WARNING While writing this book and working with and building agents over
many hours, I have encountered several instances of agents going rogue with
actions, from downloading files to writing and executing code when not
intended, continually iterating from tool to tool, and even deleting files they
shouldn’t have. Watching an agent emerge new behaviors using actions can
be fun, but things can quickly go astray.
For this exercise, we’ll define the goal described in the following listing.
Listing11.2 Demonstrating planning: The goal
Search Wikipedia for pages on {topic} and download each page and save it
to a file called Wikipedia_{topic}.txt
This goal will demonstrate the following actions:
 search_wikipedia(topic)—Searches Wikipedia and returns page IDs for the
given search term.
 get_wikipedia_page(page_id)—Downloads the page content given the page ID.
 save_file—Saves the content to a file.
Set the actions on the agent, as shown in figure 11.3. You’ll also want to make sure the
Planner is set to None. We’ll look at setting up and using planners soon. You don’t
have to click Save; the interface automatically saves an agent’s changes.
After you choose the actions and planner, enter the goal in listing 11.2. Then click
Create New Thread to instantiate a new conversation. Substitute the topic you want to
search for in the chat input, and wait for the agent to respond. Here’s an example of
the goal filled with the topic, but again, use any topic you like:
Search Wikipedia for pages on Calgary and download each page and save it to
a file called Wikipedia_Calgary.txt.

--- Page 300 ---
276 CHAPTER 11 Agent planning and feedback
Select only the three actions: Make sure to select
search_wikipedia, None for the Planner.
get_wikipedia_page, and
save_file
Figure 11.3 Selecting the actions for the agent and disabling the planner
Figure 11.4 shows the results of submitting the goal to the plain agent. We see the
agent executed the tool/action to search for the topic but couldn’t execute any
steps beyond that. If you recall from our discussion and code example of actions in
chapter 5, OpenAI, Groq, and Azure OpenAI all support parallel actions but not
sequential or planned actions.
The LLM can answer reasonably well if you submit a goal with several parallel
tasks/actions. However, if the actions are sequential, requiring one step to be depen-
dent on another, it will fail. Remember, parallel actions are standalone actions that
can be run alongside others.

--- Page 301 ---
11.2 Understanding the sequential planning process 277
Figure 11.4 The results from trying to get the agent/LLM to complete the goal
Anthropic’s Claude and OpenAI Assistants support sequential action planning. This
means both models can be called with sequential plans, and the model will execute them
and return the results. In the next section, we’ll explore sequential planning and then
demonstrate it in action.
11.2 Understanding the sequential planning process
In the next exercise, we’ll ask an OpenAI assistant to solve the same goal. If you have
Anthropic/Claude credentials and have the engine configured, you can also try this
exercise with that model.
Figure 11.5 shows the difference between executing tasks sequentially (planning)
and using iteration. If you’ve used GPTs, assistants, or Claude Sonnet 3.5, you’ve likely
already experienced this difference. These advanced tools already incorporate plan-
ning by prompt annotations, advanced training, or combining both.
As LLM and chat services evolve, most models will likely natively support some
form of planning and tool use. However, most models, including GPT-4o, only sup-
port action/tool use today.
Let’s open the GPT Assistants Playground to demonstrate sequential planning in
action. If you need help, refer to the setup guide in chapter 6. We’ll use the same goal
but, this time, run it against an assistant (which has built-in planning).

--- Page 302 ---
278 CHAPTER 11 Agent planning and feedback
Iterative execution of a goal Sequential execution of a goal
Single prompt as a goal: Single prompt as a goal:
User submits a goal.
search Wikipedia for topic, return search Wikipedia for topic, return
the top page, and save to afile. the top page, and save to afile.
Iterative Sequential
execution (planned)
search_wikipedia(topic) Tasks/plan
is default execution is
Returns a list of page IDs behavior standard in
for an LLM. GPT search_wikipedia(topic)
Results are displayed, and the Assistants
agent asks to continue to the and Claude. All tasks are
next step. Returns a list of page IDs performed
internally by
User responds
with continue. the agent.
get_wikipedia_page(page_id)
get_wikipedia_page(page_id)
Returns the page content Returns the page content
Returns are collected and In a planner, this
displayed to the user.The agent Collects pages aggregation is
asks for further continuation. performed
All pages combined internally.
All pages combined User responds
with continue.
save_file
save_file
Goal is complete, and user has the output.
Figure 11.5 The difference between iterative and planned execution
After you launch the Playground, create a new assistant, and assign it the search_
wikipedia, get_wikipedia_page, and save_file actions. Figure 11.6 shows the results
of entering the goal to the assistant. As you can see, the assistant completed all the
tasks behind the scenes and responded with the user’s final requested output, achiev-
ing the goal.
To demonstrate the effectiveness of the OpenAI Assistant’s planner, we added
another task, summarizing each page, to the goal. The inserted task didn’t have a
function/tool, but the assistant was savvy enough to use its ability to summarize the
content. You can see the output of what the assistant produced by opening the [root
folder]assistants_working_folder/Wikipedia_{topic}.txt file and reviewing the
contents. Now that we understand how LLMs function without planners and plan-
ning, we can move on to creating our planners in the next section.
11.3 Building a sequential planner
LLM tools such as LangChain and Semantic Kernel (SK) have many planners using
various strategies. However, writing our planner is relatively easy, and Nexus also sup-
ports a plugin-style interface allowing you to add other planners from tools such as
LangChain and SK, or your derivatives.

--- Page 303 ---
11.3 Building a sequential planner 279
Click the Logs tab as the assistant is
running to see it work through the actions.
This is a single response from
the assistant, which also
included summarization of
the content and confirmation
of thefile save.
No instructions are needed, but Nexus and Playground have In this example, the goal was extended
be sure to select the actions: a feature that confirms the to ask the assistant to summarize the
search_wikipedia, file indeed was saved. contentfirst before saving it to afile.
get_wikipedia_page, and
save_file
Figure 11.6 The assistant processing the goal and outputting the results
Planners may sound complicated, but they are easily implemented through prompt
engineering strategies that incorporate planning and reasoning. In chapter 10, we
covered the basics of reasoning and deriving plans, and now we can put those skills to
good use.
Listing 11.3 shows a sequential planner derived from the SK, which is extended to
incorporate iteration. Prompt annotation planners like those shown in the listing can
be adapted to fit specific needs or be more general like those shown. This planner
uses JSON, but planners could use any format an LLM understands, including code.

--- Page 304 ---
280 CHAPTER 11 Agent planning and feedback
Listing11.3 basic_nexus_planner.py
The preamble instructions telling the
agent how to process the examples
You are a planner for Nexus.
Your job is to create a properly formatted JSON plan step by step, to
satisfy the goal given.
Create a list of subtasks based off the [GOAL] provided.
Each subtask must be from within the [AVAILABLE FUNCTIONS] list. Do not
use any functions that are not in the list.
Base your decisions on which functions to use from the description and the
name of the function.
Sometimes, a function may take arguments. Provide them if necessary.
The plan should be as short as possible.
You will also be given a list of corrective, suggestive and epistemic
feedback from previous plans to help you make your decision.
For example:
[SPECIAL FUNCTIONS]
Beginning of the
for-each- prefix
three (few-shot)
description: execute a function for each item in a list examples
args:
- function: the function to execute
- list: the list of items to iterate over
- index: the arg name for the current item in the list
[AVAILABLE FUNCTIONS]
GetJokeTopics
description: Get a list ([str]) of joke topics
EmailTo
description: email the input text to a recipient
args:
- text: the text to email
- recipient: the recipient's email address. Multiple addresses may be
included if separated by ';'.
Summarize
description: summarize input text
args:
- text: the text to summarize
Joke
description: Generate a funny joke
args:
- topic: the topic to generate a joke about
[GOAL]
"Get a list of joke topics and generate a different joke for each topic.
Email the jokes to a friend."
[OUTPUT]
{
"subtasks": [
{"function": "GetJokeTopics"},

--- Page 305 ---
11.3 Building a sequential planner 281
{"function": "for-each",
"args": {
"list": "output_GetJokeTopics",
"index": "topic",
"function":
{
"function": "Joke",
"args": {"topic": "topic"}}}},
{
"function": "EmailTo",
"args": {
"text": "for-each_output_GetJokeTopics"
ecipient": "friend"}}
]
}
# 2 more examples are given but omitted from this listing
[SPECIAL FUNCTIONS]
Adds the for-each
for-each
special iterative
description: execute a function for each item in a list function
args:
- function: the function to execute
Available functions are
- iterator: the list of items to iterate over
autopopulated from the
- index: the arg name for the current item in the list
agent’s list of available
functions.
[AVAILABLE FUNCTIONS]
{{$available_functions}}
[GOAL]
{{$goal}} The goal is inserted here.
Be sure to only use functions from the list of available functions.
The plan should be as short as possible.
And only return the plan in JSON format.
[OUTPUT]
Where the agent is expected
to place the output
Figure 11.7 shows the process of building and running a planning prompt, from
building to execution to finally returning the results to the user. Planners work by
building a planning prompt, submitting it to an LLM to construct the plan, parsing
and executing the plan locally, returning the results to an LLM to evaluate and sum-
marize, and finally returning the final output back to the user.
It’s essential to notice a few subtle details about the planning process. Typically, the
plan is built in isolation by not adding context history. This is done to focus on the
goal because most planning prompts consume many tokens. Executing the functions
within the executor is usually done in a local environment and may include calling
APIs, executing code, or even running machine learning models.
Listing 11.4 shows the code for the create_plan function from the BasicNexus-
Planner class; tools such as LangChain and SK use similar patterns. The process loads
the agent’s actions as a string. The goal and available functions list are then inserted into
the planner prompt template using the PromptTemplateManager, which is just a wrapper

--- Page 306 ---
282 CHAPTER 11 Agent planning and feedback
Goal
Results of executed goal
“Fetch, summarize, and send”
Send the goal along with
planning prompt.
The planning prompt
adds the list of available
Planning prompt LLM LLM
functions and the goal to
the prompt template.
Chat history Chat history
No history of other
context is sent. Each step of the plan is executed, Results are again sent through
and results are passed through LLM the LLM to summarize the output
along with history. for the user.
LLM The plan Plan executor Assembled results
Use the output and other arguments
to execute the actions/functions.
Execution is typically done
Execute the function to query the
inan environment localto
database for access to anAPI.
the agent.
Figure 11.7 The planning process for creating and executing a plan
for the template-handling code. Template handling is done with simple regex but can
also be more sophisticated using tools such as Jinja2, Handlebars, or Mustache.
Listing11.4 basic_nexus_planner.py (create_plan)
def create_plan(self, nexus, agent, goal: str, prompt: str = PROMPT) -> Plan:
selected_actions = nexus.get_actions(agent.actions)
available_functions_string = "\n\n".join(
format_action(action) for action in selected_actions
)
context = {}
context["goal"] = goal
context["available_functions"] = available_functions_string
The context will be injected into
the planner prompt template.
Loads the agent’s available actions and
formats the result string for the planner

--- Page 307 ---
11.3 Building a sequential planner 283
ptm = PromptTemplateManager()
A simple template
prompt = ptm.render_prompt(prompt, context)
manager, similar in
concept to Jinja2,
plan_text = nexus.execute_prompt(agent, prompt) Handlebars, or
return Plan(prompt=prompt, Mustache
goal=goal,
plan_text=plan_text)
Sends the filled-in
planner prompt to
The results (the plan) are wrapped in a
the LLM
Plan class and returned for execution.
The code to execute the plan, shown in listing 11.5, parses the JSON string and exe-
cutes the functions. When executing the plan, the code detects the particular for-each
function, which iterates through a list and executes each element in a function. The
results of each function execution are added to the context. This context is passed to
each function call and returned as the final output.
Listing11.5 basic_nexus_planner.py (execute_plan)
def execute_plan(self, nexus, agent, plan: Plan) -> str:
context = {}
Iterates through each
plan = plan.generated_plan
subtask in the plan
for task in plan["subtasks"]:
if task["function"] == "for-each":
list_name = task["args"]["list"]
index_name = task["args"]["index"] Handles functions that
inner_task = task["args"]["function"] should be iterated
over and adds full list
list_value = context.get(list_name, []) of results to the
context
for item in list_value:
context[index_name] = item
result = nexus.execute_task(agent, inner_task, context)
context[f"for-each_{list_name}_{item}"] = result
for_each_output = [
➥
context[f"for-each_{list_name}_{item}"]
for item in list_value Removes
] individual
context[f"for-each_{list_name}"] = for_each_output for-each
context
for item in list_value: entries
del context[f"for-each_{list_name}_{item}"]
else:
result = nexus.execute_task(agent,
General task
task,
execution
context)
context[f"output_{task['function']}"] = result
return context
Returns the full context, which includes
the results of each function call

--- Page 308 ---
284 CHAPTER 11 Agent planning and feedback
The returned context from the entire execution is sent in a final call to the LLM,
which summarizes the results and returns a response. If everything goes as planned,
the LLM will respond with a summary of the results. If there is an error or something
is missing, the LLM may try to fix the problem or inform the user of the error.
Let’s now open Nexus again and test a planner in operation. Load up the same
agent you used last time, but select the planner under the Advanced options this time,
as shown in figure 11.8. Then, enter the goal prompt as you did before, and let the
agent take it away.
Goal requiring multiple
steps to complete
Select the basic The agent will execute the tasks and
planner. finish by outputting thefile as well
as suggesting next steps.
Figure 11.8 The results from requesting to complete the goal in Nexus using the basic planner
After a few minutes, the agent returns with the saved file, and in some cases, it may
provide extra information, such as the next steps and what to do with the output. This
is because the agent was given a high-level overview of what it accomplished. Remem-
ber, though, that plan execution is done at the local level, and only context, plan, and
goal were sent to the LLM.

--- Page 309 ---
11.4 Reviewing a stepwise planner: OpenAI Strawberry 285
This means that plan execution can be completed by any process, not necessarily
by the agent. Executing a plan outside the LLM reduces the tokens and tool use the
agent needs to perform. This also means that an LLM doesn’t need to support tools
usage to use a planner.
Internally, when a planner is enabled within Nexus, the agent engine tool is
bypassed. Instead, the planner completes the action execution, and the agent is only
aware of the actions through the passing of the output context. This can be good for
models that support tool use but can’t plan. However, a planner may limit functional-
ity for models that support both tool use and planning, such as Claude.
In general, you’ll want to understand the capabilities of the LLM you’re using. If
you’re unsure of those details, then a little trial and error can also work. Ask the agent to
complete a multistep goal with and without planning enabled, and then see the results.
Planning allows agents to complete multiple sequential tasks to achieve more com-
plex goals. The problem with external or prompt planning is that it bypasses the feed-
back iteration loop, which can help correct problems quickly. Because of this, OpenAI
and others are now directly integrating reasoning and planning at the LLM level, as
we’ll see in the next section.
11.4 Reviewing a stepwise planner: OpenAI Strawberry
The release of the o1-preview model, code named Strawberry, introduced a dra-
matic shift in the type of LLMs becoming available for agentic systems. Strawberry
was not only proclaimed to be more efficient at math, science, and general calcula-
tion tasks but also able to engage in reasoning, planning, evaluation, and feedback
directly in the LLM.
Consider our time travel problem from chapter 10 and shown again in figure 11.9.
If you recall, this problem was difficult to solve using GPT-4 and other similar LLMs.
However, with the application of reasoning and feedback, we were able to produce
output that was occasionally correct.
As an experiment, enter this problem into ChatGPT using the o1-preview model,
as shown in listing 11.6. Sit back for a few seconds and wait for the answer. Yep, the
model still gets it wrong.
Listing11.6 Time travel reasoning/planning problem
In a sci-fi film, Alex is a time traveler who decides to go back in time
to witness a famous historical battle that took place 100 years ago,
which lasted for 10 days. He arrives three days before the battle starts.
However, after spending six days in the past, he jumps forward in time
by 50 years and stays there for 20 days. Then, he travels back to
witness the end of the battle. How many days does Alex spend in the past
before he sees the end of the battle?
While it may be somewhat disappointing to see the model get the wrong answer, it
does, however, do a far better job of breaking down the problem and demonstrating

--- Page 310 ---
286 CHAPTER 11 Agent planning and feedback
The problem statement:
In a sci-fi film, Alex is a time traveler who decides to go back in
time to witness a famous historical battle that took place 100 years ago,
which lasted for 10 days. He arrives three days before the battle starts.
However, after spending six days in the past, he jumps forward in time by
50 years and stays there for 20 days. Then, he travels back to witness the
end of the battle. How many days does Alex spend in the past before he
sees the end of the battle?
Jumps back in time 100 years (3 days before the battle)
spends 6 days
jumps forward in time 50 years
20 days
The statement is vague as
jumps back to witness end of battle
to what time Alex returns
to the battle. Is it the same ??? jumps back to the present
time he left?
battle lasts 10 days Alex
Timeline
Alex Historic Alex Alex Historic Alex Alex Present
arrives battle starts leaves returns? battle ends arrives leaves
Figure 11.9 The time travel problem, revisited
its answer. Listing 11.7 shows the sample output from posing the problem in listing
11.6 to the Strawberry model. Note, you may get a different answer because of the sto-
chastic nature of the LLM.
Listing11.7 o1-preview response to time travel problem
To determine how many days Alex spends in the past before witnessing the
end of the battle, let's reconstruct the timeline step by step:
Arrival in the Past:
Alex arrives 3 days before the battle begins.
He spends these 3 days waiting for the battle to start.
During the Battle:
The battle starts, and Alex experiences the first 3 days of it.
At this point, he has spent a total of 6 days in the past (3 days before
the battle and 3 days during the battle).
Time Jump Forward:
It becomes obvious
After these 6 days, Alex jumps 50 years forward in time.
where the model is
He spends 20 days in this future time. making the error.
Return to the Past:
Alex then returns to the past to witness the end of the battle.
Since the battle lasts 10 days and he left after day 3 of the battle,
there are 7 days remaining in the battle.
However, because he was away for 20 days, which is longer than the
remaining 7 days of the battle, he must return to a point in time before
the battle ends to witness its conclusion.
To see the end of the battle, he returns to the past on the last day of

--- Page 311 ---
11.4 Reviewing a stepwise planner: OpenAI Strawberry 287
the battle.
Final Days Spent Before the Battle Ends:
Upon returning, he spends 1 more day in the past to witness the battle's
end.
Total Days Spent in the Past Before Seeing the End:
6 days before jumping forward in time.
1 day after returning to the past.
Total: 6 + 1 = 7 days.
Answer: 7
Because we know the right answer is 27, we know the LLM is wrong, but if we didn’t,
we could just as easily assume that the work and reasoning were all correct. Problems
like this can happen when we remove feedback in LLM interactions and agentic sys-
tems. Feedback can guide the model to correct itself.
However, what if we didn’t know the correct answer was 27 (26, if you assume he
doesn’t spend the day to witness the battle) and assumed the LLM or agent was cor-
rect? Well, this is a problem we can rectify with a couple of simple prompts that can
engage the LLM in reasoning and planning feedback. However, these techniques are
more effective with LLMs or wrappers such as the OpenAI Assistants, which provide
reasoning and planning within the model.
What we want to do is provide feedback to the LLM, but understanding what that
feedback is will likely be difficult for us. Fortunately, we can elicit feedback directly
from the LLM, provided we give the correct answer. Listing 11.8 shows how to gener-
ate constructive feedback from the LLM concerning our time travel problem.
Listing11.8 Generating feedback
the correct answer is 27, please review what you did wrong and suggest
feedback you could give yourself when trying to solve similar future problems
Entering this after the model answers the question wrong will generate feedback that
you can use to guide the model through prompting or as part of system instructions.
Listing 11.9 shows an example of the feedback provided by o1-preview. You can then
extract this feedback and augment the instructions the next time you want to tackle
complex time travel problems.
Listing11.9 Generated feedback
Feedback for Future Problems
Understanding Time Frames in Time Travel:
Relative Time Frames: Always consider the time periods relative to the
original point of reference. In this problem, even though Alex jumps
forward 50 years, he is still in the past relative to his original
present time.
Including All Relevant Periods:
Ensure that all time periods spent in the past (or future) are included
in the total calculation, even if they involve moving to different
points in time.
Time Continuity:

--- Page 312 ---
288 CHAPTER 11 Agent planning and feedback
Remember that while the traveler moves through time, events in other
time periods continue to progress unless specified otherwise.
Application:
Careful Reading:
Pay close attention to the details provided, such as the durations and
the sequences of time jumps.
Visualization:
It may help to draw a timeline to visualize the sequence of events and
time periods involved.
Double-Checking Calculations:
After solving, revisit each step to ensure all time periods are
accounted for correctly.
This feedback technique will consistently work on models such as o1-preview, but
other models may still struggle to answer correctly, even given this feedback. Over
time, as models become smarter, this technique will likely generally work on most
models. However, this feedback mechanism will likely be essential even as models
get progressively brighter. because language is nuanced, and not every problem we
challenge LLMs with may have an obvious absolute answer. Take our example prob-
lem, for instance. This problem is an excellent example of requiring the problem
solver to make assumptions and draw correlations from the question. There are still
plenty of areas in science, from geology to behavioral science, where answering the
same problem may yield a range of answers. Let’s look next at a few techniques for
how the application of reasoning, planning, evaluation, and feedback can be
applied to agentic systems.
11.5 Applying planning, reasoning, evaluation, and
feedback to assistant and agentic systems
In recent chapters, we’ve examined how the agentic components of planning, reason-
ing, feedback, and evaluation can be implemented. Now we look at how, when, and
where those components can be integrated into assistant and agentic systems for real-
time production, research, or development.
While not all of these components may fit the same into every application, it’s use-
ful to understand where and when to apply which component. In the next section, we
look at how planning can be integrated into assistant/agentic systems.
11.5.1 Application of assistant/agentic planning
Planning is the component where an assistant or agent can plan to undertake a set of
tasks, whether they are in series, parallel, or some other combination. We typically
associate planning with tool use, and, rightfully, any system using tools will likely want
a capable planner. However, not all systems are created equally, so in table 11.1, we’ll
review where, when, and how to implement planners.

--- Page 314 ---
290 CHAPTER 11 Agent planning and feedback
 Game AI—While applying LLMs to games is still in early stages, it isn’t hard to
imagine in-game agents or assistants that can assist or challenge the player. Giv-
ing these agents the ability to plan and execute complex workflows could dis-
rupt how and with whom we play games.
 Research—Similar to collaborative workflows, these agents will be responsible
for deriving new ideas from existing sources of information. Finding that infor-
mation will likely be facilitated through extensive tool use, which will benefit
from coordination of planning.
As you can see, planning is an essential part of many LLM applications, whether
through coordination of tool use or otherwise. In the next section, we look at the next
component of reasoning and how it can be applied to the same application stack.
11.5.2 Application of assistant/agentic reasoning
Reasoning, while often strongly associated with planning and task completion, is a
component that can also stand by itself. As LLMs mature and get smarter, reasoning is
often included within the LLM itself. However, not all applications may benefit from
extensive reasoning, as it often introduces a thinking cycle within the LLM response.
Table 11.2 describes at a high level how the reasoning component can be integrated
with various LLM application types.
Table 11.2 When and where reasoning is employed and used in various applications
Application Implemented Environment Purpose Timing Configuration
Personal Within the LLM Personal Breaking down During the As part of the
assistant device work into steps response prompt or LLM
Customer Not typical; Limited tool
service bot usually just use and need
informational for composite
tool use
Autono- As part of the Server or Facilitate As part of Within the
mous agent prompt service complex tool use LLM, external agent or LLM
agent and within and task planning reasoning not
the LLM well suited
Collabora- As part of the Shared can- Assists in break- During the Within the
tive work- LLM vas or coding ing work down response LLM
flows
Game AI As part of Server or Essential for Before or Within the
the LLM application undertaking com- during the LLM
plex actions response
Research Anywhere Server Understand how to Before, during, Anywhere
solve complex and after
problems and response
engage in complex generation
task workflows

--- Page 315 ---
11.5 Applying planning, reasoning, evaluation, and feedback to assistant and agentic sys- 291
Table 11.2 shows several varied application scenarios in which we may find an assis-
tant or agent deployed to assist in some capacity. To provide further information
and guidance, this list provides more details about how reasoning may be employed
in each application:
 Personal assistant—Depending on the application, the amount of reasoning an
agent employs may be limited. Reasoning is a process that requires the LLM to
think through a problem, and this often requires longer response times depend-
ing on the complexity of the problem and the extent of the prompt. In many
situations, responses intended to be closer to real-time reasoning may be dis-
abled or turned down. While this may limit the complexity at which an agent
can interact, limited or no reasoning can improve response times and increase
user enjoyment.
 Customer service bot—Again, because of the controlled nature of this environ-
ment, it’s unlikely that assistants engaged directly with customers will need to
perform complex or any form of reasoning.
 Autonomous agent—While reasoning is a strong component of autonomous
agents, we still don’t know how much reasoning is too much. As models such as
Strawberry become available for agentic workflows, we can gauge at what
point extensive reasoning may not be needed. This will surely be the case for
well-defined autonomous agent workflows.
 Collaborative workflows—Again, applying reasoning creates an overhead in the LLM
interaction. Extensive reasoning may provide benefits for some workflows, while
other well-defined workflows may suffer. This may mean that these types of work-
flows will benefit from multiple agents—those with reasoning and those without.
 Game AI—Similar to other applications, heavy-reasoning applications may not
be appropriate for most game AIs. Games will especially require LLM response
times to be quick, and this will surely be the application of reasoning for gen-
eral tactical agents. Of course, that doesn’t preclude the use of other reasoning
agents that may provide more strategic control.
 Research—Reasoning will likely be essential to any complex research task for sev-
eral reasons. A good example is the application of the Strawberry model, which
we’ve already seen in research done in mathematics and the sciences.
While we often consider reasoning in tandem with planning, there may be conditions
where the level at which each is implemented may differ. In the next section we con-
sider the agent pillar of evaluation of various applications.
11.5.3 Application of evaluation to agentic systems
Evaluation is the component of agentic/assistant systems that can guide how well the
system performs. While we demonstrated incorporating evaluation in some agentic
workflows, evaluation is often an external component in agentic systems. However, it’s
also a core component of most LLM applications and not something that should be

--- Page 316 ---
292 CHAPTER 11 Agent planning and feedback
overlooked in most developments. Table 11.3 describes at a high level how the evalua-
tion component can be integrated with various LLM application types.
Table 11.3 When and where evaluation is employed and used in various applications
Application Implemented Environment Purpose Timing Configuration
Personal External Server Determine how After the Often devel-
assistant well the system interaction oped externally
is working
Customer External Server Evaluate the suc- After the External to the
service bot monitor cess of each interaction agent system
interaction
Autonomous External or Server or Determine the After the External or
agent internal service success of the interaction internal
system after
or during task
completion
Collaborative External Shared can- Evaluate the After the External service
workflows vas or coding success of the interaction
collaboration
Game AI External or Server or Evaluate the After the External or
internal application agent or evalu- interaction as part of the
ate the success agent or another
of a strategy or agent
action
Research Combined Server and Evaluate the After the Depends on the
manual and human output of the generated complexity of
LLM research output the problem
developed and research
undertaken
Table 11.3 shows several varied application scenarios in which we may find an assis-
tant or agent deployed to assist in some capacity. To provide further information
and guidance, this list provides more details about how evaluation may be employed
in each application:
 Personal assistant—In most cases, an evaluation component will be used to process
and guide the performance of agent responses. In systems primarily employing
retrieval augmented generation (RAG) for document exploration, the evaluation
indicates how well the assistant responds to information requests.
 Customer service bot—Evaluating service bots is critical to understanding how well
the bot responds to customer requests. In many cases, a strong RAG knowledge
element may be an element of the system that will require extensive and ongoing
evaluation. Again, with most evaluation components, this element is external to

--- Page 317 ---
11.5 Applying planning, reasoning, evaluation, and feedback to assistant and agentic sys- 293
the main working system and is often run as part of monitoring general perfor-
mance over several metrics.
 Autonomous agent—In most cases, a manual review of agent output will be a pri-
mary guide to the success of an autonomous agent. However, in some cases,
internal evaluation can help guide the agent when it’s undertaking complex
tasks or as a means of improving the final output. Multiple agent systems, such
as CrewAI and AutoGen, are examples of autonomous agents that use internal
feedback to improve the generated output.
 Collaborative workflows—In most direct cases, manual evaluation is ongoing
within these types of workflows. A user will often immediately and in near
real time correct the assistant/agent by evaluating the output. Additional
agents could be added similarly to autonomous agents for more extensive
collaborative workflows.
 Game AI—Evaluation will often be broken down into development evaluation—
evaluating how the agent interacts with the game—and in-game evaluation, evalu-
ating how well an agent succeeded at a task. Implementing the later evaluation
form is similar to autonomous agents but aims to improve some strategies or
execution. Such in-game evaluations would also likely benefit from memory
and a means of feedback.
 Research—Evaluation at this level generally occurs as a manual effort after com-
pleting the research task. An agent could employ some form of evaluation simi-
lar to autonomous agents to improve the generated output, perhaps even
contemplating internally how evaluation of the output could be extended or
further researched. Because this is currently a new area for agentic develop-
ment, how well this will be executed remains to be seen.
Evaluation is an essential element to any agentic or assistant system, especially if that
system provides real and fundamental information to users. Developing evaluation sys-
tems for agents and assistants is likely something that could or should have its own
book. In the final section of this chapter, we’ll look at feedback implementation for
various LLM applications.
11.5.4 Application of feedback to agentic/assistant applications
Feedback as a component of agentic systems is often, if not always, implemented as
an external component—at least for now. Perhaps confidence in evaluation systems
may improve to the point where feedback is regularly incorporated into such sys-
tems. Table 11.4 showcases how feedback can be implemented into various LLM
applications.

--- Page 318 ---
294 CHAPTER 11 Agent planning and feedback
Table 11.4 When and where feedback is employed and used in various applications
Application Implemented Environment Purpose Timing Configuration
Personal External or Aggregated to Provides means After or during Internal and
assistant by the user the server or of system the interaction external
as part of the improvement
system
Customer External Aggregated to Qualifies and After the External to the
service bot monitor the server provides a means interaction agent system
for system
improvement
Autonomous External Aggregated at Provides a means After the External
agent the server for system interaction
improvement
Collaborative While Shared can- Provides a mecha- During the External
workflows interacting vas or coding nism for immedi- interaction service
ate feedback
Game AI External or Server or As part of internal After or during External or
internal application evaluation feed- the interaction as part of
back provided the agent or
for dynamic another agent
improvement
Research Combined Server and Evaluate the out- After the Depends on
manual and human put of the research generated the complexity
LLM developed output of the problem
and the
research
undertaken
Table 11.4 shows several application scenarios in which we may find an assistant or agent
deployed to assist in some capacity. To provide further information and guidance, this list
provides more details about how feedback may be employed in each application:
 Personal assistant—If the assistant or agent interacts with the user in a chat-style
interface, direct and immediate feedback can be applied by the user. Whether
this feedback is sustained over future conversations or interactions, it usually
develops within agentic memory. Assistants such as ChatGPT now incorporate
memory and can benefit from explicit user feedback.
 Customer service bot—User or system feedback is typically provided through a survey
after the interaction has completed. This usually means that feedback is regulated
to an external system that aggregates the feedback for later improvements.
 Autonomous agent—Much like bots, feedback within autonomous agents is typi-
cally regulated to after the agent has completed a task that a user then reviews.
The feedback mechanism may be harder to capture because many things can

--- Page 319 ---
11.5 Applying planning, reasoning, evaluation, and feedback to assistant and agentic sys- 295
be subjective. Methods explored in this chapter for producing feedback can be
used within prompt engineering improvements.
 Collaborative workflows—Similar to the personal assistant, these types of appli-
cations can benefit from immediate and direct feedback from the user. Again,
how this information is persisted across sessions is often an implementation of
agentic memory.
 Game AI—Feedback can be implemented alongside evaluation through addi-
tional and multiple agents. This feedback form may again be single-use and
exist within the current interaction or may persist as memory. Imagine a game
AI that can evaluate its actions, improve those with feedback, and remember
those improvements. While this pattern isn’t ideal for games, it will certainly
improve the gameplay experience.
 Research—Similar to evaluation in the context of research, feedback is typically
performed offline after the output is evaluated. While some development has
been done using multiple agent systems incorporating agents for evaluation
and feedback, these systems don’t always perform well, at least not with the cur-
rent state-of-the-art models. Instead, it’s often better to isolate feedback and
evaluation at the end to avoid the common feedback looping problem.
Feedback is another powerful component of agentic and assistant systems, but it’s not
always required on the first release. However, incorporating rigorous feedback and
evaluation mechanisms can greatly benefit agentic systems in the long term concern-
ing ongoing monitoring and providing the confidence to improve various aspects of
the system.
How you implement each of these components in your agentic systems may, in
part, be guided by the architecture of your chosen agentic platform. Now that you
understand the nuances of each component, you also have the knowledge to guide
you in selecting the right agent system that fits your application and business use case.
Regardless of your application, you’ll want to employ several agentic components in
almost all cases.
As agentic systems mature and LLMs themselves get smarter, some of the compo-
nents we today consider external may be closely integrated. We’ve already seen rea-
soning and planning be integrated into a model such as Strawberry. Certainly, as we
approach the theoretical artificial general intelligence milestone, we may see models
capable of performing long-term self-evaluation and feedback.
In any case, I hope you enjoyed this journey with me into this incredible frontier of
a new and emerging technology that will certainly alter our perception of work and
how we undertake it through agents.

--- Page 320 ---
296 CHAPTER 11 Agent planning and feedback
11.6 Exercises
Use the following exercises to improve your knowledge of the material:
 Exercise 1—Implement a Simple Planning Agent (Beginner)
Objective—Learn how to implement a basic planning agent using a prompt to
generate a sequence of actions.
Tasks:
– Create an agent that receives a goal, breaks it into steps, and executes those
steps sequentially.
– Define a simple goal, such as retrieving information from Wikipedia and sav-
ing it to a file.
– Implement the agent using a basic planner prompt (refer to the planner
example in section 11.3).
– Run the agent, and evaluate how well it plans and executes each step.
 Exercise 2—Test Feedback Integration in a Planning Agent (Intermediate)
Objective—Understand how feedback mechanisms can improve the performance
of an agentic system.
Tasks:
– Modify the agent from exercise 1 to include a feedback loop after each task.
– Use the feedback to adjust or correct the next task in the sequence.
– Test the agent by giving it a more complex task, such as gathering data from
multiple sources, and observe how the feedback improves its performance.
– Document and compare the agent’s behavior before and after adding feedback.
 Exercise 3—Experiment with Parallel and Sequential Planning (Intermediate)
Objective—Learn the difference between parallel and sequential actions and
how they affect agent behavior.
Tasks:
– Set up two agents using Nexus: one that executes tasks in parallel and another
that performs tasks sequentially.
– Define a multistep goal where some actions depend on the results of previous
actions (sequential), and some can be done simultaneously (parallel).
– Compare the performance and output of both agents, noting any errors or
inefficiencies in parallel execution when sequential steps are required.
 Exercise 4—Build and Integrate a Custom Planner into Nexus (Advanced)
Objective—Learn how to build a custom planner and integrate it into an agent
platform.
Tasks:
– Write a custom planner using prompt engineering strategies from section 11.3,
ensuring it supports sequential task execution.
– Integrate this planner into Nexus, and create an agent that uses it.

--- Page 321 ---
Summary 297
– Test the planner with a complex goal that involves multiple steps and tools
(e.g., data retrieval, processing, and saving).
– Evaluate how the custom planner performs compared to built-in planners in
Nexus or other platforms.
 Exercise 5—Implement Error Handling and Feedback in Sequential Planning
(Advanced)
Objective—Learn how to implement error handling and feedback to refine sequen-
tial planning in an agentic system.
Tasks:
– Using a sequential planner, set up an agent to perform a goal that may encoun-
ter common errors (e.g., a failed API call, missing data, or invalid input).
– Implement error-handling mechanisms in the planner to recognize and
respond to these errors.
– Add feedback loops to adjust the plan or retry actions based on the error
encountered.
– Test the system by deliberately causing errors during execution, and observe
how the agent recovers or adjusts its plan.
Summary
 Planning is central to agents and assistants, allowing them to take a goal, break
it into steps, and execute them. Without planning, agents are reduced to simple
chatbot-like interactions.
 Agents must differentiate between parallel and sequential actions. Many LLMs
can handle parallel actions, but only advanced models support sequential plan-
ning, critical for complex task completion.
 Feedback is crucial in guiding agents to correct their course and improve per-
formance over time. This chapter demonstrates how feedback mechanisms can
be integrated with agents to refine their decision-making processes.
 Platforms such as OpenAI Assistants and Anthropic’s Claude support internal
planning and can execute complex, multistep tasks. Agents using these plat-
forms can use sequential action planning for sophisticated workflows.
 Properly selecting and limiting agent actions is vital to avoid confusion and
unintended behavior. Too many actions may overwhelm an agent, while unnec-
essary tools may be misused.
 Nexus allows for creating and managing agents through a flexible interface,
where users can implement custom planners, set goals, and assign tools. The
chapter includes practical examples using Nexus to highlight the difference
between a raw LLM and a planner-enhanced agent.
 Writing custom planners is straightforward, using prompt engineering strate-
gies. Tools such as LangChain and Semantic Kernel offer a variety of planners
that can be adapted or extended to fit specific agentic needs.

--- Page 322 ---
298 CHAPTER 11 Agent planning and feedback
 Models such as OpenAI Strawberry integrate reasoning, planning, evalua-
tion, and feedback directly into the LLM, offering more accurate problem-
solving capabilities.
 Evaluation helps determine how well an agentic system is performing and can
be implemented internally or externally, depending on the use case.
 As LLMs evolve, reasoning, planning, and feedback mechanisms may become
deeply integrated into models, paving the way for more autonomous and intelli-
gent agent systems.

--- Page 323 ---
appendix A
Accessing OpenAI
large language models
Although several commercial large language model (LLM) services are available,
this book recommends using OpenAI services directly or through Azure OpenAI
Studio. To access either service, you must create an account and register a payment
method not covered in this appendix. The GPT-4 family of LLMs is considered best
in class and better suited for agent development. Using open source and alterna-
tive services is always an option but generally only advisable after you’ve worked
with GPT-4 for some time.
A.1 Accessing OpenAI accounts and keys
The following general steps can help you quickly set up using OpenAI LLMs for agent
development. Though using OpenAI and other commercial LLMs comes at a price,
you can expect to pay less than US$100 to complete all the exercises in this book:
1 Go to https://openai.com and log in, or register for an account and log in. If
this is your first time creating an account, you’ll likely be given free credit in
some amount. If you already have an account, you must register a payment
method and type. It’s generally better to purchase a number of credits at a
time. This will allow you to manage the costs better and avoid overruns.
2 After logging in to the platform, select ChatGPT or the API, as shown in
figure A.1. Choose the API.
299

--- Page 324 ---
300 APPENDIX A Accessing OpenAI large language models
Select the API
.
.
Figure A.1 Selecting the API section of the OpenAI platform
3 Open the left menu, and select the API Keys option, as shown in figure A.2.
Select the APIKeys
Figure A.2 Selecting
the API Keys option

--- Page 325 ---
A.1 Accessing OpenAI accounts and keys 301
4 Click the Create button to create a new key, enter a name for the key, and click
the Create Secret Key button, as shown in figure A.3.
Start by clicking the button Enter a helpful name, Click to create
to create a new secret key. such as GPT-Agents. the key.
Figure A.3 Creating the secret API key
5 Copy and paste the key to a notepad or another area for safekeeping using the
Copy button, as shown in figure A.4. Keep this key secret, and ensure it remains
only on your development machine.
After generating a key, you can continue to use it within an .env configuration file or
through other means of registering an OpenAI key. For most of the packages used in
this book, configuring OpenAI will generally only require the key. Other services,
such as Azure OpenAI, will require the configuration of a model deployment and a
base URL as covered in the next section.

--- Page 326 ---
302 APPENDIX A Accessing OpenAI large language models
Make sure to save the
key right away.
Click the Copy button to copy
the key to the clipboard.
Click to create the key.
Figure A.4 Copying and pasting the key to a well-known safe location
A.2 Azure OpenAI Studio, keys, and deployments
Through its ongoing relationship with OpenAI, Microsoft hosts the same models at
the same price within Azure OpenAI Studio. Occasionally, Azure may be a model ver-
sion behind, but Microsoft generally keeps current with the latest OpenAI models.
These guidelines will be more general because there are several ways to access
Azure and methods of creating accounts and accessing the studio (for specific instruc-
tions, refer to Microsoft documentation):
1 Log in to your Azure portal account subscription.
2 Create a new Azure OpenAI Studio resource in a region that makes sense to
you. At the time of writing, not all regions provided access to all models. You may
need to check which models are available for your region first. This will also be
specific to your account and usage.
Within Azure OpenAI, models are exposed through a resource allocation
called a deployment. Deployments wrap a model, such as GPT-4, and provide
access to the resource. Figure A.5 shows an example of various models being
exposed through deployments.
3 Click the Create New Deployment button to create a new deployment, and then
select the model you want to deploy.

--- Page 327 ---
A.2 Azure OpenAI Studio, keys, and deployments 303
Deployment name is the name OpenAI model Other resource
referenced as the model name. name information
Figure A.5 Deploying a model through an Azure OpenAI Studio deployment
4 After the model is wrapped in a deployment, you must access the parent Azure
OpenAI resource. From there, you can access the key, endpoint, or base URL
needed to configure your connection, as shown in figure A.6.
Again, if you get stuck, the Microsoft documentation can guide you in the right direc-
tion. The three critical differences to remember when connecting to a resource such
as Azure OpenAI Studio or another LLM using the OpenAI tooling are listed here:
 The api key to access the model
 The base url or endpoint where the model is located
 The name of the model or deployment name
If you can’t access a model for whatever reason, a good alternative is open source
models. Setting up and consuming open source LLMs is covered in chapter 2.

--- Page 328 ---
304 APPENDIX A Accessing OpenAI large language models
Other resource
information
Click to copy, and then
paste the keys as needed.
The base URL for
the model service