--- PÃ¡gina 1 ---
GuÃ­a Completa de ImplementaciÃ³n
Sistema Multi-Agente A2A para OptimizaciÃ³n de Protocolos de Enrutamiento
VersiÃ³n: 2.0 (Actualizada Noviembre 2025)
Objetivo: Desplegar una orquestaciÃ³n completa de agentes autÃ³nomos para investigar, simular y optimizar
protocolos de enrutamiento en Smart Cities utilizando hardware local y herramientas Open Source
ğŸ“‹
ÃNDICE
PARTE I: FUNDAMENTOS Y PREPARACIÃ“N
1. VisiÃ³n General del Sistema
2. Requisitos de Hardware y Software
3. Arquitectura del Sistema Multi-Agente
PARTE II: INSTALACIÃ“N Y CONFIGURACIÃ“N
4. Fase 1: Motor de IA Local (Ollama)
5. Fase 2: Entorno de SimulaciÃ³n NS-3
6. Fase 3: Sistema de OrquestaciÃ³n (LangGraph)
7. Fase 4: IntegraciÃ³n NS-3 con IA (ns3-ai)
PARTE III: DESARROLLO DE AGENTES
8. Agente Investigador (Literatura AcadÃ©mica)
9. Agente Programador (GeneraciÃ³n de CÃ³digo NS-3)
10. Agente Ejecutor de Simulaciones
11. Agente Analista de Protocolos
12. Agente de Post-Procesado y VisualizaciÃ³n
13. Sistema de BitÃ¡cora AutomÃ¡tica
PARTE IV: AUTOMATIZACIÃ“N Y OPERACIÃ“N
14. Flujos de Trabajo Automatizados
15. Monitoreo y Debugging
16. OptimizaciÃ³n y Escalabilidad
PARTE I: FUNDAMENTOS Y PREPARACIÃ“N

--- PÃ¡gina 2 ---
1. VISIÃ“N GENERAL DEL SISTEMA
1.1 PropÃ³sito
Este sistema representa un cambio paradigmÃ¡tico en la investigaciÃ³n doctoral: de la simulaciÃ³n manual iterativa
a la automatizaciÃ³n cognitiva. Los agentes A2A (Agent-to-Agent) no solo ejecutan tareas, sino que razonan
sobre el problema, proponen soluciones innovadoras y documentan meticulosamente el proceso cientÃ­fico.
1.2 Capacidades Clave
InvestigaciÃ³n automatizada: BÃºsqueda y sÃ­ntesis de literatura acadÃ©mica
GeneraciÃ³n de cÃ³digo: Scripts NS-3 validados automÃ¡ticamente
SimulaciÃ³n adaptativa: EjecuciÃ³n y correcciÃ³n iterativa de experimentos
AnÃ¡lisis inteligente: Procesamiento de mÃ©tricas y generaciÃ³n de visualizaciones
Reproducibilidad total: BitÃ¡cora automÃ¡tica de cada paso del proceso
1.3 Arquitectura de Alto Nivel
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SUPERVISOR â”‚
â”‚ (Orquestador LangGraph) â”‚
â”‚ - GestiÃ³n de estado global â”‚
â”‚ - Enrutamiento de tareas â”‚
â”‚ - Control de flujo cÃ­clico â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚ â”‚ â”‚ â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”
â”‚ Agente â”‚ â”‚ Agente â”‚ â”‚ Agente â”‚ â”‚Agenteâ”‚ â”‚Bit. â”‚
â”‚Investig.â”‚ â”‚Program. â”‚ â”‚Simul. â”‚ â”‚Anali.â”‚ â”‚ Log â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ â”‚ ESTADO COMPARTIDO â”‚
â”‚ â”‚ - research_notes â”‚
â”‚ â”‚ - code_snippet â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¤ - simulation_logs â”‚
â”‚ - analysis_results â”‚
â”‚ - errors â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2. REQUISITOS DE HARDWARE Y SOFTWARE

--- PÃ¡gina 3 ---
2.1 Requisitos de Hardware
Componente MÃ­nimo Recomendado Ã“ptimo
CPU 4 cores @ 2.5GHz 8 cores @ 3.0GHz 16 cores @ 3.5GHz
RAM 16 GB 32 GB 64 GB
GPU Ninguna (CPU) NVIDIA RTX 3060 (12GB) NVIDIA RTX 4090 (24GB)
Almacenamiento 100 GB SSD 250 GB NVMe SSD 500 GB NVMe SSD
SO Ubuntu 22.04 Ubuntu 24.04 Ubuntu 24.04
Notas importantes:
La GPU acelera la inferencia de LLMs (2-5x mÃ¡s rÃ¡pido) pero NO es obligatoria
NS-3 es CPU-intensivo; mÃ¡s cores = simulaciones paralelas
Las trazas PCAP pueden ocupar varios GB por simulaciÃ³n compleja
2.2 Stack TecnolÃ³gico (Noviembre 2025)
Motor de IA:
Ollama v0.5.2+ (Inferencia local de LLMs)
Modelos recomendados:
qwen2.5-coder:32b - Mejor modelo de cÃ³digo actual (supera a DeepSeek en benchmarks recientes)
deepseek-coder-v2:16b - Alternativa eficiente para hardware limitado
llama3.3:8b - Para razonamiento general y supervisiÃ³n
nomic-embed-text - Para embeddings de documentos
OrquestaciÃ³n:
LangGraph v1.0.3 (Ãšltima versiÃ³n estable con checkpoints mejorados)
LangChain v1.0+ (Para componentes auxiliares)
Simulador:
NS-3 v3.43 o v3.44 (Ãšltima versiÃ³n estable)
Python bindings habilitados
Interfaz IA-Red:
ns3-ai (Preferido por memoria compartida de alta velocidad)
ns3-gym (Alternativa compatible con OpenAI Gym)
Base de Datos y AnÃ¡lisis:

--- PÃ¡gina 4 ---
ChromaDB v0.4+ (Base de datos vectorial local)
Pandas v2.0+ (Procesamiento de datos)
Matplotlib + Seaborn (VisualizaciÃ³n)
2.3 PreparaciÃ³n del Entorno Base
bash
# 1. Actualizar sistema
sudo apt update && sudo apt upgrade -y
# 2. Instalar dependencias esenciales
sudo apt install -y \
g++ python3 python3-dev python3-pip python3-venv \
cmake ninja-build git \
pkg-config sqlite3 libsqlite3-dev \
curl wget tar bzip2
# 3. Instalar dependencias para NS-3
sudo apt install -y \
gir1.2-goocanvas-2.0 python3-gi python3-gi-cairo \
python3-pygraphviz gir1.2-gtk-3.0 \
qtbase5-dev qtchooser qt5-qmake qtbase5-dev-tools \
tcpdump wireshark \
libxml2 libxml2-dev \
libboost-all-dev \
libeigen3-dev gsl-bin libgsl-dev
# 4. Crear directorio de trabajo
mkdir -p ~/tesis-a2a
cd ~/tesis-a2a
PARTE II: INSTALACIÃ“N Y CONFIGURACIÃ“N
4. FASE 1: MOTOR DE IA LOCAL (OLLAMA)
4.1 InstalaciÃ³n de Ollama
bash

--- PÃ¡gina 5 ---
# InstalaciÃ³n en Linux/Mac
curl -fsSL https://ollama.com/install.sh | sh
# Verificar instalaciÃ³n
ollama --version
# Iniciar servidor (se ejecuta automÃ¡ticamente como servicio)
# Para verificar que estÃ¡ corriendo:
curl http://localhost:11434/api/tags
4.2 Descarga de Modelos Especializados
IMPORTANTE: Descarga solo los modelos que tu hardware pueda manejar:
bash
# Para hardware limitado (16GB RAM):
ollama pull qwen2.5-coder:7b # Mejor modelo pequeÃ±o de cÃ³digo
ollama pull llama3.3:8b # Razonamiento general
ollama pull nomic-embed-text # Embeddings (esencial)
# Para hardware medio (32GB RAM):
ollama pull qwen2.5-coder:32b # Estado del arte en cÃ³digo
ollama pull deepseek-coder-v2:16b # Alternativa eficiente
ollama pull llama3.3:8b
ollama pull nomic-embed-text
# Para hardware potente (64GB RAM + GPU):
ollama pull qwen2.5-coder:32b
ollama pull deepseek-coder-v2:236b # MÃ¡ximo rendimiento
ollama pull llama3.3:70b
ollama pull nomic-embed-text
4.3 VerificaciÃ³n y Test
bash
# Test del modelo de cÃ³digo
ollama run qwen2.5-coder:7b "Escribe una funciÃ³n Python para bubble sort"
# Test del modelo general
ollama run llama3.3:8b "Explica quÃ© es un protocolo de enrutamiento"
# Verificar embeddings
ollama show nomic-embed-text

--- PÃ¡gina 6 ---
4.4 ConfiguraciÃ³n Avanzada (Opcional)
Crear archivo ~/.ollama/config.json :
json
{
"origins": ["http://localhost:*"],
"models_path": "/home/tu_usuario/.ollama/models",
"keep_alive": "5m",
"num_parallel": 2,
"num_ctx": 8192
}
5. FASE 2: ENTORNO DE SIMULACIÃ“N NS-3
5.1 CompilaciÃ³n de NS-3 con Python Bindings
CRÃTICO: NO uses apt install ns3 . Siempre compila desde fuente.
bash
cd ~/tesis-a2a
# 1. Descargar NS-3 (VersiÃ³n 3.43 o 3.44)
wget https://www.nsnam.org/releases/ns-allinone-3.43.tar.bz2
tar xjf ns-allinone-3.43.tar.bz2
cd ns-allinone-3.43/ns-3.43
# 2. Configurar con Python bindings y ejemplos
./ns3 configure --enable-python-bindings --enable-examples
# 3. Compilar (tomarÃ¡ 10-30 minutos dependiendo de tu CPU)
./ns3 build
# 4. Verificar compilaciÃ³n exitosa
./ns3 build-status
# 5. Test bÃ¡sico
./test.py
5.2 Configurar Python Virtual Environment para NS-3
bash

--- PÃ¡gina 7 ---
# Crear entorno virtual
python3 -m venv ~/tesis-a2a/venv-ns3
source ~/tesis-a2a/venv-ns3/bin/activate
# Instalar dependencias Python para NS-3
pip install --upgrade pip
pip install numpy matplotlib pandas
5.3 VerificaciÃ³n de Python Bindings
bash
# Test de importaciÃ³n
cd ~/tesis-a2a/ns-allinone-3.43/ns-3.43
python3 << EOF
import sys
sys.path.append('./build/lib/python3')
import ns.core
import ns.network
import ns.internet
print("âœ“ Python bindings funcionando correctamente")
print(f"NS-3 versiÃ³n: {ns.core.Version()}")
EOF
6. FASE 3: SISTEMA DE ORQUESTACIÃ“N (LANGGRAPH)
6.1 Crear Proyecto Python para el Sistema A2A
bash

--- PÃ¡gina 8 ---
cd ~/tesis-a2a
# Crear estructura de proyecto
mkdir -p sistema-a2a/{agents,utils,config,logs,data,simulations}
cd sistema-a2a
# Crear entorno virtual dedicado
python3 -m venv venv-a2a
source venv-a2a/bin/activate
# Instalar dependencias principales (Noviembre 2025)
pip install --upgrade pip
# LangGraph y LangChain (versiones estables mÃ¡s recientes)
pip install langgraph==1.0.3
pip install langchain==1.0.0
pip install langchain-community
pip install langchain-ollama
# Bases de datos y embeddings
pip install chromadb==0.4.22
pip install sentence-transformers
# AnÃ¡lisis y visualizaciÃ³n
pip install pandas numpy matplotlib seaborn
# APIs acadÃ©micas
pip install semanticscholar
pip install arxiv
# Utilidades
pip install python-dotenv
pip install pydantic==2.5.0
6.2 Estructura del Proyecto
bash

--- PÃ¡gina 9 ---
sistema-a2a/
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”œâ”€â”€ researcher.py # Agente investigador
â”‚ â”œâ”€â”€ coder.py # Agente programador
â”‚ â”œâ”€â”€ simulator.py # Agente ejecutor
â”‚ â”œâ”€â”€ analyst.py # Agente analista
â”‚ â””â”€â”€ visualizer.py # Agente visualizaciÃ³n
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ __init__.py
â”‚ â”œâ”€â”€ state.py # DefiniciÃ³n de estado
â”‚ â”œâ”€â”€ llm_utils.py # Utilidades LLM
â”‚ â””â”€â”€ ns3_utils.py # Utilidades NS-3
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ __init__.py
â”‚ â””â”€â”€ settings.py # ConfiguraciÃ³n global
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ bitacora_tesis.db # Base de datos de bitÃ¡cora
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ papers/ # Papers descargados
â”‚ â””â”€â”€ vector_db/ # ChromaDB
â”œâ”€â”€ simulations/
â”‚ â”œâ”€â”€ scripts/ # Scripts NS-3 generados
â”‚ â”œâ”€â”€ results/ # Resultados de simulaciones
â”‚ â””â”€â”€ plots/ # GrÃ¡ficos generados
â”œâ”€â”€ main.py # Punto de entrada principal
â”œâ”€â”€ supervisor.py # Orquestador LangGraph
â””â”€â”€ requirements.txt # Dependencias
6.3 ImplementaciÃ³n del Estado Global
Crear utils/state.py :
python

--- PÃ¡gina 10 ---
from typing import TypedDict, List, Annotated, Dict, Any
import operator
class AgentState(TypedDict):
"""
Estado compartido entre todos los agentes.
Este es el 'cerebro' del sistema.
"""
# Tarea actual
task: str
# InvestigaciÃ³n
research_notes: Annotated[List[str], operator.add]
papers_found: Annotated[List[Dict[str, Any]], operator.add]
# CÃ³digo
code_snippet: str
code_validated: bool
# SimulaciÃ³n
simulation_logs: str
simulation_status: str # 'pending', 'running', 'completed', 'failed'
# AnÃ¡lisis
analysis_results: Dict[str, Any]
metrics: Dict[str, float]
# VisualizaciÃ³n
plots_generated: Annotated[List[str], operator.add]
# Control de errores
errors: Annotated[List[str], operator.add]
iteration_count: int
max_iterations: int
# BitÃ¡cora
audit_trail: Annotated[List[Dict[str, Any]], operator.add]
# Mensajes conversacionales
messages: Annotated[List[str], operator.add]
6.4 ConfiguraciÃ³n Global
Crear config/settings.py :
python

--- PÃ¡gina 11 ---
import os
from pathlib import Path
# Rutas
PROJECT_ROOT = Path(__file__).parent.parent
NS3_ROOT = Path.home() / "tesis-a2a" / "ns-allinone-3.43" / "ns-3.43"
SIMULATIONS_DIR = PROJECT_ROOT / "simulations"
DATA_DIR = PROJECT_ROOT / "data"
LOGS_DIR = PROJECT_ROOT / "logs"
# Ollama
OLLAMA_BASE_URL = "http://localhost:11434"
# Modelos LLM
MODEL_REASONING = "llama3.3:8b" # Para razonamiento general
MODEL_CODING = "qwen2.5-coder:7b" # Para generaciÃ³n de cÃ³digo
MODEL_EMBEDDING = "nomic-embed-text" # Para embeddings
# ChromaDB
CHROMA_PATH = DATA_DIR / "vector_db"
# LÃ­mites
MAX_ITERATIONS = 5 # Evitar bucles infinitos
SIMULATION_TIMEOUT = 600 # 10 minutos por simulaciÃ³n
# Crear directorios si no existen
for dir_path in [SIMULATIONS_DIR, DATA_DIR, LOGS_DIR, CHROMA_PATH]:
dir_path.mkdir(parents=True, exist_ok=True)
7. FASE 4: INTEGRACIÃ“N NS-3 CON IA (ns3-ai)
7.1 InstalaciÃ³n de ns3-ai
bash

--- PÃ¡gina 12 ---
cd ~/tesis-a2a/ns-allinone-3.43/ns-3.43/contrib
# Clonar repositorio ns3-ai
git clone https://github.com/hust-diangroup/ns3-ai.git ai
# Volver al directorio raÃ­z de NS-3
cd ..
# Reconfigurar NS-3 con ns3-ai
./ns3 configure --enable-python-bindings --enable-examples \
-- -DPython_EXECUTABLE=$(which python3)
# Compilar
./ns3 build
# Instalar interfaz Python de ns3-ai
source ~/tesis-a2a/venv-ns3/bin/activate
pip install -e contrib/ai/python_utils
pip install -e contrib/ai/model/gym-interface/py
7.2 Verificar InstalaciÃ³n de ns3-ai
bash
# Test del ejemplo A-Plus-B (ejemplo mÃ¡s simple)
cd ~/tesis-a2a/ns-allinone-3.43/ns-3.43
# Compilar ejemplo
./ns3 build ns3ai_apb_gym
# Ejecutar (requiere dos terminales)
# Terminal 1 - Ejecutar simulaciÃ³n NS-3:
./ns3 run ns3ai_apb_gym
# Terminal 2 - Ejecutar agente Python:
cd contrib/ai/examples/a-plus-b
python3 run_gym.py
# Si ves "Sum: X + Y = Z" funcionando, Â¡Ã©xito!
7.3 Alternativa: InstalaciÃ³n de ns3-gym (Si ns3-ai falla)
bash

--- PÃ¡gina 13 ---
cd ~/tesis-a2a/ns-allinone-3.43/ns-3.43/contrib
# Clonar ns3-gym
git clone https://github.com/tkn-tub/ns3-gym.git opengym
cd opengym
# Cambiar a rama compatible
git checkout app-ns-3.36+
cd ../../
# Reconfigurar y compilar
./ns3 configure --enable-python-bindings --enable-examples
./ns3 build
# Instalar interfaz Python
cd contrib/opengym
source ~/tesis-a2a/venv-ns3/bin/activate
pip install ./model/ns3gym
PARTE III: DESARROLLO DE AGENTES
8. AGENTE INVESTIGADOR (LITERATURA ACADÃ‰MICA)
Este agente es responsable de buscar, recuperar y sintetizar literatura acadÃ©mica relevante.
8.1 ImplementaciÃ³n Completa
Crear agents/researcher.py :
python

--- PÃ¡gina 14 ---
"""
Agente Investigador: BÃºsqueda y sÃ­ntesis de literatura acadÃ©mica
"""
import sys
sys.path.append('../')
from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun
from langchain_ollama import ChatOllama
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
import chromadb
from chromadb.utils import embedding_functions
import arxiv
from typing import List, Dict
import json
from config.settings import (
OLLAMA_BASE_URL, MODEL_REASONING, MODEL_EMBEDDING,
CHROMA_PATH, DATA_DIR
)
from utils.state import AgentState
class ResearchAgent:
"""
Agente especializado en investigaciÃ³n acadÃ©mica automatizada
"""
def __init__(self):
# LLM para sÃ­ntesis
self.llm = ChatOllama(
model=MODEL_REASONING,
temperature=0.1, # Baja temperatura para respuestas factuales
base_url=OLLAMA_BASE_URL
)
# Herramienta de bÃºsqueda Semantic Scholar
self.semantic_scholar = SemanticScholarQueryRun()
# Cliente arXiv
self.arxiv_client = arxiv.Client()
# ChromaDB para almacenar papers
self.chroma_client = chromadb.PersistentClient(path=str(CHROMA_PATH))
# FunciÃ³n de embedding local

--- PÃ¡gina 15 ---
self.embedding_fn = embedding_functions.OllamaEmbeddingFunction(
model_name=MODEL_EMBEDDING,
url=f"{OLLAMA_BASE_URL}/api/embeddings"
)
# ColecciÃ³n para papers
self.collection = self.chroma_client.get_or_create_collection(
name="research_papers",
embedding_function=self.embedding_fn
)
# Text splitter para chunks
self.text_splitter = RecursiveCharacterTextSplitter(
chunk_size=1000,
chunk_overlap=200
)
def search_semantic_scholar(self, query: str, max_results: int = 10) -> List[Dict]:
"""
Buscar papers en Semantic Scholar
"""
print(f"ğŸ” Buscando en Semantic Scholar: {query}")
try:
results = self.semantic_scholar.run(query)
# Parsear resultados (formato JSON)
papers = json.loads(results) if isinstance(results, str) else results
# Filtrar y limpiar
cleaned_papers = []
for paper in papers[:max_results]:
cleaned_papers.append({
'title': paper.get('title', ''),
'abstract': paper.get('abstract', ''),
'year': paper.get('year', ''),
'authors': paper.get('authors', []),
'url': paper.get('url', ''),
'citations': paper.get('citationCount', 0)
})
return cleaned_papers
except Exception as e:
print(f"âŒ Error en Semantic Scholar: {e}")
return []
def search_arxiv(self, query: str, max_results: int = 5) -> List[Dict]:

--- PÃ¡gina 16 ---
"""
Buscar papers en arXiv
"""
print(f"ğŸ” Buscando en arXiv: {query}")
try:
search = arxiv.Search(
query=query,
max_results=max_results,
sort_by=arxiv.SortCriterion.Relevance
)
papers = []
for result in self.arxiv_client.results(search):
papers.append({
'title': result.title,
'abstract': result.summary,
'year': result.published.year,
'authors': [author.name for author in result.authors],
'url': result.pdf_url,
'citations': 0 # arXiv no proporciona citas
})
return papers
except Exception as e:
print(f"âŒ Error en arXiv: {e}")
return []
def store_papers_in_vectordb(self, papers: List[Dict]):
"""
Almacenar papers en ChromaDB para RAG posterior
"""
print(f"ğŸ’¾ Almacenando {len(papers)} papers en base de datos vectorial...")
for i, paper in enumerate(papers):
# Combinar tÃ­tulo y abstract para embedding
content = f"Title: {paper['title']}\n\nAbstract: {paper['abstract']}"
# Dividir en chunks si es muy largo
chunks = self.text_splitter.split_text(content)
# Almacenar cada chunk
for j, chunk in enumerate(chunks):
doc_id = f"paper_{i}_chunk_{j}"
self.collection.add(

--- PÃ¡gina 17 ---
documents=[chunk],
metadatas=[{
'title': paper['title'],
'year': str(paper['year']),
'url': paper['url'],
'citations': paper['citations']
}],
ids=[doc_id]
)
def query_vectordb(self, query: str, n_results: int = 5) -> List[str]:
"""
Consultar la base de datos vectorial (RAG)
"""
results = self.collection.query(
query_texts=[query],
n_results=n_results
)
return results['documents'][0] if results['documents'] else []
def synthesize_research(self, query: str, papers: List[Dict]) -> str:
"""
Sintetizar findings usando el LLM local
"""
print("ğŸ“ Sintetizando hallazgos de investigaciÃ³n...")
# Preparar contexto
papers_summary = "\n\n".join([
f"Paper {i+1}:\nTÃ­tulo: {p['title']}\n"
f"AÃ±o: {p['year']}\nCitas: {p['citations']}\n"
f"Abstract: {p['abstract'][:500]}..."
for i, p in enumerate(papers[:5]) # Top 5 papers
])
prompt = f"""
Eres un investigador experto en redes de telecomunicaciones y Smart Cities.
Analiza los siguientes papers acadÃ©micos y proporciona una sÃ­ntesis concisa.
Consulta de investigaciÃ³n: {query}
Papers encontrados:
{papers_summary}
Por favor, proporciona:
1. **Resumen de hallazgos clave** (2-3 pÃ¡rrafos)
2. **Brechas de investigaciÃ³n identificadas**

--- PÃ¡gina 18 ---
3. **Recomendaciones tÃ©cnicas** para implementaciÃ³n en NS-3
SÃ© especÃ­fico y cita nÃºmeros de paper cuando sea relevante.
"""
response = self.llm.invoke(prompt)
return response.content
def run(self, state: AgentState) -> Dict:
"""
Ejecutar el agente investigador
"""
print("\n" + "="*60)
print("ğŸ“ AGENTE INVESTIGADOR ACTIVADO")
print("="*60)
task = state['task']
# 1. Buscar en Semantic Scholar
ss_papers = self.search_semantic_scholar(
f"routing protocols optimization {task} smart cities ns-3",
max_results=10
)
# 2. Buscar en arXiv
arxiv_papers = self.search_arxiv(
f"routing protocols {task} machine learning",
max_results=5
)
# 3. Combinar resultados
all_papers = ss_papers + arxiv_papers
# 4. Almacenar en ChromaDB
if all_papers:
self.store_papers_in_vectordb(all_papers)
# 5. Sintetizar hallazgos
if all_papers:
synthesis = self.synthesize_research(task, all_papers)
else:
synthesis = "No se encontraron papers relevantes. Proceder con conocimiento base."
# 6. Actualizar estado
return {
"research_notes": [synthesis],
"papers_found": all_papers,

--- PÃ¡gina 19 ---
"audit_trail": [{
'agent': 'researcher',
'action': 'literature_review',
'papers_count': len(all_papers),
'timestamp': str(pd.Timestamp.now())
}]
}
def research_node(state: AgentState) -> Dict:
"""
Nodo para LangGraph
"""
agent = ResearchAgent()
return agent.run(state)
8.2 Test del Agente Investigador
Crear test_researcher.py :
python

--- PÃ¡gina 20 ---
from agents.researcher import research_node
from utils.state import AgentState
# Estado de prueba
test_state = {
'task': 'AODV optimization using Graph Neural Networks',
'research_notes': [],
'papers_found': [],
'code_snippet': '',
'code_validated': False,
'simulation_logs': '',
'simulation_status': 'pending',
'analysis_results': {},
'metrics': {},
'plots_generated': [],
'errors': [],
'iteration_count': 0,
'max_iterations': 5,
'audit_trail': [],
'messages': []
}
# Ejecutar agente
result = research_node(test_state)
print("\n" + "="*60)
print("RESULTADO:")
print("="*60)
print(f"Papers encontrados: {len(result['papers_found'])}")
print(f"\nSÃ­ntesis:\n{result['research_notes'][0]}")
9. AGENTE PROGRAMADOR (GENERACIÃ“N DE CÃ“DIGO NS-3)
Este es el agente mÃ¡s crÃ­tico: genera scripts de simulaciÃ³n NS-3 vÃ¡lidos.
9.1 ImplementaciÃ³n Completa
Crear agents/coder.py :
python

--- PÃ¡gina 21 ---
"""
Agente Programador: GeneraciÃ³n y validaciÃ³n de cÃ³digo NS-3
"""
import sys
sys.path.append('../')
from langchain_ollama import ChatOllama
from typing import Dict
import re
from config.settings import (
OLLAMA_BASE_URL, MODEL_CODING,
SIMULATIONS_DIR
)
from utils.state import AgentState
class CoderAgent:
"""
Agente especializado en generaciÃ³n de cÃ³digo NS-3
"""
def __init__(self):
# LLM especializado en cÃ³digo
self.llm = ChatOllama(
model=MODEL_CODING,
temperature=0.1, # Baja temperatura para cÃ³digo determinista
base_url=OLLAMA_BASE_URL
)
# Templates de cÃ³digo base
self.base_template = '''#!/usr/bin/env python3
"""
Script de simulaciÃ³n NS-3 generado automÃ¡ticamente
Objetivo: {objective}
"""
import sys
sys.path.append('build/lib/python3')
import ns.core
import ns.network
import ns.internet
import ns.mobility
import ns.wifi
import ns.applications

--- PÃ¡gina 22 ---
import ns.flow_monitor
def main():
"""FunciÃ³n principal de simulaciÃ³n"""
# ConfiguraciÃ³n de simulaciÃ³n
ns.core.Config.SetDefault("ns3::WifiRemoteStationManager::RtsCtsThreshold", ns.core.StringValue("2200"))
# {code_placeholder}
# Configurar FlowMonitor para mÃ©tricas
flowmon_helper = ns.flow_monitor.FlowMonitorHelper()
monitor = flowmon_helper.InstallAll()
# Ejecutar simulaciÃ³n
print("Iniciando simulaciÃ³n...")
ns.core.Simulator.Stop(ns.core.Seconds(simulation_time))
ns.core.Simulator.Run()
# Exportar resultados
monitor.SerializeToXmlFile("resultados.xml", True, True)
print("SimulaciÃ³n completada. Resultados en resultados.xml")
ns.core.Simulator.Destroy()
return 0
if __name__ == "__main__":
sys.exit(main())
'''
def extract_code(self, response: str) -> str:
"""
Extraer cÃ³digo limpio de la respuesta del LLM
"""
# Buscar bloques de cÃ³digo Python
code_pattern = r'```python\n(.*?)\n```'
matches = re.findall(code_pattern, response, re.DOTALL)
if matches:
return matches[0]
# Si no hay bloques markdown, retornar todo
return response.strip()
def validate_imports(self, code: str) -> bool:
"""
Validar que el cÃ³digo tenga los imports necesarios

--- PÃ¡gina 23 ---
"""
required_imports = ['ns.core', 'ns.network']
return all(imp in code for imp in required_imports)
def generate_code(self, task: str, research_notes: str,
previous_error: str = None) -> str:
"""
Generar cÃ³digo NS-3 usando Chain-of-Thought
"""
print("ğŸ”¨ Generando cÃ³digo NS-3...")
# Construir prompt con CoT
prompt = f"""
Eres un experto en NS-3 y Python. Tu tarea es generar un script de simulaciÃ³n.
**OBJETIVO DE SIMULACIÃ“N:**
{task}
**CONTEXTO DE INVESTIGACIÃ“N:**
{research_notes}
**INSTRUCCIONES CRÃTICAS:**
1. USA SOLO Python bindings de NS-3 (NO C++)
2. Importa mÃ³dulos como: import ns.core, import ns.network, etc.
3. Configura FlowMonitor para exportar mÃ©tricas a "resultados.xml"
4. Incluye movilidad de nodos si se trata de VANETs
5. Usa protocolos estÃ¡ndar (AODV, OLSR, DSDV) como baseline
6. La simulaciÃ³n debe durar entre 50-100 segundos
7. NO uses funciones obsoletas (verifica versiÃ³n NS-3 3.43)
**REGLAS DE FORMATO:**
- Devuelve SOLO el cÃ³digo Python completo
- NO incluyas explicaciones fuera del cÃ³digo
- USA comentarios # dentro del cÃ³digo para explicar
- El cÃ³digo debe ser ejecutable directamente
"""
# Si hay error previo, agregarlo para correcciÃ³n
if previous_error:
prompt += f"""
**ERROR ANTERIOR A CORREGIR:**
{previous_error}
Por favor, corrige el cÃ³digo basÃ¡ndote en este error especÃ­fico.
"""

--- PÃ¡gina 24 ---
# Primero: Razonamiento (Chain of Thought)
cot_prompt = f"""
Antes de escribir cÃ³digo, planifica la simulaciÃ³n paso a paso:
1. Â¿QuÃ© tipo de red es? (MANET, VANET, WSN)
2. Â¿CuÃ¡ntos nodos se necesitan?
3. Â¿QuÃ© protocolo de enrutamiento usar como baseline?
4. Â¿QuÃ© mÃ©tricas medir?
5. Â¿QuÃ© modelo de movilidad aplicar?
Responde brevemente cada pregunta en 1-2 lÃ­neas.
"""
reasoning = self.llm.invoke(cot_prompt + "\n\nContexto:\n" + task)
print(f"ğŸ“‹ PlanificaciÃ³n:\n{reasoning.content}\n")
# Segundo: Generar cÃ³digo basado en el razonamiento
full_prompt = prompt + f"\n**TU PLANIFICACIÃ“N:**\n{reasoning.content}\n\nAhora genera el cÃ³digo:"
response = self.llm.invoke(full_prompt)
code = self.extract_code(response.content)
return code
def save_code(self, code: str, filename: str = "tesis_sim.py") -> str:
"""
Guardar cÃ³digo en el directorio de simulaciones
"""
filepath = SIMULATIONS_DIR / "scripts" / filename
filepath.parent.mkdir(parents=True, exist_ok=True)
with open(filepath, 'w') as f:
f.write(code)
# Hacer ejecutable
filepath.chmod(0o755)
return str(filepath)
def run(self, state: AgentState) -> Dict:
"""
Ejecutar el agente programador
"""
print("\n" + "="*60)
print("ğŸ’» AGENTE PROGRAMADOR ACTIVADO")
print("="*60)

--- PÃ¡gina 25 ---
task = state['task']
research_notes = "\n".join(state.get('research_notes', []))
previous_error = state['errors'][-1] if state.get('errors') else None
# Generar cÃ³digo
code = self.generate_code(task, research_notes, previous_error)
# Validar imports bÃ¡sicos
if not self.validate_imports(code):
return {
'code_snippet': code,
'code_validated': False,
'errors': ['CÃ³digo generado no tiene los imports necesarios de NS-3'],
'iteration_count': state['iteration_count'] + 1
}
# Guardar cÃ³digo
filepath = self.save_code(code)
print(f"âœ… CÃ³digo guardado en: {filepath}")
return {
'code_snippet': code,
'code_validated': True,
'iteration_count': state['iteration_count'] + 1,
'audit_trail': [{
'agent': 'coder',
'action': 'code_generation',
'filepath': filepath,
'timestamp': str(pd.Timestamp.now())
}]
}
def coder_node(state: AgentState) -> Dict:
"""
Nodo para LangGraph
"""
agent = CoderAgent()
return agent.run(state)
10. AGENTE EJECUTOR DE SIMULACIONES
Este agente ejecuta los scripts NS-3 y captura errores.
10.1 ImplementaciÃ³n Completa

--- PÃ¡gina 26 ---
Crear agents/simulator.py :
python

--- PÃ¡gina 27 ---
"""
Agente Ejecutor: EjecuciÃ³n de simulaciones NS-3
"""
import sys
sys.path.append('../')
import subprocess
import os
from pathlib import Path
from typing import Dict
import pandas as pd
from config.settings import (
NS3_ROOT, SIMULATIONS_DIR, SIMULATION_TIMEOUT
)
from utils.state import AgentState
class SimulatorAgent:
"""
Agente especializado en ejecutar simulaciones NS-3
"""
def __init__(self):
self.ns3_root = NS3_ROOT
self.results_dir = SIMULATIONS_DIR / "results"
self.results_dir.mkdir(parents=True, exist_ok=True)
def prepare_simulation(self, code: str) -> Path:
"""
Preparar script para ejecuciÃ³n
"""
# Guardar en directorio scratch de NS-3
script_path = self.ns3_root / "scratch" / "tesis_sim.py"
with open(script_path, 'w') as f:
f.write(code)
script_path.chmod(0o755)
return script_path
def execute_simulation(self, script_name: str = "tesis_sim.py") -> Dict:
"""
Ejecutar simulaciÃ³n NS-3
"""
print(f"ğŸš€ Ejecutando simulaciÃ³n: {script_name}")

--- PÃ¡gina 28 ---
try:
# Comando: ./ns3 run scratch/tesis_sim.py
cmd = ["./ns3", "run", f"scratch/{script_name}"]
result = subprocess.run(
cmd,
cwd=str(self.ns3_root),
capture_output=True,
text=True,
timeout=SIMULATION_TIMEOUT
)
# Verificar Ã©xito
if result.returncode != 0:
error_msg = result.stderr if result.stderr else result.stdout
return {
'success': False,
'error': error_msg,
'stdout': result.stdout
}
# Buscar archivo de resultados
results_file = self.ns3_root / "resultados.xml"
if not results_file.exists():
return {
'success': False,
'error': 'SimulaciÃ³n ejecutÃ³ pero no generÃ³ resultados.xml'
}
# Mover resultados a directorio organizado
timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
new_path = self.results_dir / f"sim_{timestamp}.xml"
results_file.rename(new_path)
return {
'success': True,
'results_path': str(new_path),
'stdout': result.stdout
}
except subprocess.TimeoutExpired:
return {
'success': False,
'error': f'SimulaciÃ³n excediÃ³ timeout de {SIMULATION_TIMEOUT}s'
}

--- PÃ¡gina 29 ---
except Exception as e:
return {
'success': False,
'error': f'Error inesperado: {str(e)}'
}
def run(self, state: AgentState) -> Dict:
"""
Ejecutar el agente simulador
"""
print("\n" + "="*60)
print("âš¡ AGENTE SIMULADOR ACTIVADO")
print("="*60)
code = state.get('code_snippet', '')
if not code:
return {
'simulation_status': 'failed',
'errors': ['No hay cÃ³digo para ejecutar']
}
# Preparar script
script_path = self.prepare_simulation(code)
# Ejecutar
result = self.execute_simulation()
if result['success']:
print(f"âœ… SimulaciÃ³n exitosa!")
print(f"ğŸ“Š Resultados: {result['results_path']}")
return {
'simulation_status': 'completed',
'simulation_logs': result['results_path'],
'audit_trail': [{
'agent': 'simulator',
'action': 'simulation_completed',
'results_path': result['results_path'],
'timestamp': str(pd.Timestamp.now())
}]
}
else:
print(f"âŒ SimulaciÃ³n fallÃ³")
print(f"Error: {result['error']}")
return {

--- PÃ¡gina 30 ---
'simulation_status': 'failed',
'errors': [result['error']],
'iteration_count': state['iteration_count'] + 1
}
def simulator_node(state: AgentState) -> Dict:
"""
Nodo para LangGraph
"""
agent = SimulatorAgent()
return agent.run(state)
11. AGENTE ANALISTA DE PROTOCOLOS
Este agente analiza resultados y propone mejoras con redes neuronales.
11.1 ImplementaciÃ³n
Crear agents/analyst.py :
python

--- PÃ¡gina 31 ---
"""
Agente Analista: AnÃ¡lisis de resultados y propuesta de optimizaciones
"""
import sys
sys.path.append('../')
from langchain_ollama import ChatOllama
import xml.etree.ElementTree as ET
import pandas as pd
from typing import Dict
import numpy as np
from config.settings import (
OLLAMA_BASE_URL, MODEL_REASONING
)
from utils.state import AgentState
class AnalystAgent:
"""
Agente especializado en anÃ¡lisis de protocolos
"""
def __init__(self):
self.llm = ChatOllama(
model=MODEL_REASONING,
temperature=0.3,
base_url=OLLAMA_BASE_URL
)
def parse_flowmonitor_xml(self, xml_path: str) -> pd.DataFrame:
"""
Parsear XML de FlowMonitor y extraer mÃ©tricas
"""
print(f"ğŸ“Š Parseando resultados: {xml_path}")
tree = ET.parse(xml_path)
root = tree.getroot()
flows = []
for flow in root.findall('.//Flow'):
flow_id = flow.get('flowId')
# Extraer estadÃ­sticas
tx_packets = int(flow.get('txPackets', 0))

--- PÃ¡gina 32 ---
rx_packets = int(flow.get('rxPackets', 0))
tx_bytes = int(flow.get('txBytes', 0))
rx_bytes = int(flow.get('rxBytes', 0))
delay_sum = float(flow.get('delaySum', '0').replace('ns', ''))
jitter_sum = float(flow.get('jitterSum', '0').replace('ns', ''))
# Calcular mÃ©tricas
pdr = (rx_packets / tx_packets * 100) if tx_packets > 0 else 0
throughput = (rx_bytes * 8 / 1000000) # Mbps (asumiendo 100s simulaciÃ³n)
avg_delay = (delay_sum / rx_packets / 1e6) if rx_packets > 0 else 0 # ms
flows.append({
'flow_id': flow_id,
'tx_packets': tx_packets,
'rx_packets': rx_packets,
'pdr': pdr,
'throughput_mbps': throughput,
'avg_delay_ms': avg_delay
})
return pd.DataFrame(flows)
def calculate_kpis(self, df: pd.DataFrame) -> Dict:
"""
Calcular KPIs agregados
"""
kpis = {
'avg_pdr': df['pdr'].mean(),
'avg_throughput': df['throughput_mbps'].mean(),
'avg_delay': df['avg_delay_ms'].mean(),
'total_flows': len(df),
'successful_flows': len(df[df['rx_packets'] > 0])
}
return kpis
def propose_optimization(self, kpis: Dict, task: str) -> str:
"""
Proponer optimizaciones usando redes neuronales
"""
print("ğŸ§  Analizando y proponiendo optimizaciones...")
prompt = f"""
Eres un experto en optimizaciÃ³n de redes con Deep Learning.
**TAREA ORIGINAL:**

--- PÃ¡gina 33 ---
{task}
**MÃ‰TRICAS ACTUALES (Protocolo Baseline):**
- PDR (Packet Delivery Ratio): {kpis['avg_pdr']:.2f}%
- Throughput promedio: {kpis['avg_throughput']:.2f} Mbps
- Delay promedio: {kpis['avg_delay']:.2f} ms
- Flujos exitosos: {kpis['successful_flows']}/{kpis['total_flows']}
**ANÃLISIS REQUERIDO:**
1. **EvaluaciÃ³n del rendimiento actual**: Â¿Es bueno/malo? Â¿Por quÃ©?
2. **IdentificaciÃ³n de cuellos de botella**: Â¿DÃ³nde estÃ¡ el problema?
3. **Propuesta de arquitectura de red neuronal**:
- Â¿QuÃ© tipo? (DQN, A3C, GNN, etc.)
- Â¿QuÃ© observa? (Estado de la red)
- Â¿QuÃ© decide? (Acciones de enrutamiento)
- Â¿FunciÃ³n de recompensa?
4. **Plan de implementaciÃ³n**: Pasos concretos para integrar con NS-3
SÃ© especÃ­fico y tÃ©cnico. Proporciona cÃ³digo conceptual si es posible.
"""
response = self.llm.invoke(prompt)
return response.content
def run(self, state: AgentState) -> Dict:
"""
Ejecutar el agente analista
"""
print("\n" + "="*60)
print("ğŸ”¬ AGENTE ANALISTA ACTIVADO")
print("="*60)
results_path = state.get('simulation_logs', '')
if not results_path:
return {
'errors': ['No hay resultados de simulaciÃ³n para analizar']
}
try:
# Parsear resultados
df = self.parse_flowmonitor_xml(results_path)
# Calcular KPIs
kpis = self.calculate_kpis(df)
print("\nğŸ“ˆ KPIs Calculados:")

--- PÃ¡gina 34 ---
for key, value in kpis.items():
print(f" {key}: {value}")
# Proponer optimizaciÃ³n
optimization_proposal = self.propose_optimization(
kpis,
state['task']
)
return {
'analysis_results': {
'dataframe': df.to_dict(),
'kpis': kpis,
'proposal': optimization_proposal
},
'metrics': kpis,
'messages': [f"AnÃ¡lisis completado. PDR: {kpis['avg_pdr']:.2f}%"],
'audit_trail': [{
'agent': 'analyst',
'action': 'analysis_completed',
'kpis': kpis,
'timestamp': str(pd.Timestamp.now())
}]
}
except Exception as e:
return {
'errors': [f'Error en anÃ¡lisis: {str(e)}']
}
def analyst_node(state: AgentState) -> Dict:
"""
Nodo para LangGraph
"""
agent = AnalystAgent()
return agent.run(state)
12. AGENTE DE POST-PROCESADO Y VISUALIZACIÃ“N
Crear agents/visualizer.py :
python

--- PÃ¡gina 35 ---
"""
Agente Visualizador: GeneraciÃ³n de grÃ¡ficos acadÃ©micos
"""
import sys
sys.path.append('../')
from langchain_ollama import ChatOllama
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from pathlib import Path
from typing import Dict
from config.settings import (
OLLAMA_BASE_URL, MODEL_CODING, SIMULATIONS_DIR
)
from utils.state import AgentState
class VisualizerAgent:
"""
Agente especializado en visualizaciÃ³n de resultados
"""
def __init__(self):
self.llm = ChatOllama(
model=MODEL_CODING,
temperature=0.1,
base_url=OLLAMA_BASE_URL
)
self.plots_dir = SIMULATIONS_DIR / "plots"
self.plots_dir.mkdir(parents=True, exist_ok=True)
# Configurar estilo acadÃ©mico
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 12
plt.rcParams['font.family'] = 'serif'
def generate_plot_code(self, kpis: Dict, task: str) -> str:
"""
Generar cÃ³digo para visualizaciÃ³n usando LLM
"""
prompt = f"""
Genera cÃ³digo Python para visualizar mÃ©tricas de red.

--- PÃ¡gina 36 ---
**DATOS DISPONIBLES:**
{kpis}
**OBJETIVO:**
{task}
**REQUISITOS:**
1. Usa matplotlib y seaborn
2. Estilo acadÃ©mico (IEEE)
3. Genera 2-3 grÃ¡ficos relevantes
4. Guarda como PNG de alta resoluciÃ³n
5. Incluye tÃ­tulos, etiquetas y leyendas claras
Devuelve SOLO el cÃ³digo Python ejecutable.
"""
response = self.llm.invoke(prompt)
# Extraer cÃ³digo (simplificado, similar al CoderAgent)
return response.content
def create_standard_plots(self, df: pd.DataFrame, kpis: Dict) -> list:
"""
Crear grÃ¡ficos estÃ¡ndar sin LLM
"""
plots = []
# 1. GrÃ¡fico de PDR por flujo
plt.figure()
plt.bar(range(len(df)), df['pdr'], color='steelblue', alpha=0.7)
plt.axhline(y=kpis['avg_pdr'], color='r', linestyle='--',
label=f'Promedio: {kpis["avg_pdr"]:.2f}%')
plt.xlabel('Flujo ID')
plt.ylabel('PDR (%)')
plt.title('Packet Delivery Ratio por Flujo')
plt.legend()
plt.tight_layout()
plot_path = self.plots_dir / "pdr_per_flow.png"
plt.savefig(plot_path, dpi=300)
plt.close()
plots.append(str(plot_path))
# 2. GrÃ¡fico de Delay
plt.figure()
plt.hist(df['avg_delay_ms'], bins=20, color='coral', alpha=0.7, edgecolor='black')
plt.axvline(x=kpis['avg_delay'], color='r', linestyle='--',

--- PÃ¡gina 37 ---
label=f'Promedio: {kpis["avg_delay"]:.2f} ms')
plt.xlabel('Delay (ms)')
plt.ylabel('Frecuencia')
plt.title('DistribuciÃ³n de Delay End-to-End')
plt.legend()
plt.tight_layout()
plot_path = self.plots_dir / "delay_distribution.png"
plt.savefig(plot_path, dpi=300)
plt.close()
plots.append(str(plot_path))
# 3. GrÃ¡fico de Throughput
plt.figure()
df_sorted = df.sort_values('throughput_mbps', ascending=False)
plt.plot(df_sorted['throughput_mbps'].values, marker='o', color='green', alpha=0.6)
plt.xlabel('Flujo (ordenado por throughput)')
plt.ylabel('Throughput (Mbps)')
plt.title('Throughput por Flujo')
plt.grid(True, alpha=0.3)
plt.tight_layout()
plot_path = self.plots_dir / "throughput_flows.png"
plt.savefig(plot_path, dpi=300)
plt.close()
plots.append(str(plot_path))
return plots
def run(self, state: AgentState) -> Dict:
"""
Ejecutar el agente visualizador
"""
print("\n" + "="*60)
print("ğŸ“Š AGENTE VISUALIZADOR ACTIVADO")
print("="*60)
analysis_results = state.get('analysis_results', {})
if not analysis_results:
return {
'errors': ['No hay resultados de anÃ¡lisis para visualizar']
}
try:
# Reconstruir DataFrame
df_dict = analysis_results.get('dataframe', {})

--- PÃ¡gina 38 ---
df = pd.DataFrame(df_dict)
kpis = analysis_results.get('kpis', {})
# Generar grÃ¡ficos
plots = self.create_standard_plots(df, kpis)
print(f"âœ… Generados {len(plots)} grÃ¡ficos:")
for plot in plots:
print(f" ğŸ“ˆ {plot}")
return {
'plots_generated': plots,
'audit_trail': [{
'agent': 'visualizer',
'action': 'plots_generated',
'count': len(plots),
'timestamp': str(pd.Timestamp.now())
}]
}
except Exception as e:
return {
'errors': [f'Error en visualizaciÃ³n: {str(e)}']
}
def visualizer_node(state: AgentState) -> Dict:
"""
Nodo para LangGraph
"""
agent = VisualizerAgent()
return agent.run(state)
13. SISTEMA DE BITÃCORA AUTOMÃTICA
Crear utils/logbook.py :
python

--- PÃ¡gina 39 ---
"""
Sistema de BitÃ¡cora: Registro automÃ¡tico de toda la investigaciÃ³n
"""
import sqlite3
import pandas as pd
from pathlib import Path
from typing import Dict, List
import json
from config.settings import LOGS_DIR
class LogbookManager:
"""
Gestor de bitÃ¡cora automÃ¡tica
"""
def __init__(self, db_path: Path = None):
if db_path is None:
db_path = LOGS_DIR / "bitacora_tesis.db"
self.db_path = db_path
self.conn = sqlite3.connect(str(db_path))
self._init_db()
def _init_db(self):
"""
Crear tablas si no existen
"""
cursor = self.conn.cursor()
# Tabla de experimentos
cursor.execute('''
CREATE TABLE IF NOT EXISTS experiments (
id INTEGER PRIMARY KEY AUTOINCREMENT,
timestamp TEXT,
task TEXT,
status TEXT,
iteration_count INTEGER
)
''')
# Tabla de acciones de agentes
cursor.execute('''
CREATE TABLE IF NOT EXISTS agent_actions (
id INTEGER PRIMARY KEY AUTOINCREMENT,

--- PÃ¡gina 40 ---
experiment_id INTEGER,
agent_name TEXT,
action_type TEXT,
details TEXT,
timestamp TEXT,
FOREIGN KEY (experiment_id) REFERENCES experiments(id)
)
''')
# Tabla de mÃ©tricas
cursor.execute('''
CREATE TABLE IF NOT EXISTS metrics (
id INTEGER PRIMARY KEY AUTOINCREMENT,
experiment_id INTEGER,
metric_name TEXT,
metric_value REAL,
timestamp TEXT,
FOREIGN KEY (experiment_id) REFERENCES experiments(id)
)
''')
self.conn.commit()
def create_experiment(self, task: str) -> int:
"""
Crear nuevo experimento
"""
cursor = self.conn.cursor()
cursor.execute('''
INSERT INTO experiments (timestamp, task, status, iteration_count)
VALUES (datetime('now'), ?, 'running', 0)
''', (task,))
self.conn.commit()
return cursor.lastrowid
def log_agent_action(self, experiment_id: int, agent_name: str,
action_type: str, details: Dict):
"""
Registrar acciÃ³n de un agente
"""
cursor = self.conn.cursor()
cursor.execute('''
INSERT INTO agent_actions (experiment_id, agent_name, action_type, details, timestamp)
VALUES (?, ?, ?, ?, datetime('now'))
''', (experiment_id, agent_name, action_type, json.dumps(details)))
self.conn.commit()

--- PÃ¡gina 41 ---
def log_metrics(self, experiment_id: int, metrics: Dict):
"""
Registrar mÃ©tricas
"""
cursor = self.conn.cursor()
for metric_name, metric_value in metrics.items():
cursor.execute('''
INSERT INTO metrics (experiment_id, metric_name, metric_value, timestamp)
VALUES (?, ?, ?, datetime('now'))
''', (experiment_id, metric_name, metric_value))
self.conn.commit()
def update_experiment_status(self, experiment_id: int, status: str):
"""
Actualizar estado del experimento
"""
cursor = self.conn.cursor()
cursor.execute('''
UPDATE experiments SET status = ? WHERE id = ?
''', (status, experiment_id))
self.conn.commit()
def export_to_markdown(self, output_path: Path = None) -> str:
"""
Exportar bitÃ¡cora completa a Markdown
"""
if output_path is None:
output_path = LOGS_DIR / "bitacora_completa.md"
# Leer datos
experiments = pd.read_sql_query("SELECT * FROM experiments", self.conn)
actions = pd.read_sql_query("SELECT * FROM agent_actions", self.conn)
metrics = pd.read_sql_query("SELECT * FROM metrics", self.conn)
# Generar Markdown
md_content = "# BitÃ¡cora de InvestigaciÃ³n Doctoral\n\n"
md_content += f"**Generado:** {pd.Timestamp.now()}\n\n"
md_content += "---\n\n"
# Por cada experimento
for _, exp in experiments.iterrows():
md_content += f"## Experimento #{exp['id']}: {exp['task']}\n\n"
md_content += f"- **Timestamp:** {exp['timestamp']}\n"
md_content += f"- **Estado:** {exp['status']}\n"
md_content += f"- **Iteraciones:** {exp['iteration_count']}\n\n"
# Acciones del experimento

--- PÃ¡gina 42 ---
exp_actions = actions[actions['experiment_id'] == exp['id']]
if len(exp_actions) > 0:
md_content += "### Acciones de Agentes\n\n"
for _, action in exp_actions.iterrows():
md_content += f"- **{action['agent_name']}** ({action['timestamp']})\n"
md_content += f" - AcciÃ³n: {action['action_type']}\n"
md_content += f" - Detalles: {action['details']}\n\n"
# MÃ©tricas del experimento
exp_metrics = metrics[metrics['experiment_id'] == exp['id']]
if len(exp_metrics) > 0:
md_content += "### MÃ©tricas Obtenidas\n\n"
md_content += "| MÃ©trica | Valor |\n"
md_content += "|---------|-------|\n"
for _, metric in exp_metrics.iterrows():
md_content += f"| {metric['metric_name']} | {metric['metric_value']:.2f} |\n"
md_content += "\n"
md_content += "---\n\n"
# Guardar archivo
with open(output_path, 'w', encoding='utf-8') as f:
f.write(md_content)
return str(output_path)
def close(self):
"""Cerrar conexiÃ³n"""
self.conn.close()
PARTE IV: AUTOMATIZACIÃ“N Y OPERACIÃ“N
14. FLUJOS DE TRABAJO AUTOMATIZADOS
14.1 ImplementaciÃ³n del Supervisor (LangGraph)
Crear supervisor.py :
python

--- PÃ¡gina 43 ---
"""
Supervisor: Orquestador principal del sistema multi-agente
"""
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3
from typing import Literal
import pandas as pd
from utils.state import AgentState
from agents.researcher import research_node
from agents.coder import coder_node
from agents.simulator import simulator_node
from agents.analyst import analyst_node
from agents.visualizer import visualizer_node
from config.settings import LOGS_DIR
class SupervisorOrchestrator:
"""
Orquestador central del sistema A2A
"""
def __init__(self):
# Crear grafo de estados
self.workflow = StateGraph(AgentState)
# AÃ±adir nodos (agentes)
self.workflow.add_node("researcher", research_node)
self.workflow.add_node("coder", coder_node)
self.workflow.add_node("simulator", simulator_node)
self.workflow.add_node("analyst", analyst_node)
self.workflow.add_node("visualizer", visualizer_node)
# Definir flujo
self._define_workflow()
# Configurar persistencia (bitÃ¡cora automÃ¡tica)
db_path = LOGS_DIR / "langgraph_checkpoints.db"
memory = SqliteSaver(sqlite3.connect(str(db_path), check_same_thread=False))
# Compilar grafo
self.app = self.workflow.compile(checkpointer=memory)
def _define_workflow(self):
"""

--- PÃ¡gina 44 ---
Definir el flujo de trabajo entre agentes
"""
# Punto de entrada
self.workflow.set_entry_point("researcher")
# Flujo lineal bÃ¡sico
self.workflow.add_edge("researcher", "coder")
# LÃ³gica condicional: Â¿El cÃ³digo es vÃ¡lido?
self.workflow.add_conditional_edges(
"coder",
self._should_retry_code,
{
"simulator": "simulator",
"retry": "coder",
"end": END
}
)
# Desde simulador: Â¿La simulaciÃ³n fue exitosa?
self.workflow.add_conditional_edges(
"simulator",
self._should_retry_simulation,
{
"analyst": "analyst",
"retry_code": "coder",
"end": END
}
)
# AnÃ¡lisis â†’ VisualizaciÃ³n
self.workflow.add_edge("analyst", "visualizer")
# VisualizaciÃ³n â†’ Fin
self.workflow.add_edge("visualizer", END)
def _should_retry_code(self, state: AgentState) -> Literal["simulator", "retry", "end"]:
"""
Decidir si reintentar generaciÃ³n de cÃ³digo
"""
# Si hay errores y no se excediÃ³ lÃ­mite de iteraciones
if state.get('errors') and state['iteration_count'] < state['max_iterations']:
return "retry"
# Si cÃ³digo validado
if state.get('code_validated', False):
return "simulator"

--- PÃ¡gina 45 ---
# Si se excediÃ³ lÃ­mite
return "end"
def _should_retry_simulation(self, state: AgentState) -> Literal["analyst", "retry_code", "end"]:
"""
Decidir quÃ© hacer despuÃ©s de simulaciÃ³n
"""
sim_status = state.get('simulation_status', '')
# Si simulaciÃ³n exitosa
if sim_status == 'completed':
return "analyst"
# Si fallÃ³ y no se excediÃ³ lÃ­mite
if sim_status == 'failed' and state['iteration_count'] < state['max_iterations']:
return "retry_code"
# Si se excediÃ³ lÃ­mite
return "end"
def run_experiment(self, task: str, thread_id: str = None):
"""
Ejecutar un experimento completo
"""
from uuid import uuid4
if thread_id is None:
thread_id = str(uuid4())
config = {
"configurable": {
"thread_id": thread_id
}
}
# Estado inicial
initial_state = {
'task': task,
'research_notes': [],
'papers_found': [],
'code_snippet': '',
'code_validated': False,
'simulation_logs': '',
'simulation_status': 'pending',
'analysis_results': {},
'metrics': {},

--- PÃ¡gina 46 ---
'plots_generated': [],
'errors': [],
'iteration_count': 0,
'max_iterations': 5,
'audit_trail': [],
'messages': []
}
print("\n" + "="*80)
print("ğŸš€ INICIANDO EXPERIMENTO A2A")
print("="*80)
print(f"ğŸ“‹ Tarea: {task}")
print(f"ğŸ†” Thread ID: {thread_id}")
print("="*80 + "\n")
# Ejecutar workflow
try:
for event in self.app.stream(initial_state, config=config):
for node_name, node_output in event.items():
print(f"\nâœ“ Completado: {node_name}")
# Mostrar errores si existen
if 'errors' in node_output and node_output['errors']:
print(f" âš  Errores: {node_output['errors'][-1]}")
# Obtener estado final
final_state = self.app.get_state(config)
print("\n" + "="*80)
print("ğŸ‰ EXPERIMENTO COMPLETADO")
print("="*80)
# Resumen de resultados
if final_state.values.get('metrics'):
print("\nğŸ“Š MÃ‰TRICAS FINALES:")
for key, value in final_state.values['metrics'].items():
print(f" {key}: {value}")
if final_state.values.get('plots_generated'):
print(f"\nğŸ“ˆ GrÃ¡ficos generados: {len(final_state.values['plots_generated'])}")
return final_state.values
except Exception as e:
print(f"\nâŒ ERROR EN EXPERIMENTO: {str(e)}")
import traceback

--- PÃ¡gina 47 ---
traceback.print_exc()
return None
14.2 Script Principal de EjecuciÃ³n
Crear main.py :
python

--- PÃ¡gina 48 ---
#!/usr/bin/env python3
"""
Sistema Multi-Agente A2A para Tesis Doctoral
Punto de entrada principal
"""
import sys
import argparse
from pathlib import Path
# AÃ±adir directorio raÃ­z al path
sys.path.insert(0, str(Path(__file__).parent))
from supervisor import SupervisorOrchestrator
from utils.logbook import LogbookManager
from config.settings import LOGS_DIR
def main():
"""
FunciÃ³n principal
"""
parser = argparse.ArgumentParser(
description='Sistema Multi-Agente A2A para InvestigaciÃ³n en Redes'
)
parser.add_argument(
'--task',
type=str,
required=True,
help='DescripciÃ³n de la tarea de investigaciÃ³n'
)
parser.add_argument(
'--thread-id',
type=str,
default=None,
help='ID de thread para continuar experimento previo'
)
parser.add_argument(
'--export-logbook',
action='store_true',
help='Exportar bitÃ¡cora completa a Markdown'
)
args = parser.parse_args()

--- PÃ¡gina 49 ---
# Si solo se quiere exportar bitÃ¡cora
if args.export_logbook:
logbook = LogbookManager()
output_path = logbook.export_to_markdown()
print(f"âœ… BitÃ¡cora exportada a: {output_path}")
logbook.close()
return
# Crear orquestador
supervisor = SupervisorOrchestrator()
# Ejecutar experimento
result = supervisor.run_experiment(
task=args.task,
thread_id=args.thread_id
)
if result:
print("\nâœ… Experimento finalizado exitosamente")
# Exportar bitÃ¡cora automÃ¡ticamente
logbook = LogbookManager()
output_path = logbook.export_to_markdown()
print(f"ğŸ“š BitÃ¡cora actualizada: {output_path}")
logbook.close()
else:
print("\nâŒ Experimento fallÃ³")
sys.exit(1)
if __name__ == "__main__":
main()
Hacer ejecutable:
bash
chmod +x main.py
14.3 Ejemplos de Uso
bash

--- PÃ¡gina 50 ---
# Activar entorno virtual
cd ~/tesis-a2a/sistema-a2a
source venv-a2a/bin/activate
# Experimento 1: ComparaciÃ³n bÃ¡sica
python main.py --task "Comparar latencia entre AODV y OLSR en red vehicular con 50 nodos"
# Experimento 2: OptimizaciÃ³n con GNN
python main.py --task "Implementar y evaluar Graph Neural Network para optimizar enrutamiento en Smart City con 100 disp
# Experimento 3: AnÃ¡lisis de throughput
python main.py --task "Analizar impacto de movilidad de nodos en throughput usando protocolo DSDV"
# Exportar bitÃ¡cora completa
python main.py --export-logbook
15. MONITOREO Y DEBUGGING
15.1 Script de Monitoreo en Tiempo Real
Crear monitor.py :
python

--- PÃ¡gina 51 ---
#!/usr/bin/env python3
"""
Monitor de experimentos en tiempo real
"""
import sqlite3
import pandas as pd
from pathlib import Path
import time
from datetime import datetime
import sys
from config.settings import LOGS_DIR
def monitor_experiments(refresh_interval=5):
"""
Monitorear experimentos en tiempo real
"""
db_path = LOGS_DIR / "langgraph_checkpoints.db"
if not db_path.exists():
print("âŒ No se encontrÃ³ base de datos de checkpoints")
return
print("ğŸ” Monitoreando experimentos... (Ctrl+C para salir)\n")
try:
while True:
conn = sqlite3.connect(str(db_path))
# Leer checkpoints
try:
df = pd.read_sql_query("""
SELECT * FROM checkpoints
ORDER BY checkpoint_id DESC
LIMIT 10
""", conn)
print(f"\n{'='*80}")
print(f"Actualizado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"{'='*80}")
if len(df) > 0:
print(f"\nğŸ“Š Ãšltimos 10 checkpoints:")
print(df[['thread_id', 'checkpoint_id']].to_string(index=False))
else:

--- PÃ¡gina 52 ---
print("\nâ³ No hay checkpoints aÃºn...")
except Exception as e:
print(f"\nâš  Error leyendo checkpoints: {e}")
conn.close()
time.sleep(refresh_interval)
except KeyboardInterrupt:
print("\n\nâœ‹ Monitor detenido")
if __name__ == "__main__":
monitor_experiments()
15.2 Script de Debugging
Crear debug_tools.py :
python

--- PÃ¡gina 53 ---
#!/usr/bin/env python3
"""
Herramientas de debugging para el sistema A2A
"""
import sqlite3
import json
from pathlib import Path
import argparse
from config.settings import LOGS_DIR
def inspect_checkpoint(thread_id: str):
"""
Inspeccionar un checkpoint especÃ­fico
"""
db_path = LOGS_DIR / "langgraph_checkpoints.db"
conn = sqlite3.connect(str(db_path))
cursor = conn.cursor()
cursor.execute("""
SELECT * FROM checkpoints
WHERE thread_id = ?
ORDER BY checkpoint_id DESC
LIMIT 1
""", (thread_id,))
result = cursor.fetchone()
if result:
print(f"\n{'='*80}")
print(f"CHECKPOINT: {thread_id}")
print(f"{'='*80}\n")
# Mostrar columnas
columns = [desc[0] for desc in cursor.description]
for col, val in zip(columns, result):
print(f"{col}: {val}")
else:
print(f"âŒ No se encontrÃ³ checkpoint para thread_id: {thread_id}")
conn.close()
def list_all_threads():
"""
Listar todos los threads disponibles

--- PÃ¡gina 54 ---
"""
db_path = LOGS_DIR / "langgraph_checkpoints.db"
if not db_path.exists():
print("âŒ No existe base de datos de checkpoints")
return
conn = sqlite3.connect(str(db_path))
cursor = conn.cursor()
cursor.execute("SELECT DISTINCT thread_id FROM checkpoints")
threads = cursor.fetchall()
print(f"\nğŸ“‹ Threads disponibles ({len(threads)}):\n")
for thread in threads:
print(f" - {thread[0]}")
conn.close()
def validate_setup():
"""
Validar que todo el setup estÃ© correcto
"""
print("\nğŸ” VALIDANDO CONFIGURACIÃ“N DEL SISTEMA")
print("="*80)
checks = []
# 1. Verificar Ollama
try:
import requests
response = requests.get("http://localhost:11434/api/tags", timeout=2)
if response.status_code == 200:
checks.append(("âœ…", "Ollama", "Corriendo"))
else:
checks.append(("âŒ", "Ollama", "No responde"))
except:
checks.append(("âŒ", "Ollama", "No disponible"))
# 2. Verificar NS-3
from config.settings import NS3_ROOT
if NS3_ROOT.exists():
checks.append(("âœ…", "NS-3", f"Encontrado en {NS3_ROOT}"))
else:
checks.append(("âŒ", "NS-3", "No encontrado"))

--- PÃ¡gina 55 ---
# 3. Verificar directorios
from config.settings import SIMULATIONS_DIR, DATA_DIR, LOGS_DIR
for name, path in [("Simulaciones", SIMULATIONS_DIR),
("Datos", DATA_DIR),
("Logs", LOGS_DIR)]:
if path.exists():
checks.append(("âœ…", f"Dir {name}", str(path)))
else:
checks.append(("âŒ", f"Dir {name}", "No existe"))
# 4. Verificar paquetes Python
required_packages = [
'langgraph', 'langchain', 'chromadb',
'pandas', 'matplotlib', 'semanticscholar'
]
for package in required_packages:
try:
__import__(package)
checks.append(("âœ…", f"Paquete {package}", "Instalado"))
except ImportError:
checks.append(("âŒ", f"Paquete {package}", "NO instalado"))
# Mostrar resultados
print()
for status, component, message in checks:
print(f"{status} {component:20s} : {message}")
print("\n" + "="*80)
failed = sum(1 for c in checks if c[0] == "âŒ")
if failed == 0:
print("âœ… Todos los componentes estÃ¡n correctos")
else:
print(f"âš  {failed} componentes requieren atenciÃ³n")
def main():
parser = argparse.ArgumentParser(description='Herramientas de debugging')
subparsers = parser.add_subparsers(dest='command')
# Comando: inspect
inspect_parser = subparsers.add_parser('inspect', help='Inspeccionar checkpoint')
inspect_parser.add_argument('thread_id', help='ID del thread')
# Comando: list
subparsers.add_parser('list', help='Listar todos los threads')

--- PÃ¡gina 56 ---
# Comando: validate
subparsers.add_parser('validate', help='Validar configuraciÃ³n del sistema')
args = parser.parse_args()
if args.command == 'inspect':
inspect_checkpoint(args.thread_id)
elif args.command == 'list':
list_all_threads()
elif args.command == 'validate':
validate_setup()
else:
parser.print_help()
if __name__ == "__main__":
main()
Uso:
bash
# Validar configuraciÃ³n
python debug_tools.py validate
# Listar experimentos
python debug_tools.py list
# Inspeccionar experimento especÃ­fico
python debug_tools.py inspect <thread-id>
16. OPTIMIZACIÃ“N Y ESCALABILIDAD
16.1 EjecuciÃ³n Paralela de Simulaciones
Para experimentos que requieren mÃºltiples simulaciones (barrido de parÃ¡metros), crear parallel_runner.py :
python

--- PÃ¡gina 57 ---
#!/usr/bin/env python3
"""
Ejecutor paralelo de simulaciones
"""
import multiprocessing as mp
from pathlib import Path
import pandas as pd
from typing import List, Dict
from supervisor import SupervisorOrchestrator
def run_single_experiment(params: Dict) -> Dict:
"""
Ejecutar un experimento individual
"""
task = params['task']
thread_id = params.get('thread_id')
supervisor = SupervisorOrchestrator()
result = supervisor.run_experiment(task, thread_id)
return {
'params': params,
'result': result
}
def run_parameter_sweep(base_task: str, parameter_name: str,
parameter_values: List) -> pd.DataFrame:
"""
Ejecutar barrido de parÃ¡metros en paralelo
"""
# Crear lista de tareas
tasks = []
for value in parameter_values:
task = f"{base_task} con {parameter_name}={value}"
tasks.append({
'task': task,
parameter_name: value
})
# Ejecutar en paralelo
num_processes = min(mp.cpu_count() - 1, len(tasks))
print(f"ğŸš€ Ejecutando {len(tasks)} experimentos en {num_processes} procesos")

--- PÃ¡gina 58 ---
with mp.Pool(processes=num_processes) as pool:
results = pool.map(run_single_experiment, tasks)
# Consolidar resultados
data = []
for res in results:
if res['result'] and res['result'].get('metrics'):
row = {parameter_name: res['params'][parameter_name]}
row.update(res['result']['metrics'])
data.append(row)
return pd.DataFrame(data)
# Ejemplo de uso
if __name__ == "__main__":
# Barrido de nÃºmero de nodos
results_df = run_parameter_sweep(
base_task="Evaluar AODV en red vehicular",
parameter_name="num_nodos",
parameter_values=[25, 50, 75, 100, 150]
)
print("\nğŸ“Š RESULTADOS DEL BARRIDO:")
print(results_df)
# Guardar resultados
results_df.to_csv("barrido_nodos.csv", index=False)
16.2 Uso de Google Colab como Respaldo
Crear colab_setup.py para configurar Colab:
python

--- PÃ¡gina 59 ---
"""
Script para ejecutar en Google Colab
"""
# 1. Instalar Ollama en Colab
!curl -fsSL https://ollama.com/install.sh | sh
# 2. Iniciar Ollama en background
import subprocess
import time
ollama_process = subprocess.Popen(
["ollama", "serve"],
stdout=subprocess.PIPE,
stderr=subprocess.PIPE
)
time.sleep(5) # Esperar a que inicie
# 3. Descargar modelos
!ollama pull qwen2.5-coder:7b
!ollama pull llama3.3:8b
# 4. Instalar ngrok para exponer puerto
!pip install pyngrok
from pyngrok import ngrok
# Exponer Ollama
public_url = ngrok.connect(11434)
print(f"ğŸŒ Ollama pÃºblico en: {public_url}")
# 5. Clonar repositorio del proyecto
!git clone https://github.com/tu-usuario/tesis-a2a.git
%cd tesis-a2a/sistema-a2a
# 6. Instalar dependencias
!pip install -r requirements.txt
# 7. Ejecutar experimento
!python main.py --task "Tu tarea de investigaciÃ³n"

--- PÃ¡gina 60 ---
GUÃA DE AUTOMATIZACIÃ“N COMPLETA
17. AUTOMATIZACIÃ“N DEL USO DIARIO
17.1 Script de Inicio RÃ¡pido
Crear quick_start.sh :
bash

--- PÃ¡gina 61 ---
#!/bin/bash
# Script de inicio rÃ¡pido del sistema A2A
echo "ğŸš€ Iniciando Sistema A2A para Tesis Doctoral"
echo "=============================================="
# 1. Activar entorno virtual
cd ~/tesis-a2a/sistema-a2a
source venv-a2a/bin/activate
# 2. Verificar que Ollama estÃ© corriendo
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
echo "âš  Ollama no estÃ¡ corriendo. Iniciando..."
ollama serve &
sleep 5
fi
# 3. Validar configuraciÃ³n
python debug_tools.py validate
# 4. Mostrar menÃº
echo ""
echo "Sistema listo. Opciones:"
echo "1. Ejecutar experimento interactivo"
echo "2. Ejecutar experimento desde archivo"
echo "3. Ver bitÃ¡cora"
echo "4. Monitorear experimentos"
echo ""
read -p "Selecciona opciÃ³n (1-4): " option
case $option in
1)
read -p "Describe tu experimento: " task
python main.py --task "$task"
;;
2)
read -p "Ruta al archivo con tareas: " file
while IFS= read -r task; do
python main.py --task "$task"
done < "$file"
;;
3)
python main.py --export-logbook
xdg-open logs/bitacora_completa.md

--- PÃ¡gina 62 ---
;;
4)
python monitor.py
;;
*)
echo "OpciÃ³n invÃ¡lida"
;;
esac
Hacer ejecutable:
bash
chmod +x quick_start.sh
17.2 Archivo de Tareas para AutomatizaciÃ³n
Crear experimentos.txt :
Comparar PDR entre AODV y OLSR con 50 nodos en grid 1000x1000m
Evaluar impacto de velocidad de nodos (20, 40, 60 km/h) en throughput
Implementar DQN para selecciÃ³n de siguiente salto en MANET
Analizar overhead de control en protocolos reactivos vs proactivos
Proponer GNN para predicciÃ³n de congestiÃ³n en Smart City
Ejecutar todas las tareas:
bash
./quick_start.sh
# Seleccionar opciÃ³n 2
# Ingresar: experimentos.txt
17.3 Cron Job para Experimentos Nocturnos
Editar crontab:
bash
crontab -e
AÃ±adir:
cron

--- PÃ¡gina 63 ---
# Ejecutar experimentos todas las noches a las 2 AM
0 2 * * * cd ~/tesis-a2a/sistema-a2a && source venv-a2a/bin/activate && python batch_runner.py --file experimentos.txt >> l
Crear batch_runner.py :
python

--- PÃ¡gina 64 ---
#!/usr/bin/env python3
"""
Ejecutor batch para cron jobs
"""
import sys
import argparse
from pathlib import Path
from main import SupervisorOrchestrator
from utils.logbook import LogbookManager
def run_batch(tasks_file: Path):
"""
Ejecutar mÃºltiples tareas desde archivo
"""
with open(tasks_file, 'r') as f:
tasks = [line.strip() for line in f if line.strip() and not line.startswith('#')]
print(f"ğŸ“‹ Ejecutando {len(tasks)} tareas...")
supervisor = SupervisorOrchestrator()
for i, task in enumerate(tasks, 1):
print(f"\n{'='*80}")
print(f"Tarea {i}/{len(tasks)}: {task}")
print(f"{'='*80}\n")
try:
supervisor.run_experiment(task)
except Exception as e:
print(f"âŒ Error en tarea {i}: {e}")
continue
# Exportar bitÃ¡cora
logbook = LogbookManager()
output_path = logbook.export_to_markdown()
print(f"\nâœ… BitÃ¡cora exportada: {output_path}")
logbook.close()
if __name__ == "__main__":
parser = argparse.ArgumentParser()
parser.add_argument('--file', required=True, help='Archivo con tareas')
args = parser.parse_args()

--- PÃ¡gina 65 ---
run_batch(Path(args.file))
18. CHECKLIST DE IMPLEMENTACIÃ“N COMPLETA
markdown

--- PÃ¡gina 66 ---
## FASE 1: Infraestructura Base (Semana 1-2)
- [ ] Instalar y configurar Ollama
- [ ] Descargar modelos LLM necesarios
- [ ] Compilar NS-3 con Python bindings
- [ ] Verificar instalaciÃ³n de ns3-ai
- [ ] Crear estructura de proyecto Python
- [ ] Instalar dependencias (LangGraph, etc.)
## FASE 2: Agentes BÃ¡sicos (Semana 3-4)
- [ ] Implementar Agente Investigador
- [ ] Configurar ChromaDB
- [ ] Test de bÃºsqueda en Semantic Scholar
- [ ] Implementar Agente Programador
- [ ] Test de generaciÃ³n de cÃ³digo NS-3
## FASE 3: SimulaciÃ³n (Semana 5-6)
- [ ] Implementar Agente Ejecutor
- [ ] Test de ejecuciÃ³n de simulaciÃ³n simple
- [ ] Configurar manejo de errores
- [ ] Implementar Agente Analista
- [ ] Test de parsing de FlowMonitor XML
## FASE 4: VisualizaciÃ³n y BitÃ¡cora (Semana 7)
- [ ] Implementar Agente Visualizador
- [ ] Configurar sistema de bitÃ¡cora
- [ ] Test de exportaciÃ³n a Markdown
## FASE 5: OrquestaciÃ³n (Semana 8-9)
- [ ] Implementar Supervisor LangGraph
- [ ] Configurar flujos condicionales
- [ ] Test de experimento end-to-end
- [ ] Ajustar manejo de errores
## FASE 6: AutomatizaciÃ³n (Semana 10)
- [ ] Crear scripts de inicio rÃ¡pido
- [ ] Configurar ejecuciÃ³n paralela
- [ ] Setup de cron jobs
- [ ] Documentar uso
## FASE 7: OptimizaciÃ³n IA (Semana 11-12)
- [ ] Integrar ns3-ai con PyTorch
- [ ] Implementar entorno DRL bÃ¡sico
- [ ] Test de Q-Learning simple
- [ ] Explorar arquitecturas GNN
## FASE 8: ProducciÃ³n (Semana 13+)

--- PÃ¡gina 67 ---
- [ ] Ejecutar experimentos reales
- [ ] AnÃ¡lisis de resultados
- [ ] IteraciÃ³n basada en findings
- [ ] DocumentaciÃ³n de tesis
19. RESOLUCIÃ“N DE PROBLEMAS COMUNES
Problema 1: Ollama no responde
bash
# Verificar estado
systemctl status ollama
# Reiniciar
systemctl restart ollama
# Ver logs
journalctl -u ollama -f
Problema 2: NS-3 no compila
bash
# Limpiar build
cd ~/tesis-a2a/ns-allinone-3.43/ns-3.43
./ns3 clean
# Verificar dependencias
sudo apt install g++ python3-dev cmake
# Reconfigurar
./ns3 configure --enable-python-bindings
# Rebuild
./ns3 build
Problema 3: Error en imports de Python
python
# AÃ±adir path de NS-3 manualmente
import sys
sys.path.append('/home/tu_usuario/tesis-a2a/ns-allinone-3.43/ns-3.43/build/lib/python3')

--- PÃ¡gina 68 ---
Problema 4: ChromaDB da error de permisos
bash
# Cambiar permisos del directorio
chmod -R 755 ~/tesis-a2a/sistema-a2a/data/vector_db
Problema 5: LLM genera cÃ³digo incorrecto repetidamente
SoluciÃ³n: Ajustar el prompt del agente programador con ejemplos especÃ­ficos:
python
# En agents/coder.py, aÃ±adir ejemplos al prompt
examples = """
EJEMPLO 1 - Red WiFi bÃ¡sica:
```python
import ns.core
import ns.network
import ns.wifi
nodes = ns.network.NodeContainer()
nodes.Create(10)
wifi = ns.wifi.WifiHelper()
# ... configuraciÃ³n
```
EJEMPLO 2 - Movilidad:
```python
mobility = ns.mobility.MobilityHelper()
mobility.SetMobilityModel("ns3::RandomWaypointMobilityModel")
mobility.Install(nodes)
```
"""
20. GUÃA DE REFERENCIA RÃPIDA
Comandos Esenciales
bash

--- PÃ¡gina 69 ---
# Iniciar sistema completo
cd ~/tesis-a2a/sistema-a2a
./quick_start.sh
# Ejecutar experimento Ãºnico
python main.py --task "Tu descripciÃ³n aquÃ­"
# Ejecutar batch de experimentos
python batch_runner.py --file experimentos.txt
# Monitorear en tiempo real
python monitor.py
# Validar configuraciÃ³n
python debug_tools.py validate
# Ver lista de experimentos
python debug_tools.py list
# Inspeccionar experimento especÃ­fico
python debug_tools.py inspect <thread-id>
# Exportar bitÃ¡cora
python main.py --export-logbook
Estructura de Directorios

--- PÃ¡gina 70 ---
~/tesis-a2a/
â”œâ”€â”€ ns-allinone-3.43/ # NS-3 compilado
â”‚ â””â”€â”€ ns-3.43/
â”‚ â”œâ”€â”€ scratch/ # Scripts generados aquÃ­
â”‚ â””â”€â”€ resultados.xml # Resultados de simulaciÃ³n
â”‚
â””â”€â”€ sistema-a2a/ # Sistema de agentes
â”œâ”€â”€ agents/ # Agentes individuales
â”œâ”€â”€ config/ # ConfiguraciÃ³n
â”œâ”€â”€ utils/ # Utilidades
â”œâ”€â”€ logs/ # Logs y bitÃ¡cora
â”œâ”€â”€ data/ # Papers y ChromaDB
â”œâ”€â”€ simulations/
â”‚ â”œâ”€â”€ scripts/ # Scripts guardados
â”‚ â”œâ”€â”€ results/ # XMLs de resultados
â”‚ â””â”€â”€ plots/ # GrÃ¡ficos generados
â”œâ”€â”€ main.py # Punto de entrada
â”œâ”€â”€ supervisor.py # Orquestador
â””â”€â”€ quick_start.sh # Inicio rÃ¡pido
Flujo de Trabajo TÃ­pico
1. MaÃ±ana: Definir tareas en experimentos.txt
2. DÃ­a: Ejecutar: python batch_runner.py --file experimentos.txt
3. Tarde: Revisar resultados en simulations/plots/
4. Noche: Exportar bitÃ¡cora: python main.py --export-logbook
5. Revisar: Leer logs/bitacora_completa.md para documentar tesis
21. INTEGRACIÃ“N AVANZADA: REDES NEURONALES
21.1 ImplementaciÃ³n de DQN para Enrutamiento
Crear agents/dqn_routing.py :
python

--- PÃ¡gina 71 ---
"""
Agente DQN para optimizaciÃ³n de enrutamiento
"""
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from collections import deque
import random
class DQNNetwork(nn.Module):
"""
Red neuronal para Q-Learning
"""
def __init__(self, state_size, action_size):
super(DQNNetwork, self).__init__()
self.fc1 = nn.Linear(state_size, 128)
self.fc2 = nn.Linear(128, 128)
self.fc3 = nn.Linear(128, action_size)
def forward(self, x):
x = torch.relu(self.fc1(x))
x = torch.relu(self.fc2(x))
return self.fc3(x)
class DQNAgent:
"""
Agente DQN para decisiones de enrutamiento
"""
def __init__(self, state_size, action_size):
self.state_size = state_size
self.action_size = action_size
# HiperparÃ¡metros
self.gamma = 0.95 # Factor de descuento
self.epsilon = 1.0 # ExploraciÃ³n
self.epsilon_min = 0.01
self.epsilon_decay = 0.995
self.learning_rate = 0.001
# Memoria de replay
self.memory = deque(maxlen=2000)
# Redes

--- PÃ¡gina 72 ---
self.model = DQNNetwork(state_size, action_size)
self.target_model = DQNNetwork(state_size, action_size)
self.update_target_model()
# Optimizador
self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
def update_target_model(self):
"""Copiar pesos de modelo principal a target"""
self.target_model.load_state_dict(self.model.state_dict())
def remember(self, state, action, reward, next_state, done):
"""Guardar experiencia en memoria"""
self.memory.append((state, action, reward, next_state, done))
def act(self, state):
"""Seleccionar acciÃ³n usando epsilon-greedy"""
if np.random.rand() <= self.epsilon:
return random.randrange(self.action_size)
state = torch.FloatTensor(state).unsqueeze(0)
with torch.no_grad():
q_values = self.model(state)
return q_values.argmax().item()
def replay(self, batch_size):
"""Entrenar con batch de experiencias"""
if len(self.memory) < batch_size:
return
minibatch = random.sample(self.memory, batch_size)
for state, action, reward, next_state, done in minibatch:
state = torch.FloatTensor(state).unsqueeze(0)
next_state = torch.FloatTensor(next_state).unsqueeze(0)
target = reward
if not done:
target += self.gamma * self.target_model(next_state).max().item()
current_q = self.model(state)
target_q = current_q.clone()
target_q[0][action] = target
# Backpropagation
loss = nn.MSELoss()(current_q, target_q)
self.optimizer.zero_grad()

--- PÃ¡gina 73 ---
loss.backward()
self.optimizer.step()
# Decay epsilon
if self.epsilon > self.epsilon_min:
self.epsilon *= self.epsilon_decay
def save(self, filename):
"""Guardar modelo"""
torch.save(self.model.state_dict(), filename)
def load(self, filename):
"""Cargar modelo"""
self.model.load_state_dict(torch.load(filename))
21.2 Script de NS-3 con ns3-ai para DQN
Crear template en agents/coder.py :
python

--- PÃ¡gina 74 ---
# Template para integraciÃ³n DQN con NS-3
ns3_ai_template = '''#!/usr/bin/env python3
"""
SimulaciÃ³n NS-3 con agente DQN
"""
import sys
sys.path.append('build/lib/python3')
import ns.core
import ns.network
import ns.internet
import ns.applications
from ns3ai_gym_env import Ns3AiGymEnv
# Definir entorno Gym
class RoutingEnv(Ns3AiGymEnv):
def __init__(self):
super().__init__()
self.state_size = 10 # Ej: longitud cola, energÃ­a, vecinos
self.action_size = 5 # NÃºmero de vecinos posibles
def get_state(self):
"""Obtener estado actual de la red"""
# Extraer de NS-3: mÃ©tricas de nodos
state = []
# ... lÃ³gica para obtener estado
return state
def take_action(self, action):
"""Aplicar acciÃ³n (seleccionar siguiente salto)"""
# Modificar tabla de enrutamiento en NS-3
pass
def get_reward(self):
"""Calcular recompensa basada en mÃ©tricas"""
# Ej: -delay - 0.1*energy_consumed + 10*packet_delivered
return reward
def main():
# Crear entorno
env = RoutingEnv()
# Cargar agente DQN (entrenado previamente)
from dqn_routing import DQNAgent
agent = DQNAgent(state_size=10, action_size=5)

--- PÃ¡gina 75 ---
agent.load('dqn_model.pth')
# Loop de simulaciÃ³n
state = env.reset()
done = False
while not done:
action = agent.act(state)
next_state, reward, done = env.step(action)
state = next_state
print("SimulaciÃ³n con DQN completada")
if __name__ == "__main__":
main()
'''
21.3 Entrenamiento del Agente DQN
Crear train_dqn.py :
python

--- PÃ¡gina 76 ---
#!/usr/bin/env python3
"""
Entrenar agente DQN para enrutamiento
"""
from agents.dqn_routing import DQNAgent
import numpy as np
def train_dqn(episodes=1000):
"""
Entrenar agente DQN
"""
# Definir tamaÃ±os
state_size = 10 # Ej: [queue_length, energy, num_neighbors, ...]
action_size = 5 # NÃºmero de vecinos posibles
agent = DQNAgent(state_size, action_size)
batch_size = 32
for episode in range(episodes):
# SimulaciÃ³n simplificada (reemplazar con NS-3 real)
state = np.random.rand(state_size)
total_reward = 0
for step in range(100): # 100 pasos por episodio
# Seleccionar acciÃ³n
action = agent.act(state)
# Simular resultado (reemplazar con NS-3)
next_state = np.random.rand(state_size)
reward = np.random.randn() # Recompensa simulada
done = (step == 99)
# Guardar experiencia
agent.remember(state, action, reward, next_state, done)
state = next_state
total_reward += reward
if done:
agent.update_target_model()
print(f"Episodio: {episode+1}/{episodes}, "
f"Recompensa: {total_reward:.2f}, "
f"Epsilon: {agent.epsilon:.3f}")
break

--- PÃ¡gina 77 ---
# Entrenar
agent.replay(batch_size)
# Guardar cada 100 episodios
if (episode + 1) % 100 == 0:
agent.save(f'models/dqn_episode_{episode+1}.pth')
print("\nâœ… Entrenamiento completado")
agent.save('models/dqn_final.pth')
if __name__ == "__main__":
train_dqn()
22. ROADMAP DE INVESTIGACIÃ“N DOCTORAL
AÃ±o 1: Fundamentos y Baseline
Q1-Q2: Setup y Protocolos Tradicionales
Implementar sistema A2A completo
Simular protocolos baseline (AODV, OLSR, DSDV)
Establecer mÃ©tricas de referencia
Publicar paper de metodologÃ­a A2A
Q3-Q4: Primeras Optimizaciones
Implementar Q-Learning bÃ¡sico
Comparar con protocolos tradicionales
Identificar limitaciones de DRL clÃ¡sico
AÃ±o 2: InnovaciÃ³n con GNN
Q1-Q2: Desarrollo de GNN
Implementar arquitectura RouteNet adaptada
Entrenar con topologÃ­as variadas
Validar generalizaciÃ³n
Q3-Q4: EvaluaciÃ³n Exhaustiva
Experimentos a gran escala
ComparaciÃ³n con estado del arte

--- PÃ¡gina 78 ---
Publicar paper principal (GNN para Smart Cities)
AÃ±o 3: ConsolidaciÃ³n y Escritura
Q1-Q2: Refinamiento
Optimizar hiperparÃ¡metros
ValidaciÃ³n en escenarios reales
AnÃ¡lisis de complejidad computacional
Q3-Q4: Tesis
RedacciÃ³n de tesis doctoral
PreparaciÃ³n de defensa
Publicaciones finales
23. RECURSOS ADICIONALES Y COMUNIDAD
DocumentaciÃ³n Oficial
LangGraph: https://langchain-ai.github.io/langgraph/
NS-3: https://www.nsnam.org/documentation/
ns3-ai: https://github.com/hust-diangroup/ns3-ai
Ollama: https://ollama.com/docs
Papers Clave para Citar
1. GenOnet (2025): Multi-agent LLM con NS-3
2. RouteNet (2019): GNN para redes
3. ns3-gym (2019): RL con NS-3
4. LangGraph (2024): OrquestaciÃ³n de agentes
Comunidades y Foros
Reddit: r/LocalLLaMA, r/MachineLearning
Discord: LangChain Community
NS-3 Users Mailing List
Stack Overflow: [ns-3], [langgraph]

--- PÃ¡gina 79 ---
24. CONCLUSIÃ“N Y PRÃ“XIMOS PASOS
Â¿QuÃ© has logrado con esta guÃ­a?
âœ… Sistema completamente funcional de agentes A2A
âœ… IntegraciÃ³n NS-3 + IA para experimentos avanzados
âœ… AutomatizaciÃ³n total del proceso de investigaciÃ³n
âœ… BitÃ¡cora automÃ¡tica para reproducibilidad
âœ… Base sÃ³lida para tesis doctoral innovadora
Primeros Pasos Inmediatos
1. HOY: Instalar Ollama y descargar modelos
2. MAÃ‘ANA: Compilar NS-3 con Python bindings
3. DÃA 3: Implementar Agente Investigador
4. DÃA 4: Test completo con experimento simple
5. SEMANA 2: Primer experimento end-to-end
Contacto y Soporte
Si encuentras problemas durante la implementaciÃ³n:
1. Revisar logs: logs/cron.log , journalctl -u ollama
2. Validar setup: python debug_tools.py validate
3. Consultar documentaciÃ³n oficial de cada componente
4. Buscar en issues de GitHub de LangGraph y ns3-ai
APÃ‰NDICE A: GLOSARIO TÃ‰CNICO
A2A: Agent-to-Agent (Agente a Agente)
AODV: Ad-hoc On-demand Distance Vector
DQN: Deep Q-Network
DRL: Deep Reinforcement Learning
FlowMonitor: MÃ³dulo de NS-3 para mÃ©tricas
GNN: Graph Neural Network
LLM: Large Language Model
MANET: Mobile Ad-hoc Network
NS-3: Network Simulator 3

--- PÃ¡gina 80 ---
PDR: Packet Delivery Ratio
RAG: Retrieval Augmented Generation
VANET: Vehicular Ad-hoc Network
APÃ‰NDICE B: TROUBLESHOOTING AVANZADO
B.1 Error: "ModuleNotFoundError: No module named 'ns'"
Causa: Python no encuentra los bindings de NS-3
SoluciÃ³n:
python
import sys
sys.path.insert(0, '/ruta/completa/a/ns-3.43/build/lib/python3')
B.2 Error: "Ollama connection refused"
Causa: Servidor Ollama no estÃ¡ corriendo
SoluciÃ³n:
bash
# Verificar estado
systemctl status ollama
# Si no estÃ¡ activo
sudo systemctl start ollama
# Habilitar en boot
sudo systemctl enable ollama
B.3 SimulaciÃ³n NS-3 cuelga indefinidamente
Causa: Bucle infinito en el cÃ³digo generado
SoluciÃ³n: AÃ±adir timeout en agents/simulator.py :
python
result = subprocess.run(
cmd,
timeout=600 # 10 minutos mÃ¡ximo
)

--- PÃ¡gina 81 ---
B.4 LLM genera respuestas muy lentas
Causa: Modelo muy grande para tu hardware
SoluciÃ³n: Usar modelos cuantizados mÃ¡s pequeÃ±os:
bash
# En lugar de 32b, usar 7b
ollama pull qwen2.5-coder:7b
APÃ‰NDICE C: EJEMPLO COMPLETO DE SESIÃ“N
bash

--- PÃ¡gina 82 ---
# SesiÃ³n de ejemplo completa desde cero
# 1. Activar entorno
cd ~/tesis-a2a/sistema-a2a
source venv-a2a/bin/activate
# 2. Validar sistema
python debug_tools.py validate
# âœ… Todos los componentes estÃ¡n correctos
# 3. Ejecutar experimento
python main.py --task "Comparar latencia entre AODV y OLSR con 30 nodos"
# Output esperado:
# ğŸš€ INICIANDO EXPERIMENTO A2A
# ==========================================================================
# ğŸ“‹ Tarea: Comparar latencia entre AODV y OLSR con 30 nodos
# ğŸ†” Thread ID: abc-123-xyz
# ==========================================================================
#
# ğŸ“ AGENTE INVESTIGADOR ACTIVADO
# ğŸ” Buscando en Semantic Scholar: routing protocols optimization...
# ğŸ“ Sintetizando hallazgos de investigaciÃ³n...
# âœ“ Completado: researcher
#
# ğŸ’» AGENTE PROGRAMADOR ACTIVADO
# ğŸ”¨ Generando cÃ³digo NS-3...
# âœ… CÃ³digo guardado en: simulations/scripts/tesis_sim.py
# âœ“ Completado: coder
#
# âš¡ AGENTE SIMULADOR ACTIVADO
# ğŸš€ Ejecutando simulaciÃ³n: tesis_sim.py
# âœ… SimulaciÃ³n exitosa!
# ğŸ“Š Resultados: simulations/results/sim_20251123_143022.xml
# âœ“ Completado: simulator
#
# ğŸ”¬ AGENTE ANALISTA ACTIVADO
# ğŸ“Š Parseando resultados...
# ğŸ“ˆ KPIs Calculados:
# avg_pdr: 87.5
# avg_throughput: 2.3
# avg_delay: 45.2
# âœ“ Completado: analyst
#
# ğŸ“Š AGENTE VISUALIZADOR ACTIVADO
# âœ… Generados 3 grÃ¡ficos

--- PÃ¡gina 83 ---
# âœ“ Completado: visualizer
#
# ğŸ‰ EXPERIMENTO COMPLETADO
# ==========================================================================
# ğŸ“Š MÃ‰TRICAS FINALES:
# avg_pdr: 87.5
# avg_throughput: 2.3
# avg_delay: 45.2
# ğŸ“ˆ GrÃ¡ficos generados: 3
# 4. Ver bitÃ¡cora
python main.py --export-logbook
# âœ… BitÃ¡cora exportada a: logs/bitacora_completa.md
# 5. Abrir resultados
xdg-open simulations/plots/pdr_per_flow.png
xdg-open logs/bitacora_completa.md
FIN DE LA GUÃA COMPLETA
Ãšltima actualizaciÃ³n: Noviembre 2025
VersiÃ³n: 2.0
Licencia: MIT (Open Source)
ğŸ¯
Â¡ACCIÃ“N INMEDIATA!
Tu prÃ³ximo paso es:
bash
# Copia y ejecuta estos comandos AHORA:
cd ~
mkdir -p tesis-a2a
cd tesis-a2a
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh
# Descargar primer modelo
ollama pull qwen2.5-coder:7b
# Â¡Ya tienes el 20% del sistema funcionando!

--- PÃ¡gina 84 ---
Â¡Ã‰xito en tu investigaciÃ³n doctoral! ğŸš€ğŸ“š
